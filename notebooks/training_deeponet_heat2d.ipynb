{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-05 02:22:48.105628: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-05 02:22:48.116916: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1741137768.129099  705342 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1741137768.132495  705342 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-05 02:22:48.145797: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sciml.model.deeponet import DeepONet\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "tf.config.list_physical_devices('GPU')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_p = 40\n",
    "d_V = 40\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "internal_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(40, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(40, activation='relu'),\n",
    "])\n",
    "\n",
    "\n",
    "external_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(3, activation='relu'),\n",
    "    tf.keras.layers.Dense(40, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(40, activation='relu'),\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"data/test_data/example_data/heat2d/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1741137770.229100  705342 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5563 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "INFO:sciml.model.deeponet.deeponet:Model initialized with 100 epochs, 32 batch size, 0.001 learning rate\n"
     ]
    }
   ],
   "source": [
    "model = DeepONet(regular_params={\"internal_model\": internal_model, \"external_model\": external_model}, hyper_params={\"d_p\": d_p, \"d_V\": d_V,\"device\": \"GPU\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading mu data: 100%|██████████| 40/40 [00:00<00:00, 8612.09it/s]\n",
      "Loading x data: 100%|██████████| 40/40 [00:00<00:00, 19488.00it/s]\n",
      "Loading y data: 100%|██████████| 40/40 [00:00<00:00, 11001.45it/s]\n"
     ]
    }
   ],
   "source": [
    "mus, xs, sol = model.get_data(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 4, 20)\n"
     ]
    }
   ],
   "source": [
    "print(mus.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading mu data: 100%|██████████| 40/40 [00:00<00:00, 16526.02it/s]\n",
      "Loading x data: 100%|██████████| 40/40 [00:00<00:00, 15544.53it/s]\n",
      "Loading y data: 100%|██████████| 40/40 [00:00<00:00, 16172.37it/s]\n",
      "Training progress:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorShape([32, 4, 20])\n",
      "TensorShape([32, 400, 2])\n",
      "TensorShape([32, 40])\n",
      "TensorShape([32, 400, 40])\n",
      "TensorShape([32, 400])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-05 02:22:51.155732: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: INVALID_ARGUMENT: Incompatible shapes: [32,400] vs. [32,40]\n",
      "Training progress:   0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__Sub_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [32,400] vs. [32,40] [Op:Sub] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInvalidArgumentError\u001b[39m                      Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m train_history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SCIML/sciml/model/deeponet/deeponet.py:178\u001b[39m, in \u001b[36mDeepONet.fit\u001b[39m\u001b[34m(self, device, mus, xs, sol, folder_path)\u001b[39m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.n_epochs),desc=\u001b[33m\"\u001b[39m\u001b[33mTraining progress\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    177\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m dataset:\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m         loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    179\u001b[39m         loss_history.append(loss)\n\u001b[32m    180\u001b[39m     logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m completed\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SCIML/sciml/model/deeponet/deeponet.py:192\u001b[39m, in \u001b[36mDeepONet.train_step\u001b[39m\u001b[34m(self, batch)\u001b[39m\n\u001b[32m    190\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m tf.GradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape: \u001b[38;5;66;03m# gradient tape to compute the gradients\u001b[39;00m\n\u001b[32m    191\u001b[39m     y_pred = \u001b[38;5;28mself\u001b[39m.predict(mu,x)\n\u001b[32m--> \u001b[39m\u001b[32m192\u001b[39m     loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43msol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[38;5;66;03m# Backprop\u001b[39;00m\n\u001b[32m    195\u001b[39m gradients = tape.gradient(loss,\u001b[38;5;28mself\u001b[39m.trainable_variables)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SCIML/sciml/.venv/lib/python3.11/site-packages/keras/src/losses/loss.py:67\u001b[39m, in \u001b[36mLoss.__call__\u001b[39m\u001b[34m(self, y_true, y_pred, sample_weight)\u001b[39m\n\u001b[32m     60\u001b[39m y_pred = tree.map_structure(\n\u001b[32m     61\u001b[39m     \u001b[38;5;28;01mlambda\u001b[39;00m x: ops.convert_to_tensor(x, dtype=\u001b[38;5;28mself\u001b[39m.dtype), y_pred\n\u001b[32m     62\u001b[39m )\n\u001b[32m     63\u001b[39m y_true = tree.map_structure(\n\u001b[32m     64\u001b[39m     \u001b[38;5;28;01mlambda\u001b[39;00m x: ops.convert_to_tensor(x, dtype=\u001b[38;5;28mself\u001b[39m.dtype), y_true\n\u001b[32m     65\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m losses = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     68\u001b[39m out_mask = backend.get_keras_mask(losses)\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m in_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m out_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SCIML/sciml/.venv/lib/python3.11/site-packages/keras/src/losses/losses.py:33\u001b[39m, in \u001b[36mLossFunctionWrapper.call\u001b[39m\u001b[34m(self, y_true, y_pred)\u001b[39m\n\u001b[32m     31\u001b[39m y_true = tree.map_structure_up_to(y_true, \u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[32m0\u001b[39m], y_true_y_pred)\n\u001b[32m     32\u001b[39m y_pred = tree.map_structure_up_to(y_pred, \u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[32m1\u001b[39m], y_true_y_pred)\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fn_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SCIML/sciml/.venv/lib/python3.11/site-packages/keras/src/losses/losses.py:1679\u001b[39m, in \u001b[36mmean_squared_error\u001b[39m\u001b[34m(y_true, y_pred)\u001b[39m\n\u001b[32m   1677\u001b[39m y_true = ops.convert_to_tensor(y_true, dtype=y_pred.dtype)\n\u001b[32m   1678\u001b[39m y_true, y_pred = squeeze_or_expand_to_same_rank(y_true, y_pred)\n\u001b[32m-> \u001b[39m\u001b[32m1679\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ops.mean(ops.square(\u001b[43my_true\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m), axis=-\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SCIML/sciml/.venv/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    155\u001b[39m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SCIML/sciml/.venv/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:6002\u001b[39m, in \u001b[36mraise_from_not_ok_status\u001b[39m\u001b[34m(e, name)\u001b[39m\n\u001b[32m   6000\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mraise_from_not_ok_status\u001b[39m(e, name) -> NoReturn:\n\u001b[32m   6001\u001b[39m   e.message += (\u001b[33m\"\u001b[39m\u001b[33m name: \u001b[39m\u001b[33m\"\u001b[39m + \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m-> \u001b[39m\u001b[32m6002\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m core._status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mInvalidArgumentError\u001b[39m: {{function_node __wrapped__Sub_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [32,400] vs. [32,40] [Op:Sub] name: "
     ]
    }
   ],
   "source": [
    "train_history = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
