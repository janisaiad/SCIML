{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sciml.model.deeponet import DeepONet\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "tf.config.list_physical_devices('GPU')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_p = 40\n",
    "d_V = 5\n",
    "epochs = 300    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "internal_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(80,)),\n",
    "    tf.keras.layers.Dense(40, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(d_V, activation='relu'),\n",
    "])\n",
    "\n",
    "\n",
    "external_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(3,)),\n",
    "    tf.keras.layers.Dense(40, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(d_V, activation='relu'),\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"data/test_data/example_data/heat2d/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-17 11:01:47,529 - sciml.model.deeponet.deeponet - INFO - Model initialized with 300 epochs, 32 batch size, 0.001 learning rate\n"
     ]
    }
   ],
   "source": [
    "model = DeepONet(regular_params={\"internal_model\": internal_model, \"external_model\": external_model}, hyper_params={\"d_p\": d_p, \"d_V\": d_V,\"device\": \"GPU\",\"n_epochs\":epochs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading mu data: 100%|██████████| 40/40 [00:00<00:00, 7411.74it/s]\n",
      "Loading x data: 100%|██████████| 40/40 [00:00<00:00, 4106.93it/s]\n",
      "Loading y data: 100%|██████████| 40/40 [00:00<00:00, 6417.97it/s]\n"
     ]
    }
   ],
   "source": [
    "mus, xs, sol = model.get_data(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 80)\n",
      "(40, 8000, 3)\n",
      "(40, 8000)\n"
     ]
    }
   ],
   "source": [
    "print(mus.shape)\n",
    "print(xs.shape)\n",
    "print(sol.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading mu data: 100%|██████████| 40/40 [00:00<00:00, 10229.39it/s]\n",
      "Loading x data: 100%|██████████| 40/40 [00:00<00:00, 5682.76it/s]\n",
      "Loading y data: 100%|██████████| 40/40 [00:00<00:00, 5857.76it/s]\n",
      "2025-03-17 11:01:47.992852: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [40,8000]\n",
      "\t [[{{node Placeholder/_2}}]]\n",
      "Training progress:   0%|          | 0/300 [00:00<?, ?it/s]2025-03-17 11:01:48.012616: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,8000]\n",
      "\t [[{{node Placeholder/_2}}]]\n",
      "2025-03-17 11:01:48.179039: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [8,8000]\n",
      "\t [[{{node Placeholder/_2}}]]\n",
      "2025-03-17 11:01:48,204 - sciml.model.deeponet.deeponet - INFO - Epoch 1/300\n",
      "2025-03-17 11:01:48,205 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.336108\n",
      "2025-03-17 11:01:48,205 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.305188\n",
      "Training progress:   0%|          | 1/300 [00:00<00:58,  5.10it/s]2025-03-17 11:01:48,387 - sciml.model.deeponet.deeponet - INFO - Epoch 2/300\n",
      "2025-03-17 11:01:48,388 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.315190\n",
      "2025-03-17 11:01:48,389 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.282747\n",
      "Training progress:   1%|          | 2/300 [00:00<00:56,  5.30it/s]2025-03-17 11:01:48,570 - sciml.model.deeponet.deeponet - INFO - Epoch 3/300\n",
      "2025-03-17 11:01:48,570 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.296001\n",
      "2025-03-17 11:01:48,571 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.262896\n",
      "Training progress:   1%|          | 3/300 [00:00<00:55,  5.38it/s]2025-03-17 11:01:48,756 - sciml.model.deeponet.deeponet - INFO - Epoch 4/300\n",
      "2025-03-17 11:01:48,757 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.282885\n",
      "2025-03-17 11:01:48,758 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.248215\n",
      "Training progress:   1%|▏         | 4/300 [00:00<00:55,  5.38it/s]2025-03-17 11:01:48,966 - sciml.model.deeponet.deeponet - INFO - Epoch 5/300\n",
      "2025-03-17 11:01:48,967 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.279982\n",
      "2025-03-17 11:01:48,968 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.240925\n",
      "Training progress:   2%|▏         | 5/300 [00:00<00:57,  5.13it/s]2025-03-17 11:01:49,155 - sciml.model.deeponet.deeponet - INFO - Epoch 6/300\n",
      "2025-03-17 11:01:49,156 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.284198\n",
      "2025-03-17 11:01:49,157 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.238643\n",
      "Training progress:   2%|▏         | 6/300 [00:01<00:56,  5.19it/s]2025-03-17 11:01:49,331 - sciml.model.deeponet.deeponet - INFO - Epoch 7/300\n",
      "2025-03-17 11:01:49,332 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.284672\n",
      "2025-03-17 11:01:49,332 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.238714\n",
      "Training progress:   2%|▏         | 7/300 [00:01<00:54,  5.34it/s]2025-03-17 11:01:49,513 - sciml.model.deeponet.deeponet - INFO - Epoch 8/300\n",
      "2025-03-17 11:01:49,513 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.279851\n",
      "2025-03-17 11:01:49,514 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.240601\n",
      "Training progress:   3%|▎         | 8/300 [00:01<00:54,  5.40it/s]2025-03-17 11:01:49,695 - sciml.model.deeponet.deeponet - INFO - Epoch 9/300\n",
      "2025-03-17 11:01:49,696 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.273561\n",
      "2025-03-17 11:01:49,697 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.243901\n",
      "Training progress:   3%|▎         | 9/300 [00:01<00:53,  5.42it/s]2025-03-17 11:01:49,887 - sciml.model.deeponet.deeponet - INFO - Epoch 10/300\n",
      "2025-03-17 11:01:49,888 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.268748\n",
      "2025-03-17 11:01:49,888 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.247745\n",
      "Training progress:   3%|▎         | 10/300 [00:01<00:54,  5.36it/s]2025-03-17 11:01:50,068 - sciml.model.deeponet.deeponet - INFO - Epoch 11/300\n",
      "2025-03-17 11:01:50,069 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.266038\n",
      "2025-03-17 11:01:50,069 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.251057\n",
      "Training progress:   4%|▎         | 11/300 [00:02<00:53,  5.41it/s]2025-03-17 11:01:50,239 - sciml.model.deeponet.deeponet - INFO - Epoch 12/300\n",
      "2025-03-17 11:01:50,240 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.264583\n",
      "2025-03-17 11:01:50,240 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.252958\n",
      "Training progress:   4%|▍         | 12/300 [00:02<00:52,  5.53it/s]2025-03-17 11:01:50,425 - sciml.model.deeponet.deeponet - INFO - Epoch 13/300\n",
      "2025-03-17 11:01:50,426 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.263242\n",
      "2025-03-17 11:01:50,426 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.253035\n",
      "Training progress:   4%|▍         | 13/300 [00:02<00:52,  5.49it/s]2025-03-17 11:01:50,604 - sciml.model.deeponet.deeponet - INFO - Epoch 14/300\n",
      "2025-03-17 11:01:50,605 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.261224\n",
      "2025-03-17 11:01:50,605 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.251275\n",
      "Training progress:   5%|▍         | 14/300 [00:02<00:51,  5.51it/s]2025-03-17 11:01:50,790 - sciml.model.deeponet.deeponet - INFO - Epoch 15/300\n",
      "2025-03-17 11:01:50,791 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.258281\n",
      "2025-03-17 11:01:50,792 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.247915\n",
      "Training progress:   5%|▌         | 15/300 [00:02<00:52,  5.47it/s]2025-03-17 11:01:50,971 - sciml.model.deeponet.deeponet - INFO - Epoch 16/300\n",
      "2025-03-17 11:01:50,972 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.254574\n",
      "2025-03-17 11:01:50,973 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.243402\n",
      "Training progress:   5%|▌         | 16/300 [00:02<00:51,  5.48it/s]2025-03-17 11:01:51,148 - sciml.model.deeponet.deeponet - INFO - Epoch 17/300\n",
      "2025-03-17 11:01:51,148 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.250548\n",
      "2025-03-17 11:01:51,149 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.238222\n",
      "Training progress:   6%|▌         | 17/300 [00:03<00:51,  5.54it/s]2025-03-17 11:01:51,327 - sciml.model.deeponet.deeponet - INFO - Epoch 18/300\n",
      "2025-03-17 11:01:51,328 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.246696\n",
      "2025-03-17 11:01:51,329 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.233006\n",
      "Training progress:   6%|▌         | 18/300 [00:03<00:50,  5.55it/s]2025-03-17 11:01:51,513 - sciml.model.deeponet.deeponet - INFO - Epoch 19/300\n",
      "2025-03-17 11:01:51,514 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.243392\n",
      "2025-03-17 11:01:51,515 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.228389\n",
      "Training progress:   6%|▋         | 19/300 [00:03<00:51,  5.49it/s]2025-03-17 11:01:51,694 - sciml.model.deeponet.deeponet - INFO - Epoch 20/300\n",
      "2025-03-17 11:01:51,695 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.240486\n",
      "2025-03-17 11:01:51,696 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.224757\n",
      "Training progress:   7%|▋         | 20/300 [00:03<00:50,  5.50it/s]2025-03-17 11:01:51,879 - sciml.model.deeponet.deeponet - INFO - Epoch 21/300\n",
      "2025-03-17 11:01:51,880 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.237225\n",
      "2025-03-17 11:01:51,880 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.222298\n",
      "Training progress:   7%|▋         | 21/300 [00:03<00:50,  5.48it/s]2025-03-17 11:01:52,080 - sciml.model.deeponet.deeponet - INFO - Epoch 22/300\n",
      "2025-03-17 11:01:52,080 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.232818\n",
      "2025-03-17 11:01:52,081 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.220969\n",
      "Training progress:   7%|▋         | 22/300 [00:04<00:52,  5.32it/s]2025-03-17 11:01:52,280 - sciml.model.deeponet.deeponet - INFO - Epoch 23/300\n",
      "2025-03-17 11:01:52,281 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.227528\n",
      "2025-03-17 11:01:52,282 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.220589\n",
      "Training progress:   8%|▊         | 23/300 [00:04<00:53,  5.21it/s]2025-03-17 11:01:52,459 - sciml.model.deeponet.deeponet - INFO - Epoch 24/300\n",
      "2025-03-17 11:01:52,460 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.222360\n",
      "2025-03-17 11:01:52,460 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.220679\n",
      "Training progress:   8%|▊         | 24/300 [00:04<00:51,  5.33it/s]2025-03-17 11:01:52,633 - sciml.model.deeponet.deeponet - INFO - Epoch 25/300\n",
      "2025-03-17 11:01:52,634 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.218008\n",
      "2025-03-17 11:01:52,635 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.220188\n",
      "Training progress:   8%|▊         | 25/300 [00:04<00:50,  5.44it/s]2025-03-17 11:01:52,815 - sciml.model.deeponet.deeponet - INFO - Epoch 26/300\n",
      "2025-03-17 11:01:52,816 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.214099\n",
      "2025-03-17 11:01:52,817 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.218221\n",
      "Training progress:   9%|▊         | 26/300 [00:04<00:50,  5.45it/s]2025-03-17 11:01:52,992 - sciml.model.deeponet.deeponet - INFO - Epoch 27/300\n",
      "2025-03-17 11:01:52,992 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.209642\n",
      "2025-03-17 11:01:52,993 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.214633\n",
      "Training progress:   9%|▉         | 27/300 [00:04<00:49,  5.53it/s]2025-03-17 11:01:53,163 - sciml.model.deeponet.deeponet - INFO - Epoch 28/300\n",
      "2025-03-17 11:01:53,164 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.204326\n",
      "2025-03-17 11:01:53,165 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.209947\n",
      "Training progress:   9%|▉         | 28/300 [00:05<00:48,  5.60it/s]2025-03-17 11:01:53,335 - sciml.model.deeponet.deeponet - INFO - Epoch 29/300\n",
      "2025-03-17 11:01:53,336 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.198711\n",
      "2025-03-17 11:01:53,336 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.205012\n",
      "Training progress:  10%|▉         | 29/300 [00:05<00:47,  5.67it/s]2025-03-17 11:01:53,508 - sciml.model.deeponet.deeponet - INFO - Epoch 30/300\n",
      "2025-03-17 11:01:53,509 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.193386\n",
      "2025-03-17 11:01:53,510 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.200715\n",
      "Training progress:  10%|█         | 30/300 [00:05<00:47,  5.70it/s]2025-03-17 11:01:53,683 - sciml.model.deeponet.deeponet - INFO - Epoch 31/300\n",
      "2025-03-17 11:01:53,683 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.188415\n",
      "2025-03-17 11:01:53,684 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.197475\n",
      "Training progress:  10%|█         | 31/300 [00:05<00:47,  5.71it/s]2025-03-17 11:01:53,857 - sciml.model.deeponet.deeponet - INFO - Epoch 32/300\n",
      "2025-03-17 11:01:53,858 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.184236\n",
      "2025-03-17 11:01:53,859 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.194675\n",
      "Training progress:  11%|█         | 32/300 [00:05<00:46,  5.71it/s]2025-03-17 11:01:54,032 - sciml.model.deeponet.deeponet - INFO - Epoch 33/300\n",
      "2025-03-17 11:01:54,032 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.180534\n",
      "2025-03-17 11:01:54,033 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.192001\n",
      "Training progress:  11%|█         | 33/300 [00:06<00:46,  5.72it/s]2025-03-17 11:01:54,208 - sciml.model.deeponet.deeponet - INFO - Epoch 34/300\n",
      "2025-03-17 11:01:54,209 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.176553\n",
      "2025-03-17 11:01:54,209 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.189729\n",
      "Training progress:  11%|█▏        | 34/300 [00:06<00:46,  5.71it/s]2025-03-17 11:01:54,383 - sciml.model.deeponet.deeponet - INFO - Epoch 35/300\n",
      "2025-03-17 11:01:54,383 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.172791\n",
      "2025-03-17 11:01:54,384 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.188348\n",
      "Training progress:  12%|█▏        | 35/300 [00:06<00:46,  5.72it/s]2025-03-17 11:01:54,721 - sciml.model.deeponet.deeponet - INFO - Epoch 36/300\n",
      "2025-03-17 11:01:54,722 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.169478\n",
      "2025-03-17 11:01:54,722 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.187717\n",
      "Training progress:  12%|█▏        | 36/300 [00:06<00:59,  4.46it/s]2025-03-17 11:01:54,889 - sciml.model.deeponet.deeponet - INFO - Epoch 37/300\n",
      "2025-03-17 11:01:54,890 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.166399\n",
      "2025-03-17 11:01:54,891 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.186703\n",
      "Training progress:  12%|█▏        | 37/300 [00:06<00:54,  4.82it/s]2025-03-17 11:01:55,063 - sciml.model.deeponet.deeponet - INFO - Epoch 38/300\n",
      "2025-03-17 11:01:55,064 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.163765\n",
      "2025-03-17 11:01:55,065 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.184176\n",
      "Training progress:  13%|█▎        | 38/300 [00:07<00:51,  5.07it/s]2025-03-17 11:01:55,238 - sciml.model.deeponet.deeponet - INFO - Epoch 39/300\n",
      "2025-03-17 11:01:55,239 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.161182\n",
      "2025-03-17 11:01:55,239 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.180684\n",
      "Training progress:  13%|█▎        | 39/300 [00:07<00:49,  5.25it/s]2025-03-17 11:01:55,428 - sciml.model.deeponet.deeponet - INFO - Epoch 40/300\n",
      "2025-03-17 11:01:55,429 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.158812\n",
      "2025-03-17 11:01:55,429 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.177736\n",
      "Training progress:  13%|█▎        | 40/300 [00:07<00:49,  5.26it/s]2025-03-17 11:01:55,608 - sciml.model.deeponet.deeponet - INFO - Epoch 41/300\n",
      "2025-03-17 11:01:55,609 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.156925\n",
      "2025-03-17 11:01:55,610 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.175994\n",
      "Training progress:  14%|█▎        | 41/300 [00:07<00:48,  5.33it/s]2025-03-17 11:01:55,782 - sciml.model.deeponet.deeponet - INFO - Epoch 42/300\n",
      "2025-03-17 11:01:55,782 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.155273\n",
      "2025-03-17 11:01:55,783 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.174957\n",
      "Training progress:  14%|█▍        | 42/300 [00:07<00:47,  5.46it/s]2025-03-17 11:01:55,948 - sciml.model.deeponet.deeponet - INFO - Epoch 43/300\n",
      "2025-03-17 11:01:55,949 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.153901\n",
      "2025-03-17 11:01:55,949 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.173602\n",
      "Training progress:  14%|█▍        | 43/300 [00:07<00:45,  5.62it/s]2025-03-17 11:01:56,129 - sciml.model.deeponet.deeponet - INFO - Epoch 44/300\n",
      "2025-03-17 11:01:56,130 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.152671\n",
      "2025-03-17 11:01:56,130 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.171673\n",
      "Training progress:  15%|█▍        | 44/300 [00:08<00:45,  5.59it/s]2025-03-17 11:01:56,302 - sciml.model.deeponet.deeponet - INFO - Epoch 45/300\n",
      "2025-03-17 11:01:56,302 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.151513\n",
      "2025-03-17 11:01:56,303 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.169784\n",
      "Training progress:  15%|█▌        | 45/300 [00:08<00:45,  5.64it/s]2025-03-17 11:01:56,478 - sciml.model.deeponet.deeponet - INFO - Epoch 46/300\n",
      "2025-03-17 11:01:56,479 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.150587\n",
      "2025-03-17 11:01:56,479 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.168499\n",
      "Training progress:  15%|█▌        | 46/300 [00:08<00:44,  5.66it/s]2025-03-17 11:01:56,657 - sciml.model.deeponet.deeponet - INFO - Epoch 47/300\n",
      "2025-03-17 11:01:56,658 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.149760\n",
      "2025-03-17 11:01:56,659 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.167686\n",
      "Training progress:  16%|█▌        | 47/300 [00:08<00:44,  5.63it/s]2025-03-17 11:01:56,831 - sciml.model.deeponet.deeponet - INFO - Epoch 48/300\n",
      "2025-03-17 11:01:56,832 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.148956\n",
      "2025-03-17 11:01:56,832 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.166666\n",
      "Training progress:  16%|█▌        | 48/300 [00:08<00:44,  5.67it/s]2025-03-17 11:01:57,006 - sciml.model.deeponet.deeponet - INFO - Epoch 49/300\n",
      "2025-03-17 11:01:57,006 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.148199\n",
      "2025-03-17 11:01:57,007 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.164984\n",
      "Training progress:  16%|█▋        | 49/300 [00:08<00:44,  5.68it/s]2025-03-17 11:01:57,183 - sciml.model.deeponet.deeponet - INFO - Epoch 50/300\n",
      "2025-03-17 11:01:57,184 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.147378\n",
      "2025-03-17 11:01:57,184 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.163325\n",
      "Training progress:  17%|█▋        | 50/300 [00:09<00:44,  5.67it/s]2025-03-17 11:01:57,357 - sciml.model.deeponet.deeponet - INFO - Epoch 51/300\n",
      "2025-03-17 11:01:57,358 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.146559\n",
      "2025-03-17 11:01:57,358 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.162247\n",
      "Training progress:  17%|█▋        | 51/300 [00:09<00:43,  5.69it/s]2025-03-17 11:01:57,534 - sciml.model.deeponet.deeponet - INFO - Epoch 52/300\n",
      "2025-03-17 11:01:57,534 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.145689\n",
      "2025-03-17 11:01:57,535 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.161472\n",
      "Training progress:  17%|█▋        | 52/300 [00:09<00:43,  5.69it/s]2025-03-17 11:01:57,705 - sciml.model.deeponet.deeponet - INFO - Epoch 53/300\n",
      "2025-03-17 11:01:57,705 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.144825\n",
      "2025-03-17 11:01:57,706 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.160399\n",
      "Training progress:  18%|█▊        | 53/300 [00:09<00:43,  5.73it/s]2025-03-17 11:01:57,875 - sciml.model.deeponet.deeponet - INFO - Epoch 54/300\n",
      "2025-03-17 11:01:57,876 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.143964\n",
      "2025-03-17 11:01:57,877 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.158975\n",
      "Training progress:  18%|█▊        | 54/300 [00:09<00:42,  5.77it/s]2025-03-17 11:01:58,049 - sciml.model.deeponet.deeponet - INFO - Epoch 55/300\n",
      "2025-03-17 11:01:58,050 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.143107\n",
      "2025-03-17 11:01:58,051 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.157991\n",
      "Training progress:  18%|█▊        | 55/300 [00:10<00:42,  5.75it/s]2025-03-17 11:01:58,226 - sciml.model.deeponet.deeponet - INFO - Epoch 56/300\n",
      "2025-03-17 11:01:58,227 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.142273\n",
      "2025-03-17 11:01:58,228 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.157388\n",
      "Training progress:  19%|█▊        | 56/300 [00:10<00:42,  5.73it/s]2025-03-17 11:01:58,400 - sciml.model.deeponet.deeponet - INFO - Epoch 57/300\n",
      "2025-03-17 11:01:58,401 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.141455\n",
      "2025-03-17 11:01:58,402 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.156253\n",
      "Training progress:  19%|█▉        | 57/300 [00:10<00:42,  5.74it/s]2025-03-17 11:01:58,573 - sciml.model.deeponet.deeponet - INFO - Epoch 58/300\n",
      "2025-03-17 11:01:58,573 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.140619\n",
      "2025-03-17 11:01:58,574 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.154909\n",
      "Training progress:  19%|█▉        | 58/300 [00:10<00:42,  5.75it/s]2025-03-17 11:01:58,747 - sciml.model.deeponet.deeponet - INFO - Epoch 59/300\n",
      "2025-03-17 11:01:58,748 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.139790\n",
      "2025-03-17 11:01:58,748 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.154075\n",
      "Training progress:  20%|█▉        | 59/300 [00:10<00:41,  5.75it/s]2025-03-17 11:01:58,933 - sciml.model.deeponet.deeponet - INFO - Epoch 60/300\n",
      "2025-03-17 11:01:58,933 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.138960\n",
      "2025-03-17 11:01:58,934 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.153513\n",
      "Training progress:  20%|██        | 60/300 [00:10<00:42,  5.63it/s]2025-03-17 11:01:59,109 - sciml.model.deeponet.deeponet - INFO - Epoch 61/300\n",
      "2025-03-17 11:01:59,110 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.138176\n",
      "2025-03-17 11:01:59,110 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.152663\n",
      "Training progress:  20%|██        | 61/300 [00:11<00:42,  5.65it/s]2025-03-17 11:01:59,294 - sciml.model.deeponet.deeponet - INFO - Epoch 62/300\n",
      "2025-03-17 11:01:59,295 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.137385\n",
      "2025-03-17 11:01:59,295 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.151987\n",
      "Training progress:  21%|██        | 62/300 [00:11<00:42,  5.57it/s]2025-03-17 11:01:59,476 - sciml.model.deeponet.deeponet - INFO - Epoch 63/300\n",
      "2025-03-17 11:01:59,477 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.136630\n",
      "2025-03-17 11:01:59,477 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.151800\n",
      "Training progress:  21%|██        | 63/300 [00:11<00:42,  5.55it/s]2025-03-17 11:01:59,648 - sciml.model.deeponet.deeponet - INFO - Epoch 64/300\n",
      "2025-03-17 11:01:59,649 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.135883\n",
      "2025-03-17 11:01:59,650 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.151476\n",
      "Training progress:  21%|██▏       | 64/300 [00:11<00:41,  5.62it/s]2025-03-17 11:01:59,827 - sciml.model.deeponet.deeponet - INFO - Epoch 65/300\n",
      "2025-03-17 11:01:59,827 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.135149\n",
      "2025-03-17 11:01:59,828 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.150985\n",
      "Training progress:  22%|██▏       | 65/300 [00:11<00:41,  5.62it/s]2025-03-17 11:01:59,999 - sciml.model.deeponet.deeponet - INFO - Epoch 66/300\n",
      "2025-03-17 11:02:00,000 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.134420\n",
      "2025-03-17 11:02:00,000 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.150713\n",
      "Training progress:  22%|██▏       | 66/300 [00:11<00:41,  5.67it/s]2025-03-17 11:02:00,178 - sciml.model.deeponet.deeponet - INFO - Epoch 67/300\n",
      "2025-03-17 11:02:00,179 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.133689\n",
      "2025-03-17 11:02:00,180 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.150339\n",
      "Training progress:  22%|██▏       | 67/300 [00:12<00:41,  5.64it/s]2025-03-17 11:02:00,353 - sciml.model.deeponet.deeponet - INFO - Epoch 68/300\n",
      "2025-03-17 11:02:00,354 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.132970\n",
      "2025-03-17 11:02:00,354 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.149915\n",
      "Training progress:  23%|██▎       | 68/300 [00:12<00:40,  5.67it/s]2025-03-17 11:02:00,527 - sciml.model.deeponet.deeponet - INFO - Epoch 69/300\n",
      "2025-03-17 11:02:00,528 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.132236\n",
      "2025-03-17 11:02:00,528 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.149523\n",
      "Training progress:  23%|██▎       | 69/300 [00:12<00:40,  5.69it/s]2025-03-17 11:02:00,702 - sciml.model.deeponet.deeponet - INFO - Epoch 70/300\n",
      "2025-03-17 11:02:00,703 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.131478\n",
      "2025-03-17 11:02:00,703 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.148995\n",
      "Training progress:  23%|██▎       | 70/300 [00:12<00:40,  5.70it/s]2025-03-17 11:02:00,887 - sciml.model.deeponet.deeponet - INFO - Epoch 71/300\n",
      "2025-03-17 11:02:00,888 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.130723\n",
      "2025-03-17 11:02:00,888 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.148502\n",
      "Training progress:  24%|██▎       | 71/300 [00:12<00:40,  5.61it/s]2025-03-17 11:02:01,070 - sciml.model.deeponet.deeponet - INFO - Epoch 72/300\n",
      "2025-03-17 11:02:01,070 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.129954\n",
      "2025-03-17 11:02:01,071 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.147927\n",
      "Training progress:  24%|██▍       | 72/300 [00:13<00:40,  5.57it/s]2025-03-17 11:02:01,248 - sciml.model.deeponet.deeponet - INFO - Epoch 73/300\n",
      "2025-03-17 11:02:01,249 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.129207\n",
      "2025-03-17 11:02:01,250 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.147286\n",
      "Training progress:  24%|██▍       | 73/300 [00:13<00:40,  5.58it/s]2025-03-17 11:02:01,431 - sciml.model.deeponet.deeponet - INFO - Epoch 74/300\n",
      "2025-03-17 11:02:01,432 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.128454\n",
      "2025-03-17 11:02:01,433 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.146439\n",
      "Training progress:  25%|██▍       | 74/300 [00:13<00:40,  5.54it/s]2025-03-17 11:02:01,612 - sciml.model.deeponet.deeponet - INFO - Epoch 75/300\n",
      "2025-03-17 11:02:01,613 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.127686\n",
      "2025-03-17 11:02:01,614 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.145858\n",
      "Training progress:  25%|██▌       | 75/300 [00:13<00:40,  5.54it/s]2025-03-17 11:02:01,784 - sciml.model.deeponet.deeponet - INFO - Epoch 76/300\n",
      "2025-03-17 11:02:01,785 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.126918\n",
      "2025-03-17 11:02:01,786 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.145195\n",
      "Training progress:  25%|██▌       | 76/300 [00:13<00:39,  5.62it/s]2025-03-17 11:02:01,973 - sciml.model.deeponet.deeponet - INFO - Epoch 77/300\n",
      "2025-03-17 11:02:01,974 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.126122\n",
      "2025-03-17 11:02:01,974 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.144504\n",
      "Training progress:  26%|██▌       | 77/300 [00:13<00:40,  5.52it/s]2025-03-17 11:02:02,164 - sciml.model.deeponet.deeponet - INFO - Epoch 78/300\n",
      "2025-03-17 11:02:02,165 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.125323\n",
      "2025-03-17 11:02:02,166 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.144123\n",
      "Training progress:  26%|██▌       | 78/300 [00:14<00:40,  5.43it/s]2025-03-17 11:02:02,354 - sciml.model.deeponet.deeponet - INFO - Epoch 79/300\n",
      "2025-03-17 11:02:02,355 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.124535\n",
      "2025-03-17 11:02:02,355 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.143298\n",
      "Training progress:  26%|██▋       | 79/300 [00:14<00:41,  5.38it/s]2025-03-17 11:02:02,526 - sciml.model.deeponet.deeponet - INFO - Epoch 80/300\n",
      "2025-03-17 11:02:02,527 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.123727\n",
      "2025-03-17 11:02:02,528 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.142660\n",
      "Training progress:  27%|██▋       | 80/300 [00:14<00:40,  5.50it/s]2025-03-17 11:02:02,706 - sciml.model.deeponet.deeponet - INFO - Epoch 81/300\n",
      "2025-03-17 11:02:02,707 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.122896\n",
      "2025-03-17 11:02:02,707 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.141844\n",
      "Training progress:  27%|██▋       | 81/300 [00:14<00:39,  5.52it/s]2025-03-17 11:02:02,879 - sciml.model.deeponet.deeponet - INFO - Epoch 82/300\n",
      "2025-03-17 11:02:02,880 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.122053\n",
      "2025-03-17 11:02:02,880 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.140953\n",
      "Training progress:  27%|██▋       | 82/300 [00:14<00:38,  5.60it/s]2025-03-17 11:02:03,055 - sciml.model.deeponet.deeponet - INFO - Epoch 83/300\n",
      "2025-03-17 11:02:03,055 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.121203\n",
      "2025-03-17 11:02:03,056 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.140325\n",
      "Training progress:  28%|██▊       | 83/300 [00:15<00:38,  5.62it/s]2025-03-17 11:02:03,226 - sciml.model.deeponet.deeponet - INFO - Epoch 84/300\n",
      "2025-03-17 11:02:03,226 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.120346\n",
      "2025-03-17 11:02:03,227 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.139272\n",
      "Training progress:  28%|██▊       | 84/300 [00:15<00:37,  5.69it/s]2025-03-17 11:02:03,398 - sciml.model.deeponet.deeponet - INFO - Epoch 85/300\n",
      "2025-03-17 11:02:03,399 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.119497\n",
      "2025-03-17 11:02:03,400 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.139230\n",
      "Training progress:  28%|██▊       | 85/300 [00:15<00:37,  5.71it/s]2025-03-17 11:02:03,572 - sciml.model.deeponet.deeponet - INFO - Epoch 86/300\n",
      "2025-03-17 11:02:03,573 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.118721\n",
      "2025-03-17 11:02:03,573 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.137413\n",
      "Training progress:  29%|██▊       | 86/300 [00:15<00:37,  5.73it/s]2025-03-17 11:02:03,735 - sciml.model.deeponet.deeponet - INFO - Epoch 87/300\n",
      "2025-03-17 11:02:03,736 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.118275\n",
      "2025-03-17 11:02:03,736 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.140063\n",
      "Training progress:  29%|██▉       | 87/300 [00:15<00:36,  5.85it/s]2025-03-17 11:02:03,912 - sciml.model.deeponet.deeponet - INFO - Epoch 88/300\n",
      "2025-03-17 11:02:03,912 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.118705\n",
      "2025-03-17 11:02:03,913 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.136271\n",
      "Training progress:  29%|██▉       | 88/300 [00:15<00:36,  5.79it/s]2025-03-17 11:02:04,075 - sciml.model.deeponet.deeponet - INFO - Epoch 89/300\n",
      "2025-03-17 11:02:04,076 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.117839\n",
      "2025-03-17 11:02:04,076 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.137205\n",
      "Training progress:  30%|██▉       | 89/300 [00:16<00:35,  5.89it/s]2025-03-17 11:02:04,238 - sciml.model.deeponet.deeponet - INFO - Epoch 90/300\n",
      "2025-03-17 11:02:04,239 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.115801\n",
      "2025-03-17 11:02:04,239 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.136229\n",
      "Training progress:  30%|███       | 90/300 [00:16<00:35,  5.96it/s]2025-03-17 11:02:04,407 - sciml.model.deeponet.deeponet - INFO - Epoch 91/300\n",
      "2025-03-17 11:02:04,407 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.114831\n",
      "2025-03-17 11:02:04,408 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.134391\n",
      "Training progress:  30%|███       | 91/300 [00:16<00:35,  5.95it/s]2025-03-17 11:02:04,575 - sciml.model.deeponet.deeponet - INFO - Epoch 92/300\n",
      "2025-03-17 11:02:04,576 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.115301\n",
      "2025-03-17 11:02:04,577 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.135915\n",
      "Training progress:  31%|███       | 92/300 [00:16<00:35,  5.94it/s]2025-03-17 11:02:04,753 - sciml.model.deeponet.deeponet - INFO - Epoch 93/300\n",
      "2025-03-17 11:02:04,753 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.114094\n",
      "2025-03-17 11:02:04,754 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.133859\n",
      "Training progress:  31%|███       | 93/300 [00:16<00:35,  5.85it/s]2025-03-17 11:02:04,928 - sciml.model.deeponet.deeponet - INFO - Epoch 94/300\n",
      "2025-03-17 11:02:04,928 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.112553\n",
      "2025-03-17 11:02:04,929 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.132347\n",
      "Training progress:  31%|███▏      | 94/300 [00:16<00:35,  5.81it/s]2025-03-17 11:02:05,104 - sciml.model.deeponet.deeponet - INFO - Epoch 95/300\n",
      "2025-03-17 11:02:05,105 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.113133\n",
      "2025-03-17 11:02:05,105 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.133693\n",
      "Training progress:  32%|███▏      | 95/300 [00:17<00:35,  5.76it/s]2025-03-17 11:02:05,276 - sciml.model.deeponet.deeponet - INFO - Epoch 96/300\n",
      "2025-03-17 11:02:05,277 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.112018\n",
      "2025-03-17 11:02:05,278 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.131703\n",
      "Training progress:  32%|███▏      | 96/300 [00:17<00:35,  5.78it/s]2025-03-17 11:02:05,471 - sciml.model.deeponet.deeponet - INFO - Epoch 97/300\n",
      "2025-03-17 11:02:05,472 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.110572\n",
      "2025-03-17 11:02:05,474 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.130034\n",
      "Training progress:  32%|███▏      | 97/300 [00:17<00:36,  5.55it/s]2025-03-17 11:02:05,652 - sciml.model.deeponet.deeponet - INFO - Epoch 98/300\n",
      "2025-03-17 11:02:05,653 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.111128\n",
      "2025-03-17 11:02:05,654 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.131196\n",
      "Training progress:  33%|███▎      | 98/300 [00:17<00:36,  5.56it/s]2025-03-17 11:02:05,829 - sciml.model.deeponet.deeponet - INFO - Epoch 99/300\n",
      "2025-03-17 11:02:05,830 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.109977\n",
      "2025-03-17 11:02:05,830 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.129440\n",
      "Training progress:  33%|███▎      | 99/300 [00:17<00:35,  5.59it/s]2025-03-17 11:02:05,998 - sciml.model.deeponet.deeponet - INFO - Epoch 100/300\n",
      "2025-03-17 11:02:05,999 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.108732\n",
      "2025-03-17 11:02:06,000 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.127847\n",
      "Training progress:  33%|███▎      | 100/300 [00:17<00:35,  5.68it/s]2025-03-17 11:02:06,168 - sciml.model.deeponet.deeponet - INFO - Epoch 101/300\n",
      "2025-03-17 11:02:06,168 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.109317\n",
      "2025-03-17 11:02:06,169 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.129126\n",
      "Training progress:  34%|███▎      | 101/300 [00:18<00:34,  5.74it/s]2025-03-17 11:02:06,340 - sciml.model.deeponet.deeponet - INFO - Epoch 102/300\n",
      "2025-03-17 11:02:06,341 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.108197\n",
      "2025-03-17 11:02:06,341 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.127415\n",
      "Training progress:  34%|███▍      | 102/300 [00:18<00:34,  5.76it/s]2025-03-17 11:02:06,514 - sciml.model.deeponet.deeponet - INFO - Epoch 103/300\n",
      "2025-03-17 11:02:06,515 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.106969\n",
      "2025-03-17 11:02:06,516 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.125899\n",
      "Training progress:  34%|███▍      | 103/300 [00:18<00:34,  5.76it/s]2025-03-17 11:02:06,692 - sciml.model.deeponet.deeponet - INFO - Epoch 104/300\n",
      "2025-03-17 11:02:06,692 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.107532\n",
      "2025-03-17 11:02:06,693 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.127262\n",
      "Training progress:  35%|███▍      | 104/300 [00:18<00:34,  5.72it/s]2025-03-17 11:02:06,862 - sciml.model.deeponet.deeponet - INFO - Epoch 105/300\n",
      "2025-03-17 11:02:06,862 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.106533\n",
      "2025-03-17 11:02:06,863 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.125415\n",
      "Training progress:  35%|███▌      | 105/300 [00:18<00:33,  5.77it/s]2025-03-17 11:02:07,042 - sciml.model.deeponet.deeponet - INFO - Epoch 106/300\n",
      "2025-03-17 11:02:07,043 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.105271\n",
      "2025-03-17 11:02:07,044 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.123866\n",
      "Training progress:  35%|███▌      | 106/300 [00:19<00:34,  5.70it/s]2025-03-17 11:02:07,214 - sciml.model.deeponet.deeponet - INFO - Epoch 107/300\n",
      "2025-03-17 11:02:07,215 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.105853\n",
      "2025-03-17 11:02:07,216 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.125496\n",
      "Training progress:  36%|███▌      | 107/300 [00:19<00:33,  5.73it/s]2025-03-17 11:02:07,382 - sciml.model.deeponet.deeponet - INFO - Epoch 108/300\n",
      "2025-03-17 11:02:07,383 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.105045\n",
      "2025-03-17 11:02:07,384 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.123274\n",
      "Training progress:  36%|███▌      | 108/300 [00:19<00:33,  5.80it/s]2025-03-17 11:02:07,550 - sciml.model.deeponet.deeponet - INFO - Epoch 109/300\n",
      "2025-03-17 11:02:07,551 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.103638\n",
      "2025-03-17 11:02:07,551 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.121860\n",
      "Training progress:  36%|███▋      | 109/300 [00:19<00:32,  5.84it/s]2025-03-17 11:02:07,721 - sciml.model.deeponet.deeponet - INFO - Epoch 110/300\n",
      "2025-03-17 11:02:07,722 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.104247\n",
      "2025-03-17 11:02:07,722 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.123900\n",
      "Training progress:  37%|███▋      | 110/300 [00:19<00:32,  5.85it/s]2025-03-17 11:02:07,895 - sciml.model.deeponet.deeponet - INFO - Epoch 111/300\n",
      "2025-03-17 11:02:07,896 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.103805\n",
      "2025-03-17 11:02:07,896 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.121049\n",
      "Training progress:  37%|███▋      | 111/300 [00:19<00:32,  5.82it/s]2025-03-17 11:02:08,065 - sciml.model.deeponet.deeponet - INFO - Epoch 112/300\n",
      "2025-03-17 11:02:08,066 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.102116\n",
      "2025-03-17 11:02:08,066 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.119834\n",
      "Training progress:  37%|███▋      | 112/300 [00:20<00:32,  5.83it/s]2025-03-17 11:02:08,238 - sciml.model.deeponet.deeponet - INFO - Epoch 113/300\n",
      "2025-03-17 11:02:08,239 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.102700\n",
      "2025-03-17 11:02:08,239 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.122700\n",
      "Training progress:  38%|███▊      | 113/300 [00:20<00:32,  5.82it/s]2025-03-17 11:02:08,412 - sciml.model.deeponet.deeponet - INFO - Epoch 114/300\n",
      "2025-03-17 11:02:08,413 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.102923\n",
      "2025-03-17 11:02:08,413 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.118975\n",
      "Training progress:  38%|███▊      | 114/300 [00:20<00:32,  5.80it/s]2025-03-17 11:02:08,589 - sciml.model.deeponet.deeponet - INFO - Epoch 115/300\n",
      "2025-03-17 11:02:08,590 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.100815\n",
      "2025-03-17 11:02:08,590 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.117976\n",
      "Training progress:  38%|███▊      | 115/300 [00:20<00:32,  5.75it/s]2025-03-17 11:02:08,761 - sciml.model.deeponet.deeponet - INFO - Epoch 116/300\n",
      "2025-03-17 11:02:08,761 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.101323\n",
      "2025-03-17 11:02:08,762 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.121422\n",
      "Training progress:  39%|███▊      | 116/300 [00:20<00:31,  5.78it/s]2025-03-17 11:02:08,934 - sciml.model.deeponet.deeponet - INFO - Epoch 117/300\n",
      "2025-03-17 11:02:08,935 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.102107\n",
      "2025-03-17 11:02:08,935 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.117016\n",
      "Training progress:  39%|███▉      | 117/300 [00:20<00:31,  5.77it/s]2025-03-17 11:02:06,631 - sciml.model.deeponet.deeponet - INFO - Epoch 118/300\n",
      "2025-03-17 11:02:06,632 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.099656\n",
      "2025-03-17 11:02:06,632 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.116108\n",
      "2025-03-17 11:02:06,799 - sciml.model.deeponet.deeponet - INFO - Epoch 119/300\n",
      "2025-03-17 11:02:06,800 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.100228\n",
      "2025-03-17 11:02:06,800 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.120064\n",
      "2025-03-17 11:02:06,964 - sciml.model.deeponet.deeponet - INFO - Epoch 120/300\n",
      "2025-03-17 11:02:06,965 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.101347\n",
      "2025-03-17 11:02:06,965 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.115274\n",
      "2025-03-17 11:02:07,130 - sciml.model.deeponet.deeponet - INFO - Epoch 121/300\n",
      "2025-03-17 11:02:07,130 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.098618\n",
      "2025-03-17 11:02:07,131 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.114499\n",
      "2025-03-17 11:02:07,298 - sciml.model.deeponet.deeponet - INFO - Epoch 122/300\n",
      "2025-03-17 11:02:07,299 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.099461\n",
      "2025-03-17 11:02:07,300 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.118897\n",
      "2025-03-17 11:02:07,468 - sciml.model.deeponet.deeponet - INFO - Epoch 123/300\n",
      "2025-03-17 11:02:07,469 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.100701\n",
      "2025-03-17 11:02:07,470 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.114048\n",
      "2025-03-17 11:02:07,638 - sciml.model.deeponet.deeponet - INFO - Epoch 124/300\n",
      "2025-03-17 11:02:07,639 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.097620\n",
      "2025-03-17 11:02:07,639 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.113235\n",
      "2025-03-17 11:02:07,813 - sciml.model.deeponet.deeponet - INFO - Epoch 125/300\n",
      "2025-03-17 11:02:07,814 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.099450\n",
      "2025-03-17 11:02:07,815 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.118064\n",
      "2025-03-17 11:02:07,988 - sciml.model.deeponet.deeponet - INFO - Epoch 126/300\n",
      "2025-03-17 11:02:07,989 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.100337\n",
      "2025-03-17 11:02:07,990 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.113281\n",
      "2025-03-17 11:02:08,159 - sciml.model.deeponet.deeponet - INFO - Epoch 127/300\n",
      "2025-03-17 11:02:08,160 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.096877\n",
      "2025-03-17 11:02:08,161 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.112525\n",
      "2025-03-17 11:02:08,333 - sciml.model.deeponet.deeponet - INFO - Epoch 128/300\n",
      "2025-03-17 11:02:08,333 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.100758\n",
      "2025-03-17 11:02:08,334 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.116938\n",
      "2025-03-17 11:02:08,505 - sciml.model.deeponet.deeponet - INFO - Epoch 129/300\n",
      "2025-03-17 11:02:08,506 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.099708\n",
      "2025-03-17 11:02:08,507 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.114009\n",
      "2025-03-17 11:02:08,679 - sciml.model.deeponet.deeponet - INFO - Epoch 130/300\n",
      "2025-03-17 11:02:08,680 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.097270\n",
      "2025-03-17 11:02:08,680 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.112202\n",
      "2025-03-17 11:02:08,844 - sciml.model.deeponet.deeponet - INFO - Epoch 131/300\n",
      "2025-03-17 11:02:08,845 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.101243\n",
      "2025-03-17 11:02:08,845 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.112981\n",
      "2025-03-17 11:02:09,009 - sciml.model.deeponet.deeponet - INFO - Epoch 132/300\n",
      "2025-03-17 11:02:09,009 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.096621\n",
      "2025-03-17 11:02:09,009 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.114857\n",
      "2025-03-17 11:02:09,175 - sciml.model.deeponet.deeponet - INFO - Epoch 133/300\n",
      "2025-03-17 11:02:09,175 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.098214\n",
      "2025-03-17 11:02:09,176 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.110000\n",
      "Training progress:  44%|████▍     | 133/300 [00:21<00:05, 28.42it/s]2025-03-17 11:02:09,350 - sciml.model.deeponet.deeponet - INFO - Epoch 134/300\n",
      "2025-03-17 11:02:09,351 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.097060\n",
      "2025-03-17 11:02:09,351 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.109888\n",
      "2025-03-17 11:02:09,519 - sciml.model.deeponet.deeponet - INFO - Epoch 135/300\n",
      "2025-03-17 11:02:09,520 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.095775\n",
      "2025-03-17 11:02:09,520 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.113653\n",
      "2025-03-17 11:02:09,688 - sciml.model.deeponet.deeponet - INFO - Epoch 136/300\n",
      "2025-03-17 11:02:09,689 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.097212\n",
      "2025-03-17 11:02:09,689 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.110550\n",
      "Training progress:  45%|████▌     | 136/300 [00:21<00:09, 16.42it/s]2025-03-17 11:02:09,863 - sciml.model.deeponet.deeponet - INFO - Epoch 137/300\n",
      "2025-03-17 11:02:09,868 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.095127\n",
      "2025-03-17 11:02:09,869 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.109414\n",
      "2025-03-17 11:02:10,044 - sciml.model.deeponet.deeponet - INFO - Epoch 138/300\n",
      "2025-03-17 11:02:10,045 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.096948\n",
      "2025-03-17 11:02:10,046 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.110547\n",
      "Training progress:  46%|████▌     | 138/300 [00:22<00:12, 12.68it/s]2025-03-17 11:02:10,220 - sciml.model.deeponet.deeponet - INFO - Epoch 139/300\n",
      "2025-03-17 11:02:10,221 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.095172\n",
      "2025-03-17 11:02:10,222 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.110989\n",
      "2025-03-17 11:02:10,398 - sciml.model.deeponet.deeponet - INFO - Epoch 140/300\n",
      "2025-03-17 11:02:10,398 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.095586\n",
      "2025-03-17 11:02:10,399 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.108104\n",
      "Training progress:  47%|████▋     | 140/300 [00:22<00:15, 10.37it/s]2025-03-17 11:02:10,575 - sciml.model.deeponet.deeponet - INFO - Epoch 141/300\n",
      "2025-03-17 11:02:10,575 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.095408\n",
      "2025-03-17 11:02:10,576 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.108428\n",
      "2025-03-17 11:02:10,752 - sciml.model.deeponet.deeponet - INFO - Epoch 142/300\n",
      "2025-03-17 11:02:10,752 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.094323\n",
      "2025-03-17 11:02:10,753 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.110589\n",
      "Training progress:  47%|████▋     | 142/300 [00:22<00:17,  8.87it/s]2025-03-17 11:02:10,922 - sciml.model.deeponet.deeponet - INFO - Epoch 143/300\n",
      "2025-03-17 11:02:10,923 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.095059\n",
      "2025-03-17 11:02:10,923 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.108601\n",
      "2025-03-17 11:02:11,098 - sciml.model.deeponet.deeponet - INFO - Epoch 144/300\n",
      "2025-03-17 11:02:11,099 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.094066\n",
      "2025-03-17 11:02:11,099 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.107660\n",
      "Training progress:  48%|████▊     | 144/300 [00:23<00:19,  7.91it/s]2025-03-17 11:02:11,286 - sciml.model.deeponet.deeponet - INFO - Epoch 145/300\n",
      "2025-03-17 11:02:11,287 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.094523\n",
      "2025-03-17 11:02:11,288 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.108807\n",
      "Training progress:  48%|████▊     | 145/300 [00:23<00:20,  7.40it/s]2025-03-17 11:02:11,480 - sciml.model.deeponet.deeponet - INFO - Epoch 146/300\n",
      "2025-03-17 11:02:11,480 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.094073\n",
      "2025-03-17 11:02:11,481 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.108260\n",
      "Training progress:  49%|████▊     | 146/300 [00:23<00:22,  6.91it/s]2025-03-17 11:02:11,652 - sciml.model.deeponet.deeponet - INFO - Epoch 147/300\n",
      "2025-03-17 11:02:11,653 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.093826\n",
      "2025-03-17 11:02:11,654 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.106875\n",
      "Training progress:  49%|████▉     | 147/300 [00:23<00:22,  6.67it/s]2025-03-17 11:02:11,823 - sciml.model.deeponet.deeponet - INFO - Epoch 148/300\n",
      "2025-03-17 11:02:11,824 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.094042\n",
      "2025-03-17 11:02:11,825 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.107696\n",
      "Training progress:  49%|████▉     | 148/300 [00:23<00:23,  6.47it/s]2025-03-17 11:02:11,997 - sciml.model.deeponet.deeponet - INFO - Epoch 149/300\n",
      "2025-03-17 11:02:11,998 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.093316\n",
      "2025-03-17 11:02:11,999 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.108426\n",
      "Training progress:  50%|████▉     | 149/300 [00:23<00:24,  6.28it/s]2025-03-17 11:02:12,168 - sciml.model.deeponet.deeponet - INFO - Epoch 150/300\n",
      "2025-03-17 11:02:12,169 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.093587\n",
      "2025-03-17 11:02:12,170 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.106706\n",
      "Training progress:  50%|█████     | 150/300 [00:24<00:24,  6.17it/s]2025-03-17 11:02:12,349 - sciml.model.deeponet.deeponet - INFO - Epoch 151/300\n",
      "2025-03-17 11:02:12,349 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.093228\n",
      "2025-03-17 11:02:12,350 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.106233\n",
      "Training progress:  50%|█████     | 151/300 [00:24<00:24,  5.99it/s]2025-03-17 11:02:12,518 - sciml.model.deeponet.deeponet - INFO - Epoch 152/300\n",
      "2025-03-17 11:02:12,519 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.092930\n",
      "2025-03-17 11:02:12,519 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.107067\n",
      "Training progress:  51%|█████     | 152/300 [00:24<00:24,  5.97it/s]2025-03-17 11:02:12,687 - sciml.model.deeponet.deeponet - INFO - Epoch 153/300\n",
      "2025-03-17 11:02:12,688 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.093138\n",
      "2025-03-17 11:02:12,689 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.105766\n",
      "Training progress:  51%|█████     | 153/300 [00:24<00:24,  5.95it/s]2025-03-17 11:02:12,850 - sciml.model.deeponet.deeponet - INFO - Epoch 154/300\n",
      "2025-03-17 11:02:12,851 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.092693\n",
      "2025-03-17 11:02:12,852 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.105562\n",
      "Training progress:  51%|█████▏    | 154/300 [00:24<00:24,  6.00it/s]2025-03-17 11:02:13,015 - sciml.model.deeponet.deeponet - INFO - Epoch 155/300\n",
      "2025-03-17 11:02:13,016 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.092629\n",
      "2025-03-17 11:02:13,017 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.106612\n",
      "Training progress:  52%|█████▏    | 155/300 [00:25<00:24,  6.02it/s]2025-03-17 11:02:13,181 - sciml.model.deeponet.deeponet - INFO - Epoch 156/300\n",
      "2025-03-17 11:02:13,181 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.092614\n",
      "2025-03-17 11:02:13,182 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.105862\n",
      "Training progress:  52%|█████▏    | 156/300 [00:25<00:23,  6.03it/s]2025-03-17 11:02:13,344 - sciml.model.deeponet.deeponet - INFO - Epoch 157/300\n",
      "2025-03-17 11:02:13,345 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.092294\n",
      "2025-03-17 11:02:13,346 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.104945\n",
      "Training progress:  52%|█████▏    | 157/300 [00:25<00:23,  6.05it/s]2025-03-17 11:02:13,512 - sciml.model.deeponet.deeponet - INFO - Epoch 158/300\n",
      "2025-03-17 11:02:13,513 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.092306\n",
      "2025-03-17 11:02:13,513 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.105648\n",
      "Training progress:  53%|█████▎    | 158/300 [00:25<00:23,  6.03it/s]2025-03-17 11:02:13,680 - sciml.model.deeponet.deeponet - INFO - Epoch 159/300\n",
      "2025-03-17 11:02:13,681 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.092183\n",
      "2025-03-17 11:02:13,681 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.105077\n",
      "Training progress:  53%|█████▎    | 159/300 [00:25<00:23,  6.00it/s]2025-03-17 11:02:13,845 - sciml.model.deeponet.deeponet - INFO - Epoch 160/300\n",
      "2025-03-17 11:02:13,845 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.091913\n",
      "2025-03-17 11:02:13,846 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.104526\n",
      "Training progress:  53%|█████▎    | 160/300 [00:25<00:23,  6.03it/s]2025-03-17 11:02:14,005 - sciml.model.deeponet.deeponet - INFO - Epoch 161/300\n",
      "2025-03-17 11:02:14,006 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.091921\n",
      "2025-03-17 11:02:14,007 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.105377\n",
      "Training progress:  54%|█████▎    | 161/300 [00:25<00:22,  6.08it/s]2025-03-17 11:02:14,172 - sciml.model.deeponet.deeponet - INFO - Epoch 162/300\n",
      "2025-03-17 11:02:14,173 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.091814\n",
      "2025-03-17 11:02:14,173 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.104625\n",
      "Training progress:  54%|█████▍    | 162/300 [00:26<00:22,  6.05it/s]2025-03-17 11:02:14,335 - sciml.model.deeponet.deeponet - INFO - Epoch 163/300\n",
      "2025-03-17 11:02:14,336 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.091545\n",
      "2025-03-17 11:02:14,336 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.103706\n",
      "Training progress:  54%|█████▍    | 163/300 [00:26<00:22,  6.08it/s]2025-03-17 11:02:14,497 - sciml.model.deeponet.deeponet - INFO - Epoch 164/300\n",
      "2025-03-17 11:02:14,498 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.091583\n",
      "2025-03-17 11:02:14,498 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.104610\n",
      "Training progress:  55%|█████▍    | 164/300 [00:26<00:22,  6.11it/s]2025-03-17 11:02:14,658 - sciml.model.deeponet.deeponet - INFO - Epoch 165/300\n",
      "2025-03-17 11:02:14,658 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.091526\n",
      "2025-03-17 11:02:14,659 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.103673\n",
      "Training progress:  55%|█████▌    | 165/300 [00:26<00:21,  6.14it/s]2025-03-17 11:02:14,825 - sciml.model.deeponet.deeponet - INFO - Epoch 166/300\n",
      "2025-03-17 11:02:14,825 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.091179\n",
      "2025-03-17 11:02:14,826 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.103477\n",
      "Training progress:  55%|█████▌    | 166/300 [00:26<00:21,  6.09it/s]2025-03-17 11:02:14,992 - sciml.model.deeponet.deeponet - INFO - Epoch 167/300\n",
      "2025-03-17 11:02:14,993 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.091144\n",
      "2025-03-17 11:02:14,994 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.104340\n",
      "Training progress:  56%|█████▌    | 167/300 [00:26<00:21,  6.06it/s]2025-03-17 11:02:15,157 - sciml.model.deeponet.deeponet - INFO - Epoch 168/300\n",
      "2025-03-17 11:02:15,157 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.091160\n",
      "2025-03-17 11:02:15,158 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.103189\n",
      "Training progress:  56%|█████▌    | 168/300 [00:27<00:21,  6.06it/s]2025-03-17 11:02:15,322 - sciml.model.deeponet.deeponet - INFO - Epoch 169/300\n",
      "2025-03-17 11:02:15,322 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.090865\n",
      "2025-03-17 11:02:15,323 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.102924\n",
      "Training progress:  56%|█████▋    | 169/300 [00:27<00:21,  6.06it/s]2025-03-17 11:02:15,494 - sciml.model.deeponet.deeponet - INFO - Epoch 170/300\n",
      "2025-03-17 11:02:15,494 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.090750\n",
      "2025-03-17 11:02:15,495 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.103658\n",
      "Training progress:  57%|█████▋    | 170/300 [00:27<00:21,  5.99it/s]2025-03-17 11:02:15,662 - sciml.model.deeponet.deeponet - INFO - Epoch 171/300\n",
      "2025-03-17 11:02:15,663 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.090821\n",
      "2025-03-17 11:02:15,663 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.102425\n",
      "Training progress:  57%|█████▋    | 171/300 [00:27<00:21,  5.97it/s]2025-03-17 11:02:15,828 - sciml.model.deeponet.deeponet - INFO - Epoch 172/300\n",
      "2025-03-17 11:02:15,829 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.090669\n",
      "2025-03-17 11:02:15,829 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.103014\n",
      "Training progress:  57%|█████▋    | 172/300 [00:27<00:21,  5.99it/s]2025-03-17 11:02:15,992 - sciml.model.deeponet.deeponet - INFO - Epoch 173/300\n",
      "2025-03-17 11:02:15,993 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.090435\n",
      "2025-03-17 11:02:15,994 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.102682\n",
      "Training progress:  58%|█████▊    | 173/300 [00:27<00:21,  6.02it/s]2025-03-17 11:02:16,162 - sciml.model.deeponet.deeponet - INFO - Epoch 174/300\n",
      "2025-03-17 11:02:16,163 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.090293\n",
      "2025-03-17 11:02:16,164 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.102027\n",
      "Training progress:  58%|█████▊    | 174/300 [00:28<00:21,  5.97it/s]2025-03-17 11:02:16,331 - sciml.model.deeponet.deeponet - INFO - Epoch 175/300\n",
      "2025-03-17 11:02:16,332 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.090268\n",
      "2025-03-17 11:02:16,332 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.102922\n",
      "Training progress:  58%|█████▊    | 175/300 [00:28<00:20,  5.96it/s]2025-03-17 11:02:16,501 - sciml.model.deeponet.deeponet - INFO - Epoch 176/300\n",
      "2025-03-17 11:02:16,502 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.090257\n",
      "2025-03-17 11:02:16,503 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.101829\n",
      "Training progress:  59%|█████▊    | 176/300 [00:28<00:20,  5.93it/s]2025-03-17 11:02:16,673 - sciml.model.deeponet.deeponet - INFO - Epoch 177/300\n",
      "2025-03-17 11:02:16,674 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.090066\n",
      "2025-03-17 11:02:16,675 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.102304\n",
      "Training progress:  59%|█████▉    | 177/300 [00:28<00:20,  5.90it/s]2025-03-17 11:02:16,847 - sciml.model.deeponet.deeponet - INFO - Epoch 178/300\n",
      "2025-03-17 11:02:16,848 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.089860\n",
      "2025-03-17 11:02:16,848 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.102010\n",
      "Training progress:  59%|█████▉    | 178/300 [00:28<00:20,  5.86it/s]2025-03-17 11:02:17,020 - sciml.model.deeponet.deeponet - INFO - Epoch 179/300\n",
      "2025-03-17 11:02:17,020 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.089743\n",
      "2025-03-17 11:02:17,021 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.101502\n",
      "Training progress:  60%|█████▉    | 179/300 [00:29<00:20,  5.84it/s]2025-03-17 11:02:17,215 - sciml.model.deeponet.deeponet - INFO - Epoch 180/300\n",
      "2025-03-17 11:02:17,216 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.089656\n",
      "2025-03-17 11:02:17,216 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.101981\n",
      "Training progress:  60%|██████    | 180/300 [00:29<00:21,  5.60it/s]2025-03-17 11:02:17,382 - sciml.model.deeponet.deeponet - INFO - Epoch 181/300\n",
      "2025-03-17 11:02:17,383 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.089630\n",
      "2025-03-17 11:02:17,384 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.101036\n",
      "Training progress:  60%|██████    | 181/300 [00:29<00:20,  5.71it/s]2025-03-17 11:02:17,555 - sciml.model.deeponet.deeponet - INFO - Epoch 182/300\n",
      "2025-03-17 11:02:17,556 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.089565\n",
      "2025-03-17 11:02:17,557 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.101807\n",
      "Training progress:  61%|██████    | 182/300 [00:29<00:20,  5.73it/s]2025-03-17 11:02:17,728 - sciml.model.deeponet.deeponet - INFO - Epoch 183/300\n",
      "2025-03-17 11:02:17,728 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.089448\n",
      "2025-03-17 11:02:17,729 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.100881\n",
      "Training progress:  61%|██████    | 183/300 [00:29<00:20,  5.75it/s]2025-03-17 11:02:17,904 - sciml.model.deeponet.deeponet - INFO - Epoch 184/300\n",
      "2025-03-17 11:02:17,905 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.089312\n",
      "2025-03-17 11:02:17,906 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.101241\n",
      "Training progress:  61%|██████▏   | 184/300 [00:29<00:20,  5.72it/s]2025-03-17 11:02:18,069 - sciml.model.deeponet.deeponet - INFO - Epoch 185/300\n",
      "2025-03-17 11:02:18,070 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.089142\n",
      "2025-03-17 11:02:18,070 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.100797\n",
      "Training progress:  62%|██████▏   | 185/300 [00:30<00:19,  5.83it/s]2025-03-17 11:02:18,240 - sciml.model.deeponet.deeponet - INFO - Epoch 186/300\n",
      "2025-03-17 11:02:18,241 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.089018\n",
      "2025-03-17 11:02:18,241 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.100743\n",
      "Training progress:  62%|██████▏   | 186/300 [00:30<00:19,  5.84it/s]2025-03-17 11:02:18,408 - sciml.model.deeponet.deeponet - INFO - Epoch 187/300\n",
      "2025-03-17 11:02:18,409 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.088915\n",
      "2025-03-17 11:02:18,410 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.100791\n",
      "Training progress:  62%|██████▏   | 187/300 [00:30<00:19,  5.86it/s]2025-03-17 11:02:18,579 - sciml.model.deeponet.deeponet - INFO - Epoch 188/300\n",
      "2025-03-17 11:02:18,579 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.088816\n",
      "2025-03-17 11:02:18,580 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.100292\n",
      "Training progress:  63%|██████▎   | 188/300 [00:30<00:19,  5.87it/s]2025-03-17 11:02:18,751 - sciml.model.deeponet.deeponet - INFO - Epoch 189/300\n",
      "2025-03-17 11:02:18,752 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.088755\n",
      "2025-03-17 11:02:18,753 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.100716\n",
      "Training progress:  63%|██████▎   | 189/300 [00:30<00:18,  5.84it/s]2025-03-17 11:02:18,922 - sciml.model.deeponet.deeponet - INFO - Epoch 190/300\n",
      "2025-03-17 11:02:18,922 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.088688\n",
      "2025-03-17 11:02:18,923 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.099697\n",
      "Training progress:  63%|██████▎   | 190/300 [00:30<00:18,  5.85it/s]2025-03-17 11:02:19,095 - sciml.model.deeponet.deeponet - INFO - Epoch 191/300\n",
      "2025-03-17 11:02:19,095 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.088654\n",
      "2025-03-17 11:02:19,096 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.100796\n",
      "Training progress:  64%|██████▎   | 191/300 [00:31<00:18,  5.83it/s]2025-03-17 11:02:19,269 - sciml.model.deeponet.deeponet - INFO - Epoch 192/300\n",
      "2025-03-17 11:02:19,269 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.088721\n",
      "2025-03-17 11:02:19,270 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.099133\n",
      "Training progress:  64%|██████▍   | 192/300 [00:31<00:18,  5.81it/s]2025-03-17 11:02:19,434 - sciml.model.deeponet.deeponet - INFO - Epoch 193/300\n",
      "2025-03-17 11:02:19,435 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.088896\n",
      "2025-03-17 11:02:19,435 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.102078\n",
      "Training progress:  64%|██████▍   | 193/300 [00:31<00:18,  5.87it/s]2025-03-17 11:02:19,597 - sciml.model.deeponet.deeponet - INFO - Epoch 194/300\n",
      "2025-03-17 11:02:19,598 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.089600\n",
      "2025-03-17 11:02:19,599 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.099221\n",
      "Training progress:  65%|██████▍   | 194/300 [00:31<00:17,  5.95it/s]2025-03-17 11:02:19,765 - sciml.model.deeponet.deeponet - INFO - Epoch 195/300\n",
      "2025-03-17 11:02:19,766 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.090206\n",
      "2025-03-17 11:02:19,766 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.104801\n",
      "Training progress:  65%|██████▌   | 195/300 [00:31<00:17,  5.96it/s]2025-03-17 11:02:19,932 - sciml.model.deeponet.deeponet - INFO - Epoch 196/300\n",
      "2025-03-17 11:02:19,933 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.092118\n",
      "2025-03-17 11:02:19,933 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.098974\n",
      "Training progress:  65%|██████▌   | 196/300 [00:31<00:17,  5.96it/s]2025-03-17 11:02:20,101 - sciml.model.deeponet.deeponet - INFO - Epoch 197/300\n",
      "2025-03-17 11:02:20,102 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.090708\n",
      "2025-03-17 11:02:20,102 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.101565\n",
      "Training progress:  66%|██████▌   | 197/300 [00:32<00:17,  5.94it/s]2025-03-17 11:02:20,264 - sciml.model.deeponet.deeponet - INFO - Epoch 198/300\n",
      "2025-03-17 11:02:20,265 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.089457\n",
      "2025-03-17 11:02:20,266 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.098479\n",
      "Training progress:  66%|██████▌   | 198/300 [00:32<00:16,  6.00it/s]2025-03-17 11:02:20,430 - sciml.model.deeponet.deeponet - INFO - Epoch 199/300\n",
      "2025-03-17 11:02:20,431 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.087784\n",
      "2025-03-17 11:02:20,431 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.098254\n",
      "Training progress:  66%|██████▋   | 199/300 [00:32<00:16,  6.02it/s]2025-03-17 11:02:20,593 - sciml.model.deeponet.deeponet - INFO - Epoch 200/300\n",
      "2025-03-17 11:02:20,593 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.088226\n",
      "2025-03-17 11:02:20,594 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.101834\n",
      "Training progress:  67%|██████▋   | 200/300 [00:32<00:16,  6.05it/s]2025-03-17 11:02:20,764 - sciml.model.deeponet.deeponet - INFO - Epoch 201/300\n",
      "2025-03-17 11:02:20,765 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.089751\n",
      "2025-03-17 11:02:20,766 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.097817\n",
      "Training progress:  67%|██████▋   | 201/300 [00:32<00:16,  5.98it/s]2025-03-17 11:02:20,938 - sciml.model.deeponet.deeponet - INFO - Epoch 202/300\n",
      "2025-03-17 11:02:20,939 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.089100\n",
      "2025-03-17 11:02:20,939 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.099185\n",
      "Training progress:  67%|██████▋   | 202/300 [00:32<00:16,  5.92it/s]2025-03-17 11:02:21,110 - sciml.model.deeponet.deeponet - INFO - Epoch 203/300\n",
      "2025-03-17 11:02:21,110 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.087977\n",
      "2025-03-17 11:02:21,111 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.098172\n",
      "Training progress:  68%|██████▊   | 203/300 [00:33<00:16,  5.88it/s]2025-03-17 11:02:21,272 - sciml.model.deeponet.deeponet - INFO - Epoch 204/300\n",
      "2025-03-17 11:02:21,273 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.087313\n",
      "2025-03-17 11:02:21,274 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.097962\n",
      "Training progress:  68%|██████▊   | 204/300 [00:33<00:16,  5.96it/s]2025-03-17 11:02:21,437 - sciml.model.deeponet.deeponet - INFO - Epoch 205/300\n",
      "2025-03-17 11:02:21,437 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.087950\n",
      "2025-03-17 11:02:21,438 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.100909\n",
      "Training progress:  68%|██████▊   | 205/300 [00:33<00:15,  6.00it/s]2025-03-17 11:02:21,607 - sciml.model.deeponet.deeponet - INFO - Epoch 206/300\n",
      "2025-03-17 11:02:21,608 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.088636\n",
      "2025-03-17 11:02:21,609 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.097842\n",
      "Training progress:  69%|██████▊   | 206/300 [00:33<00:15,  5.96it/s]2025-03-17 11:02:21,774 - sciml.model.deeponet.deeponet - INFO - Epoch 207/300\n",
      "2025-03-17 11:02:21,775 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.087716\n",
      "2025-03-17 11:02:21,776 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.097947\n",
      "Training progress:  69%|██████▉   | 207/300 [00:33<00:15,  5.97it/s]2025-03-17 11:02:21,942 - sciml.model.deeponet.deeponet - INFO - Epoch 208/300\n",
      "2025-03-17 11:02:21,943 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.087006\n",
      "2025-03-17 11:02:21,943 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.098389\n",
      "Training progress:  69%|██████▉   | 208/300 [00:33<00:15,  5.97it/s]2025-03-17 11:02:22,117 - sciml.model.deeponet.deeponet - INFO - Epoch 209/300\n",
      "2025-03-17 11:02:22,118 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.087241\n",
      "2025-03-17 11:02:22,118 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.097148\n",
      "Training progress:  70%|██████▉   | 209/300 [00:34<00:15,  5.89it/s]2025-03-17 11:02:22,312 - sciml.model.deeponet.deeponet - INFO - Epoch 210/300\n",
      "2025-03-17 11:02:22,314 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.087618\n",
      "2025-03-17 11:02:22,314 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.098999\n",
      "Training progress:  70%|███████   | 210/300 [00:34<00:15,  5.63it/s]2025-03-17 11:02:22,489 - sciml.model.deeponet.deeponet - INFO - Epoch 211/300\n",
      "2025-03-17 11:02:22,490 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.087521\n",
      "2025-03-17 11:02:22,490 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.097226\n",
      "Training progress:  70%|███████   | 211/300 [00:34<00:15,  5.64it/s]2025-03-17 11:02:22,662 - sciml.model.deeponet.deeponet - INFO - Epoch 212/300\n",
      "2025-03-17 11:02:22,663 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.086842\n",
      "2025-03-17 11:02:22,663 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.097023\n",
      "Training progress:  71%|███████   | 212/300 [00:34<00:15,  5.69it/s]2025-03-17 11:02:22,830 - sciml.model.deeponet.deeponet - INFO - Epoch 213/300\n",
      "2025-03-17 11:02:22,831 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.086711\n",
      "2025-03-17 11:02:22,831 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.098103\n",
      "Training progress:  71%|███████   | 213/300 [00:34<00:15,  5.77it/s]2025-03-17 11:02:22,997 - sciml.model.deeponet.deeponet - INFO - Epoch 214/300\n",
      "2025-03-17 11:02:22,998 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.087049\n",
      "2025-03-17 11:02:22,999 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.096560\n",
      "Training progress:  71%|███████▏  | 214/300 [00:34<00:14,  5.82it/s]2025-03-17 11:02:23,164 - sciml.model.deeponet.deeponet - INFO - Epoch 215/300\n",
      "2025-03-17 11:02:23,165 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.086999\n",
      "2025-03-17 11:02:23,166 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.097736\n",
      "Training progress:  72%|███████▏  | 215/300 [00:35<00:14,  5.87it/s]2025-03-17 11:02:23,334 - sciml.model.deeponet.deeponet - INFO - Epoch 216/300\n",
      "2025-03-17 11:02:23,335 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.086678\n",
      "2025-03-17 11:02:23,336 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.096994\n",
      "Training progress:  72%|███████▏  | 216/300 [00:35<00:14,  5.87it/s]2025-03-17 11:02:23,501 - sciml.model.deeponet.deeponet - INFO - Epoch 217/300\n",
      "2025-03-17 11:02:23,502 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.086360\n",
      "2025-03-17 11:02:23,503 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.096673\n",
      "Training progress:  72%|███████▏  | 217/300 [00:35<00:14,  5.91it/s]2025-03-17 11:02:23,670 - sciml.model.deeponet.deeponet - INFO - Epoch 218/300\n",
      "2025-03-17 11:02:23,671 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.086384\n",
      "2025-03-17 11:02:23,671 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.097557\n",
      "Training progress:  73%|███████▎  | 218/300 [00:35<00:13,  5.92it/s]2025-03-17 11:02:23,837 - sciml.model.deeponet.deeponet - INFO - Epoch 219/300\n",
      "2025-03-17 11:02:23,838 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.086555\n",
      "2025-03-17 11:02:23,838 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.096228\n",
      "Training progress:  73%|███████▎  | 219/300 [00:35<00:13,  5.94it/s]2025-03-17 11:02:24,000 - sciml.model.deeponet.deeponet - INFO - Epoch 220/300\n",
      "2025-03-17 11:02:24,001 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.086448\n",
      "2025-03-17 11:02:24,001 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.097013\n",
      "Training progress:  73%|███████▎  | 220/300 [00:35<00:13,  5.99it/s]2025-03-17 11:02:24,168 - sciml.model.deeponet.deeponet - INFO - Epoch 221/300\n",
      "2025-03-17 11:02:24,169 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.086188\n",
      "2025-03-17 11:02:24,169 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.096482\n",
      "Training progress:  74%|███████▎  | 221/300 [00:36<00:13,  5.98it/s]2025-03-17 11:02:24,334 - sciml.model.deeponet.deeponet - INFO - Epoch 222/300\n",
      "2025-03-17 11:02:24,334 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.085988\n",
      "2025-03-17 11:02:24,335 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.096219\n",
      "Training progress:  74%|███████▍  | 222/300 [00:36<00:12,  6.00it/s]2025-03-17 11:02:24,498 - sciml.model.deeponet.deeponet - INFO - Epoch 223/300\n",
      "2025-03-17 11:02:24,499 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.085975\n",
      "2025-03-17 11:02:24,500 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.096928\n",
      "Training progress:  74%|███████▍  | 223/300 [00:36<00:12,  6.02it/s]2025-03-17 11:02:24,661 - sciml.model.deeponet.deeponet - INFO - Epoch 224/300\n",
      "2025-03-17 11:02:24,662 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.086065\n",
      "2025-03-17 11:02:24,663 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.095773\n",
      "Training progress:  75%|███████▍  | 224/300 [00:36<00:12,  6.05it/s]2025-03-17 11:02:24,825 - sciml.model.deeponet.deeponet - INFO - Epoch 225/300\n",
      "2025-03-17 11:02:24,826 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.086021\n",
      "2025-03-17 11:02:24,827 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.096581\n",
      "Training progress:  75%|███████▌  | 225/300 [00:36<00:12,  6.07it/s]2025-03-17 11:02:24,991 - sciml.model.deeponet.deeponet - INFO - Epoch 226/300\n",
      "2025-03-17 11:02:24,992 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.085877\n",
      "2025-03-17 11:02:24,993 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.095713\n",
      "Training progress:  75%|███████▌  | 226/300 [00:36<00:12,  6.05it/s]2025-03-17 11:02:25,156 - sciml.model.deeponet.deeponet - INFO - Epoch 227/300\n",
      "2025-03-17 11:02:25,157 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.085669\n",
      "2025-03-17 11:02:25,157 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.095832\n",
      "Training progress:  76%|███████▌  | 227/300 [00:37<00:12,  6.06it/s]2025-03-17 11:02:25,322 - sciml.model.deeponet.deeponet - INFO - Epoch 228/300\n",
      "2025-03-17 11:02:25,323 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.085541\n",
      "2025-03-17 11:02:25,323 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.095904\n",
      "Training progress:  76%|███████▌  | 228/300 [00:37<00:11,  6.05it/s]2025-03-17 11:02:25,487 - sciml.model.deeponet.deeponet - INFO - Epoch 229/300\n",
      "2025-03-17 11:02:25,488 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.085497\n",
      "2025-03-17 11:02:25,488 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.095322\n",
      "Training progress:  76%|███████▋  | 229/300 [00:37<00:11,  6.05it/s]2025-03-17 11:02:25,653 - sciml.model.deeponet.deeponet - INFO - Epoch 230/300\n",
      "2025-03-17 11:02:25,654 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.085490\n",
      "2025-03-17 11:02:25,655 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.096095\n",
      "Training progress:  77%|███████▋  | 230/300 [00:37<00:11,  6.04it/s]2025-03-17 11:02:25,817 - sciml.model.deeponet.deeponet - INFO - Epoch 231/300\n",
      "2025-03-17 11:02:25,818 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.085476\n",
      "2025-03-17 11:02:25,819 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.095243\n",
      "Training progress:  77%|███████▋  | 231/300 [00:37<00:11,  6.06it/s]2025-03-17 11:02:25,980 - sciml.model.deeponet.deeponet - INFO - Epoch 232/300\n",
      "2025-03-17 11:02:25,981 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.085402\n",
      "2025-03-17 11:02:25,981 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.096035\n",
      "Training progress:  77%|███████▋  | 232/300 [00:37<00:11,  6.09it/s]2025-03-17 11:02:26,144 - sciml.model.deeponet.deeponet - INFO - Epoch 233/300\n",
      "2025-03-17 11:02:26,145 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.085314\n",
      "2025-03-17 11:02:26,145 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.095141\n",
      "Training progress:  78%|███████▊  | 233/300 [00:38<00:10,  6.09it/s]2025-03-17 11:02:26,310 - sciml.model.deeponet.deeponet - INFO - Epoch 234/300\n",
      "2025-03-17 11:02:26,311 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.085177\n",
      "2025-03-17 11:02:26,312 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.095596\n",
      "Training progress:  78%|███████▊  | 234/300 [00:38<00:10,  6.07it/s]2025-03-17 11:02:26,476 - sciml.model.deeponet.deeponet - INFO - Epoch 235/300\n",
      "2025-03-17 11:02:26,476 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.085041\n",
      "2025-03-17 11:02:26,477 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.094964\n",
      "Training progress:  78%|███████▊  | 235/300 [00:38<00:10,  6.05it/s]2025-03-17 11:02:26,641 - sciml.model.deeponet.deeponet - INFO - Epoch 236/300\n",
      "2025-03-17 11:02:26,642 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084908\n",
      "2025-03-17 11:02:26,642 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.095172\n",
      "Training progress:  79%|███████▊  | 236/300 [00:38<00:10,  6.06it/s]2025-03-17 11:02:26,831 - sciml.model.deeponet.deeponet - INFO - Epoch 237/300\n",
      "2025-03-17 11:02:26,831 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084792\n",
      "2025-03-17 11:02:26,832 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.094881\n",
      "Training progress:  79%|███████▉  | 237/300 [00:38<00:10,  5.80it/s]2025-03-17 11:02:26,998 - sciml.model.deeponet.deeponet - INFO - Epoch 238/300\n",
      "2025-03-17 11:02:26,999 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084699\n",
      "2025-03-17 11:02:27,000 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.094630\n",
      "Training progress:  79%|███████▉  | 238/300 [00:38<00:10,  5.84it/s]2025-03-17 11:02:27,163 - sciml.model.deeponet.deeponet - INFO - Epoch 239/300\n",
      "2025-03-17 11:02:27,164 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084606\n",
      "2025-03-17 11:02:27,164 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.094412\n",
      "Training progress:  80%|███████▉  | 239/300 [00:39<00:10,  5.92it/s]2025-03-17 11:02:27,341 - sciml.model.deeponet.deeponet - INFO - Epoch 240/300\n",
      "2025-03-17 11:02:27,342 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084524\n",
      "2025-03-17 11:02:27,342 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.094217\n",
      "Training progress:  80%|████████  | 240/300 [00:39<00:10,  5.82it/s]2025-03-17 11:02:27,507 - sciml.model.deeponet.deeponet - INFO - Epoch 241/300\n",
      "2025-03-17 11:02:27,508 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084439\n",
      "2025-03-17 11:02:27,509 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.094525\n",
      "Training progress:  80%|████████  | 241/300 [00:39<00:10,  5.88it/s]2025-03-17 11:02:27,678 - sciml.model.deeponet.deeponet - INFO - Epoch 242/300\n",
      "2025-03-17 11:02:27,679 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084369\n",
      "2025-03-17 11:02:27,679 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.094023\n",
      "Training progress:  81%|████████  | 242/300 [00:39<00:09,  5.87it/s]2025-03-17 11:02:27,843 - sciml.model.deeponet.deeponet - INFO - Epoch 243/300\n",
      "2025-03-17 11:02:27,844 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084305\n",
      "2025-03-17 11:02:27,844 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.094533\n",
      "Training progress:  81%|████████  | 243/300 [00:39<00:09,  5.92it/s]2025-03-17 11:02:28,013 - sciml.model.deeponet.deeponet - INFO - Epoch 244/300\n",
      "2025-03-17 11:02:28,013 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084296\n",
      "2025-03-17 11:02:28,014 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.093404\n",
      "Training progress:  81%|████████▏ | 244/300 [00:40<00:09,  5.91it/s]2025-03-17 11:02:28,182 - sciml.model.deeponet.deeponet - INFO - Epoch 245/300\n",
      "2025-03-17 11:02:28,183 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084439\n",
      "2025-03-17 11:02:28,183 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.096061\n",
      "Training progress:  82%|████████▏ | 245/300 [00:40<00:09,  5.92it/s]2025-03-17 11:02:28,352 - sciml.model.deeponet.deeponet - INFO - Epoch 246/300\n",
      "2025-03-17 11:02:28,353 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.085161\n",
      "2025-03-17 11:02:28,354 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.094276\n",
      "Training progress:  82%|████████▏ | 246/300 [00:40<00:09,  5.90it/s]2025-03-17 11:02:28,525 - sciml.model.deeponet.deeponet - INFO - Epoch 247/300\n",
      "2025-03-17 11:02:28,526 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.087077\n",
      "2025-03-17 11:02:28,526 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.106097\n",
      "Training progress:  82%|████████▏ | 247/300 [00:40<00:09,  5.87it/s]2025-03-17 11:02:28,692 - sciml.model.deeponet.deeponet - INFO - Epoch 248/300\n",
      "2025-03-17 11:02:28,693 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.094374\n",
      "2025-03-17 11:02:28,693 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.096784\n",
      "Training progress:  83%|████████▎ | 248/300 [00:40<00:08,  5.90it/s]2025-03-17 11:02:28,862 - sciml.model.deeponet.deeponet - INFO - Epoch 249/300\n",
      "2025-03-17 11:02:28,863 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.092261\n",
      "2025-03-17 11:02:28,863 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.102231\n",
      "Training progress:  83%|████████▎ | 249/300 [00:40<00:08,  5.90it/s]2025-03-17 11:02:29,032 - sciml.model.deeponet.deeponet - INFO - Epoch 250/300\n",
      "2025-03-17 11:02:29,033 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.090728\n",
      "2025-03-17 11:02:29,034 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.093323\n",
      "Training progress:  83%|████████▎ | 250/300 [00:41<00:08,  5.89it/s]2025-03-17 11:02:29,208 - sciml.model.deeponet.deeponet - INFO - Epoch 251/300\n",
      "2025-03-17 11:02:29,209 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.083770\n",
      "2025-03-17 11:02:29,209 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.095383\n",
      "Training progress:  84%|████████▎ | 251/300 [00:41<00:08,  5.83it/s]2025-03-17 11:02:29,376 - sciml.model.deeponet.deeponet - INFO - Epoch 252/300\n",
      "2025-03-17 11:02:29,377 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.090237\n",
      "2025-03-17 11:02:29,377 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.107520\n",
      "Training progress:  84%|████████▍ | 252/300 [00:41<00:08,  5.86it/s]2025-03-17 11:02:29,549 - sciml.model.deeponet.deeponet - INFO - Epoch 253/300\n",
      "2025-03-17 11:02:29,549 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.097164\n",
      "2025-03-17 11:02:29,550 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092826\n",
      "Training progress:  84%|████████▍ | 253/300 [00:41<00:08,  5.84it/s]2025-03-17 11:02:29,714 - sciml.model.deeponet.deeponet - INFO - Epoch 254/300\n",
      "2025-03-17 11:02:29,714 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084048\n",
      "2025-03-17 11:02:29,715 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.102895\n",
      "Training progress:  85%|████████▍ | 254/300 [00:41<00:07,  5.91it/s]2025-03-17 11:02:29,878 - sciml.model.deeponet.deeponet - INFO - Epoch 255/300\n",
      "2025-03-17 11:02:29,879 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.101085\n",
      "2025-03-17 11:02:29,879 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.112507\n",
      "Training progress:  85%|████████▌ | 255/300 [00:41<00:07,  5.96it/s]2025-03-17 11:02:30,042 - sciml.model.deeponet.deeponet - INFO - Epoch 256/300\n",
      "2025-03-17 11:02:30,043 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.101266\n",
      "2025-03-17 11:02:30,044 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.108057\n",
      "Training progress:  85%|████████▌ | 256/300 [00:42<00:07,  5.99it/s]2025-03-17 11:02:30,214 - sciml.model.deeponet.deeponet - INFO - Epoch 257/300\n",
      "2025-03-17 11:02:30,215 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.095675\n",
      "2025-03-17 11:02:30,216 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.103613\n",
      "Training progress:  86%|████████▌ | 257/300 [00:42<00:07,  5.94it/s]2025-03-17 11:02:30,382 - sciml.model.deeponet.deeponet - INFO - Epoch 258/300\n",
      "2025-03-17 11:02:30,383 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.098133\n",
      "2025-03-17 11:02:30,384 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.093504\n",
      "Training progress:  86%|████████▌ | 258/300 [00:42<00:07,  5.94it/s]2025-03-17 11:02:30,559 - sciml.model.deeponet.deeponet - INFO - Epoch 259/300\n",
      "2025-03-17 11:02:30,559 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.085710\n",
      "2025-03-17 11:02:30,560 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.099980\n",
      "Training progress:  86%|████████▋ | 259/300 [00:42<00:06,  5.86it/s]2025-03-17 11:02:30,725 - sciml.model.deeponet.deeponet - INFO - Epoch 260/300\n",
      "2025-03-17 11:02:30,726 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.092530\n",
      "2025-03-17 11:02:30,727 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.093115\n",
      "Training progress:  87%|████████▋ | 260/300 [00:42<00:06,  5.90it/s]2025-03-17 11:02:30,892 - sciml.model.deeponet.deeponet - INFO - Epoch 261/300\n",
      "2025-03-17 11:02:30,892 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.087583\n",
      "2025-03-17 11:02:30,893 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.096354\n",
      "Training progress:  87%|████████▋ | 261/300 [00:42<00:06,  5.94it/s]2025-03-17 11:02:31,087 - sciml.model.deeponet.deeponet - INFO - Epoch 262/300\n",
      "2025-03-17 11:02:31,087 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.092431\n",
      "2025-03-17 11:02:31,088 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092705\n",
      "Training progress:  87%|████████▋ | 262/300 [00:43<00:06,  5.67it/s]2025-03-17 11:02:31,260 - sciml.model.deeponet.deeponet - INFO - Epoch 263/300\n",
      "2025-03-17 11:02:31,261 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084403\n",
      "2025-03-17 11:02:31,261 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.099124\n",
      "Training progress:  88%|████████▊ | 263/300 [00:43<00:06,  5.70it/s]2025-03-17 11:02:31,436 - sciml.model.deeponet.deeponet - INFO - Epoch 264/300\n",
      "2025-03-17 11:02:31,437 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.089219\n",
      "2025-03-17 11:02:31,438 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.095257\n",
      "Training progress:  88%|████████▊ | 264/300 [00:43<00:06,  5.69it/s]2025-03-17 11:02:31,609 - sciml.model.deeponet.deeponet - INFO - Epoch 265/300\n",
      "2025-03-17 11:02:31,609 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084375\n",
      "2025-03-17 11:02:31,610 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.096968\n",
      "Training progress:  88%|████████▊ | 265/300 [00:43<00:06,  5.72it/s]2025-03-17 11:02:31,773 - sciml.model.deeponet.deeponet - INFO - Epoch 266/300\n",
      "2025-03-17 11:02:31,774 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.087992\n",
      "2025-03-17 11:02:31,774 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.094198\n",
      "Training progress:  89%|████████▊ | 266/300 [00:43<00:05,  5.83it/s]2025-03-17 11:02:31,938 - sciml.model.deeponet.deeponet - INFO - Epoch 267/300\n",
      "2025-03-17 11:02:31,939 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084212\n",
      "2025-03-17 11:02:31,940 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.097946\n",
      "Training progress:  89%|████████▉ | 267/300 [00:43<00:05,  5.89it/s]2025-03-17 11:02:32,121 - sciml.model.deeponet.deeponet - INFO - Epoch 268/300\n",
      "2025-03-17 11:02:32,122 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.086675\n",
      "2025-03-17 11:02:32,123 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.096250\n",
      "Training progress:  89%|████████▉ | 268/300 [00:44<00:05,  5.75it/s]2025-03-17 11:02:32,320 - sciml.model.deeponet.deeponet - INFO - Epoch 269/300\n",
      "2025-03-17 11:02:32,321 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084833\n",
      "2025-03-17 11:02:32,321 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.095257\n",
      "Training progress:  90%|████████▉ | 269/300 [00:44<00:05,  5.52it/s]2025-03-17 11:02:32,492 - sciml.model.deeponet.deeponet - INFO - Epoch 270/300\n",
      "2025-03-17 11:02:32,493 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.085128\n",
      "2025-03-17 11:02:32,494 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.094997\n",
      "Training progress:  90%|█████████ | 270/300 [00:44<00:05,  5.60it/s]2025-03-17 11:02:32,691 - sciml.model.deeponet.deeponet - INFO - Epoch 271/300\n",
      "2025-03-17 11:02:32,692 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084614\n",
      "2025-03-17 11:02:32,692 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.095575\n",
      "Training progress:  90%|█████████ | 271/300 [00:44<00:05,  5.42it/s]2025-03-17 11:02:32,882 - sciml.model.deeponet.deeponet - INFO - Epoch 272/300\n",
      "2025-03-17 11:02:32,883 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084435\n",
      "2025-03-17 11:02:32,884 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.094912\n",
      "Training progress:  91%|█████████ | 272/300 [00:44<00:05,  5.36it/s]2025-03-17 11:02:33,095 - sciml.model.deeponet.deeponet - INFO - Epoch 273/300\n",
      "2025-03-17 11:02:33,096 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084615\n",
      "2025-03-17 11:02:33,096 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092127\n",
      "Training progress:  91%|█████████ | 273/300 [00:45<00:05,  5.14it/s]2025-03-17 11:02:33,303 - sciml.model.deeponet.deeponet - INFO - Epoch 274/300\n",
      "2025-03-17 11:02:33,304 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.083839\n",
      "2025-03-17 11:02:33,305 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092278\n",
      "Training progress:  91%|█████████▏| 274/300 [00:45<00:05,  5.04it/s]2025-03-17 11:02:33,495 - sciml.model.deeponet.deeponet - INFO - Epoch 275/300\n",
      "2025-03-17 11:02:33,496 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084451\n",
      "2025-03-17 11:02:33,497 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.093347\n",
      "Training progress:  92%|█████████▏| 275/300 [00:45<00:04,  5.09it/s]2025-03-17 11:02:33,685 - sciml.model.deeponet.deeponet - INFO - Epoch 276/300\n",
      "2025-03-17 11:02:33,686 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.083497\n",
      "2025-03-17 11:02:33,687 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.094857\n",
      "Training progress:  92%|█████████▏| 276/300 [00:45<00:04,  5.14it/s]2025-03-17 11:02:33,885 - sciml.model.deeponet.deeponet - INFO - Epoch 277/300\n",
      "2025-03-17 11:02:33,885 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084252\n",
      "2025-03-17 11:02:33,886 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.093256\n",
      "Training progress:  92%|█████████▏| 277/300 [00:45<00:04,  5.10it/s]2025-03-17 11:02:34,057 - sciml.model.deeponet.deeponet - INFO - Epoch 278/300\n",
      "2025-03-17 11:02:34,058 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.083223\n",
      "2025-03-17 11:02:34,058 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.093048\n",
      "Training progress:  93%|█████████▎| 278/300 [00:46<00:04,  5.30it/s]2025-03-17 11:02:34,229 - sciml.model.deeponet.deeponet - INFO - Epoch 279/300\n",
      "2025-03-17 11:02:34,230 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084017\n",
      "2025-03-17 11:02:34,230 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092789\n",
      "Training progress:  93%|█████████▎| 279/300 [00:46<00:03,  5.44it/s]2025-03-17 11:02:34,397 - sciml.model.deeponet.deeponet - INFO - Epoch 280/300\n",
      "2025-03-17 11:02:34,398 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082945\n",
      "2025-03-17 11:02:34,399 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.093971\n",
      "Training progress:  93%|█████████▎| 280/300 [00:46<00:03,  5.58it/s]2025-03-17 11:02:34,570 - sciml.model.deeponet.deeponet - INFO - Epoch 281/300\n",
      "2025-03-17 11:02:34,570 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.083763\n",
      "2025-03-17 11:02:34,571 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092568\n",
      "Training progress:  94%|█████████▎| 281/300 [00:46<00:03,  5.65it/s]2025-03-17 11:02:34,761 - sciml.model.deeponet.deeponet - INFO - Epoch 282/300\n",
      "2025-03-17 11:02:34,762 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082911\n",
      "2025-03-17 11:02:34,762 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092373\n",
      "Training progress:  94%|█████████▍| 282/300 [00:46<00:03,  5.51it/s]2025-03-17 11:02:35,095 - sciml.model.deeponet.deeponet - INFO - Epoch 283/300\n",
      "2025-03-17 11:02:35,095 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.083469\n",
      "2025-03-17 11:02:35,096 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092342\n",
      "Training progress:  94%|█████████▍| 283/300 [00:47<00:03,  4.40it/s]2025-03-17 11:02:35,267 - sciml.model.deeponet.deeponet - INFO - Epoch 284/300\n",
      "2025-03-17 11:02:35,268 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082725\n",
      "2025-03-17 11:02:35,268 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.093211\n",
      "Training progress:  95%|█████████▍| 284/300 [00:47<00:03,  4.75it/s]2025-03-17 11:02:35,434 - sciml.model.deeponet.deeponet - INFO - Epoch 285/300\n",
      "2025-03-17 11:02:35,435 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.083147\n",
      "2025-03-17 11:02:35,435 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092090\n",
      "Training progress:  95%|█████████▌| 285/300 [00:47<00:02,  5.07it/s]2025-03-17 11:02:35,610 - sciml.model.deeponet.deeponet - INFO - Epoch 286/300\n",
      "2025-03-17 11:02:35,611 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082682\n",
      "2025-03-17 11:02:35,611 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.091450\n",
      "Training progress:  95%|█████████▌| 286/300 [00:47<00:02,  5.23it/s]2025-03-17 11:02:35,789 - sciml.model.deeponet.deeponet - INFO - Epoch 287/300\n",
      "2025-03-17 11:02:35,790 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.083000\n",
      "2025-03-17 11:02:35,790 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.091759\n",
      "Training progress:  96%|█████████▌| 287/300 [00:47<00:02,  5.34it/s]2025-03-17 11:02:35,972 - sciml.model.deeponet.deeponet - INFO - Epoch 288/300\n",
      "2025-03-17 11:02:35,973 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082564\n",
      "2025-03-17 11:02:35,974 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.093058\n",
      "Training progress:  96%|█████████▌| 288/300 [00:47<00:02,  5.37it/s]2025-03-17 11:02:36,183 - sciml.model.deeponet.deeponet - INFO - Epoch 289/300\n",
      "2025-03-17 11:02:36,185 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082741\n",
      "2025-03-17 11:02:36,185 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092765\n",
      "Training progress:  96%|█████████▋| 289/300 [00:48<00:02,  5.16it/s]2025-03-17 11:02:36,386 - sciml.model.deeponet.deeponet - INFO - Epoch 290/300\n",
      "2025-03-17 11:02:36,387 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082491\n",
      "2025-03-17 11:02:36,388 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.091932\n",
      "Training progress:  97%|█████████▋| 290/300 [00:48<00:01,  5.09it/s]2025-03-17 11:02:36,580 - sciml.model.deeponet.deeponet - INFO - Epoch 291/300\n",
      "2025-03-17 11:02:36,582 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082576\n",
      "2025-03-17 11:02:36,583 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.091658\n",
      "Training progress:  97%|█████████▋| 291/300 [00:48<00:01,  5.10it/s]2025-03-17 11:02:36,765 - sciml.model.deeponet.deeponet - INFO - Epoch 292/300\n",
      "2025-03-17 11:02:36,766 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082347\n",
      "2025-03-17 11:02:36,766 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092179\n",
      "Training progress:  97%|█████████▋| 292/300 [00:48<00:01,  5.20it/s]2025-03-17 11:02:36,943 - sciml.model.deeponet.deeponet - INFO - Epoch 293/300\n",
      "2025-03-17 11:02:36,944 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082451\n",
      "2025-03-17 11:02:36,945 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.091766\n",
      "Training progress:  98%|█████████▊| 293/300 [00:48<00:01,  5.32it/s]2025-03-17 11:02:37,115 - sciml.model.deeponet.deeponet - INFO - Epoch 294/300\n",
      "2025-03-17 11:02:37,116 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082282\n",
      "2025-03-17 11:02:37,117 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.091244\n",
      "Training progress:  98%|█████████▊| 294/300 [00:49<00:01,  5.46it/s]2025-03-17 11:02:37,288 - sciml.model.deeponet.deeponet - INFO - Epoch 295/300\n",
      "2025-03-17 11:02:37,289 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082293\n",
      "2025-03-17 11:02:37,289 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.091540\n",
      "Training progress:  98%|█████████▊| 295/300 [00:49<00:00,  5.55it/s]2025-03-17 11:02:37,456 - sciml.model.deeponet.deeponet - INFO - Epoch 296/300\n",
      "2025-03-17 11:02:37,456 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082146\n",
      "2025-03-17 11:02:37,457 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092267\n",
      "Training progress:  99%|█████████▊| 296/300 [00:49<00:00,  5.67it/s]2025-03-17 11:02:37,624 - sciml.model.deeponet.deeponet - INFO - Epoch 297/300\n",
      "2025-03-17 11:02:37,625 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082206\n",
      "2025-03-17 11:02:37,625 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.091800\n",
      "Training progress:  99%|█████████▉| 297/300 [00:49<00:00,  5.75it/s]2025-03-17 11:02:37,790 - sciml.model.deeponet.deeponet - INFO - Epoch 298/300\n",
      "2025-03-17 11:02:37,791 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082054\n",
      "2025-03-17 11:02:37,791 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.091103\n",
      "Training progress:  99%|█████████▉| 298/300 [00:49<00:00,  5.82it/s]2025-03-17 11:02:37,959 - sciml.model.deeponet.deeponet - INFO - Epoch 299/300\n",
      "2025-03-17 11:02:37,960 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082091\n",
      "2025-03-17 11:02:37,960 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.091357\n",
      "Training progress: 100%|█████████▉| 299/300 [00:49<00:00,  5.85it/s]2025-03-17 11:02:38,127 - sciml.model.deeponet.deeponet - INFO - Epoch 300/300\n",
      "2025-03-17 11:02:38,128 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.081930\n",
      "2025-03-17 11:02:38,128 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092105\n",
      "Training progress: 100%|██████████| 300/300 [00:50<00:00,  5.99it/s]\n"
     ]
    }
   ],
   "source": [
    "train_history = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([0.33610790967941284, 0.31519049406051636, 0.29600125551223755, 0.2828846573829651, 0.2799820601940155, 0.2841980755329132, 0.2846720814704895, 0.2798512279987335, 0.27356091141700745, 0.2687484323978424, 0.26603758335113525, 0.26458340883255005, 0.26324158906936646, 0.26122429966926575, 0.25828084349632263, 0.25457441806793213, 0.25054794549942017, 0.2466960847377777, 0.24339237809181213, 0.24048590660095215, 0.23722541332244873, 0.23281751573085785, 0.22752797603607178, 0.222360298037529, 0.21800757944583893, 0.21409861743450165, 0.2096422016620636, 0.2043258398771286, 0.1987110674381256, 0.19338580965995789, 0.18841509521007538, 0.18423563241958618, 0.18053364753723145, 0.1765531301498413, 0.17279118299484253, 0.16947826743125916, 0.1663992702960968, 0.16376465559005737, 0.16118207573890686, 0.15881206095218658, 0.1569249927997589, 0.15527263283729553, 0.1539011299610138, 0.15267065167427063, 0.15151338279247284, 0.15058743953704834, 0.14976023137569427, 0.14895612001419067, 0.14819878339767456, 0.14737772941589355, 0.14655916392803192, 0.1456891894340515, 0.14482468366622925, 0.14396390318870544, 0.14310747385025024, 0.1422726809978485, 0.14145487546920776, 0.140619158744812, 0.13978981971740723, 0.138960063457489, 0.13817568123340607, 0.13738524913787842, 0.1366298943758011, 0.1358829140663147, 0.1351490616798401, 0.13441979885101318, 0.13368862867355347, 0.13296976685523987, 0.1322360634803772, 0.13147783279418945, 0.13072288036346436, 0.1299542486667633, 0.12920691072940826, 0.1284538209438324, 0.12768599390983582, 0.12691816687583923, 0.12612220644950867, 0.1253226399421692, 0.12453512847423553, 0.12372683733701706, 0.12289565801620483, 0.122052863240242, 0.1212034523487091, 0.12034562975168228, 0.11949706077575684, 0.11872056126594543, 0.11827543377876282, 0.11870498955249786, 0.11783923208713531, 0.11580140143632889, 0.11483072489500046, 0.11530132591724396, 0.11409400403499603, 0.11255280673503876, 0.1131334900856018, 0.1120179072022438, 0.11057235300540924, 0.11112796515226364, 0.10997714847326279, 0.10873187333345413, 0.10931660234928131, 0.10819701850414276, 0.10696862637996674, 0.10753172636032104, 0.10653267055749893, 0.10527105629444122, 0.10585309565067291, 0.10504548251628876, 0.10363803058862686, 0.10424700379371643, 0.10380490869283676, 0.10211601108312607, 0.10269960016012192, 0.10292283445596695, 0.10081513971090317, 0.1013229638338089, 0.10210685431957245, 0.09965606778860092, 0.10022803395986557, 0.10134673118591309, 0.09861838072538376, 0.09946069121360779, 0.10070095956325531, 0.09762027114629745, 0.09944963455200195, 0.10033664107322693, 0.09687744081020355, 0.10075803846120834, 0.09970774501562119, 0.09727044403553009, 0.1012430489063263, 0.09662137925624847, 0.09821391105651855, 0.09705980122089386, 0.09577510505914688, 0.09721243381500244, 0.09512663632631302, 0.0969477966427803, 0.09517180919647217, 0.09558568894863129, 0.09540820866823196, 0.094322569668293, 0.09505899250507355, 0.09406618028879166, 0.09452279657125473, 0.09407268464565277, 0.09382575750350952, 0.0940421000123024, 0.09331591427326202, 0.09358716756105423, 0.09322813898324966, 0.09293047338724136, 0.09313783049583435, 0.09269345551729202, 0.09262886643409729, 0.09261403977870941, 0.09229372441768646, 0.09230581670999527, 0.09218260645866394, 0.09191328287124634, 0.09192122519016266, 0.09181375801563263, 0.09154544025659561, 0.09158319234848022, 0.09152613580226898, 0.09117916226387024, 0.09114429354667664, 0.09115998446941376, 0.09086517989635468, 0.09075003862380981, 0.09082133322954178, 0.09066895395517349, 0.09043540060520172, 0.09029275923967361, 0.0902680903673172, 0.09025738388299942, 0.09006551653146744, 0.08985965698957443, 0.0897434875369072, 0.08965550363063812, 0.08963048458099365, 0.08956533670425415, 0.08944807946681976, 0.08931171894073486, 0.0891423150897026, 0.08901773393154144, 0.08891460299491882, 0.08881579339504242, 0.08875522017478943, 0.08868809044361115, 0.08865373581647873, 0.08872074633836746, 0.08889596909284592, 0.08959987759590149, 0.09020605683326721, 0.09211824834346771, 0.09070831537246704, 0.08945731818675995, 0.08778400719165802, 0.08822551369667053, 0.08975090086460114, 0.08909979462623596, 0.08797654509544373, 0.08731278777122498, 0.08795028924942017, 0.08863606303930283, 0.08771559596061707, 0.08700637519359589, 0.08724082261323929, 0.08761845529079437, 0.087521493434906, 0.08684223145246506, 0.08671092242002487, 0.08704868704080582, 0.08699926733970642, 0.08667818456888199, 0.08636002987623215, 0.0863843560218811, 0.08655497431755066, 0.08644843101501465, 0.08618764579296112, 0.08598767966032028, 0.08597473055124283, 0.08606521040201187, 0.0860213190317154, 0.08587675541639328, 0.08566883206367493, 0.08554062247276306, 0.08549707382917404, 0.08548961579799652, 0.08547598123550415, 0.08540225028991699, 0.0853143110871315, 0.0851774513721466, 0.08504104614257812, 0.08490756154060364, 0.08479233086109161, 0.08469875156879425, 0.0846058800816536, 0.08452365547418594, 0.08443895727396011, 0.0843685194849968, 0.08430470526218414, 0.084295853972435, 0.08443853259086609, 0.08516136556863785, 0.08707734942436218, 0.09437358379364014, 0.09226111322641373, 0.09072764217853546, 0.08377021551132202, 0.0902366042137146, 0.09716424345970154, 0.08404824137687683, 0.10108537971973419, 0.10126626491546631, 0.09567536413669586, 0.09813342243432999, 0.08570975065231323, 0.09253043681383133, 0.08758305013179779, 0.09243080019950867, 0.08440276980400085, 0.08921860158443451, 0.08437533676624298, 0.08799205720424652, 0.08421222865581512, 0.08667483925819397, 0.08483290672302246, 0.08512793481349945, 0.08461436629295349, 0.08443453907966614, 0.08461526036262512, 0.08383943140506744, 0.08445140719413757, 0.08349708467721939, 0.08425218611955643, 0.08322346210479736, 0.0840173065662384, 0.08294522762298584, 0.08376260101795197, 0.08291135728359222, 0.08346930891275406, 0.0827246829867363, 0.08314725756645203, 0.08268214762210846, 0.08299966156482697, 0.0825643315911293, 0.082740917801857, 0.08249080926179886, 0.08257634192705154, 0.08234655112028122, 0.08245109021663666, 0.0822816714644432, 0.08229348063468933, 0.08214619755744934, 0.08220642805099487, 0.08205443620681763, 0.08209145069122314, 0.08193013072013855], [0.3051883578300476, 0.2827467918395996, 0.26289603114128113, 0.24821516871452332, 0.24092525243759155, 0.23864296078681946, 0.23871414363384247, 0.2406013309955597, 0.24390120804309845, 0.24774521589279175, 0.2510570287704468, 0.25295788049697876, 0.25303518772125244, 0.25127512216567993, 0.24791470170021057, 0.24340209364891052, 0.2382216900587082, 0.23300567269325256, 0.22838936746120453, 0.22475722432136536, 0.22229832410812378, 0.2209690809249878, 0.22058941423892975, 0.22067859768867493, 0.2201875001192093, 0.21822115778923035, 0.21463322639465332, 0.20994749665260315, 0.20501220226287842, 0.20071497559547424, 0.1974751204252243, 0.1946752369403839, 0.1920013278722763, 0.18972918391227722, 0.188347727060318, 0.1877167820930481, 0.1867028772830963, 0.18417569994926453, 0.18068437278270721, 0.17773571610450745, 0.1759938895702362, 0.17495691776275635, 0.1736016571521759, 0.171672523021698, 0.16978423297405243, 0.1684987097978592, 0.1676855981349945, 0.16666610538959503, 0.16498388350009918, 0.1633249968290329, 0.16224734485149384, 0.16147169470787048, 0.16039907932281494, 0.15897497534751892, 0.15799136459827423, 0.15738780796527863, 0.15625298023223877, 0.15490862727165222, 0.15407520532608032, 0.15351349115371704, 0.15266303718090057, 0.15198694169521332, 0.1517999768257141, 0.15147626399993896, 0.15098480880260468, 0.1507127285003662, 0.15033890306949615, 0.14991521835327148, 0.1495230495929718, 0.14899510145187378, 0.1485021412372589, 0.14792653918266296, 0.1472856104373932, 0.14643937349319458, 0.14585766196250916, 0.14519473910331726, 0.144503653049469, 0.14412295818328857, 0.1432981789112091, 0.1426602602005005, 0.14184381067752838, 0.14095309376716614, 0.14032475650310516, 0.13927188515663147, 0.13922961056232452, 0.13741345703601837, 0.14006298780441284, 0.13627135753631592, 0.13720451295375824, 0.1362290382385254, 0.1343914419412613, 0.13591477274894714, 0.13385915756225586, 0.13234660029411316, 0.13369271159172058, 0.13170325756072998, 0.13003377616405487, 0.1311955749988556, 0.12943987548351288, 0.12784725427627563, 0.12912589311599731, 0.1274145096540451, 0.12589934468269348, 0.12726184725761414, 0.12541522085666656, 0.12386640906333923, 0.12549614906311035, 0.12327417731285095, 0.12185978889465332, 0.12389977276325226, 0.12104907631874084, 0.11983399093151093, 0.12270045280456543, 0.11897454410791397, 0.11797645688056946, 0.12142232060432434, 0.11701585352420807, 0.11610791832208633, 0.1200641617178917, 0.11527423560619354, 0.11449913680553436, 0.11889731884002686, 0.11404848098754883, 0.11323538422584534, 0.11806397140026093, 0.11328120529651642, 0.11252488195896149, 0.11693805456161499, 0.11400850862264633, 0.11220240592956543, 0.1129806712269783, 0.11485666036605835, 0.1099996566772461, 0.10988834500312805, 0.11365340650081635, 0.11054961383342743, 0.10941369831562042, 0.11054693162441254, 0.11098866909742355, 0.10810376703739166, 0.10842791199684143, 0.11058901250362396, 0.1086011603474617, 0.10765978693962097, 0.10880671441555023, 0.10825952887535095, 0.10687540471553802, 0.1076955646276474, 0.10842646658420563, 0.10670614242553711, 0.10623292624950409, 0.10706675797700882, 0.1057659387588501, 0.10556206107139587, 0.1066121906042099, 0.10586227476596832, 0.1049453467130661, 0.10564783960580826, 0.10507723689079285, 0.10452647507190704, 0.10537710785865784, 0.10462481528520584, 0.10370609164237976, 0.10461048781871796, 0.10367320477962494, 0.10347699373960495, 0.10433997213840485, 0.10318902879953384, 0.10292360186576843, 0.10365808010101318, 0.10242477804422379, 0.10301360487937927, 0.10268238931894302, 0.10202710330486298, 0.10292170941829681, 0.10182926803827286, 0.10230429470539093, 0.10200969874858856, 0.10150230675935745, 0.10198064148426056, 0.10103550553321838, 0.10180743038654327, 0.10088126361370087, 0.10124117881059647, 0.10079704225063324, 0.1007428914308548, 0.10079129040241241, 0.10029184818267822, 0.10071586817502975, 0.09969670325517654, 0.10079627484083176, 0.0991329550743103, 0.1020779013633728, 0.09922102093696594, 0.10480141639709473, 0.09897415339946747, 0.10156549513339996, 0.09847872704267502, 0.09825366735458374, 0.10183364897966385, 0.09781742095947266, 0.09918521344661713, 0.09817168861627579, 0.09796208143234253, 0.10090921819210052, 0.09784240275621414, 0.0979468822479248, 0.09838901460170746, 0.09714757651090622, 0.09899862110614777, 0.09722648561000824, 0.09702298790216446, 0.09810252487659454, 0.0965600460767746, 0.09773639589548111, 0.09699388593435287, 0.09667277336120605, 0.09755659103393555, 0.09622840583324432, 0.09701313823461533, 0.09648201614618301, 0.09621935337781906, 0.09692836552858353, 0.09577253460884094, 0.09658140689134598, 0.09571338444948196, 0.09583212435245514, 0.09590445458889008, 0.09532220661640167, 0.09609465301036835, 0.09524308145046234, 0.09603501856327057, 0.09514111280441284, 0.09559621661901474, 0.09496404230594635, 0.09517186135053635, 0.09488072246313095, 0.09463004022836685, 0.09441173076629639, 0.09421676397323608, 0.09452521055936813, 0.0940227061510086, 0.09453310072422028, 0.09340415894985199, 0.09606079012155533, 0.09427572786808014, 0.10609652101993561, 0.09678351134061813, 0.10223116725683212, 0.09332332015037537, 0.09538305550813675, 0.10751982033252716, 0.09282594174146652, 0.10289546847343445, 0.11250683665275574, 0.10805732011795044, 0.1036134585738182, 0.09350408613681793, 0.09998038411140442, 0.09311506897211075, 0.09635357558727264, 0.09270454943180084, 0.09912404417991638, 0.09525661170482635, 0.09696786105632782, 0.09419797360897064, 0.09794624894857407, 0.09625042974948883, 0.09525743126869202, 0.09499712288379669, 0.09557510912418365, 0.09491200745105743, 0.09212686866521835, 0.0922776460647583, 0.09334702789783478, 0.0948566198348999, 0.09325563907623291, 0.09304846078157425, 0.09278874099254608, 0.09397129714488983, 0.092568039894104, 0.09237339347600937, 0.09234157204627991, 0.09321141242980957, 0.09208956360816956, 0.09145018458366394, 0.09175916016101837, 0.09305837005376816, 0.09276493638753891, 0.09193217754364014, 0.09165821969509125, 0.09217941015958786, 0.09176565706729889, 0.09124445915222168, 0.09153957664966583, 0.09226738661527634, 0.09179963171482086, 0.0911034494638443, 0.0913572907447815, 0.0921047106385231])\n"
     ]
    }
   ],
   "source": [
    "print(train_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_history[0],c='r')\n",
    "plt.plot(train_history[1],c='b')\n",
    "plt.legend(['train','val'])\n",
    "#log \n",
    "plt.yscale('log')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions from external model for 5 different inputs\n",
    "n_samples = 5\n",
    "t_slices = [10, 20]  # Time points to visualize\n",
    "\n",
    "# Create sample inputs (3D points - x,y,t)\n",
    "x = np.linspace(0, 1, 50)\n",
    "y = np.linspace(0, 1, 50)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "inputs = []\n",
    "\n",
    "for t in t_slices:\n",
    "    points = np.stack([X.flatten(), Y.flatten(), np.ones_like(X.flatten())*t], axis=-1)\n",
    "    inputs.append(points)\n",
    "inputs = np.concatenate(inputs, axis=0)\n",
    "\n",
    "# Get predictions\n",
    "preds = external_model(inputs).numpy()\n",
    "preds = preds.reshape(len(t_slices), 50, 50, -1)  # Reshape to (n_times, height, width, n_outputs)\n",
    "\n",
    "# Plot heatmaps\n",
    "fig, axes = plt.subplots(len(t_slices), 5, figsize=(20, 8))\n",
    "for i, t in enumerate(t_slices):\n",
    "    for j in range(5):\n",
    "        im = axes[i,j].imshow(preds[i,:,:,j], cmap='viridis', extent=[0,1,0,1])\n",
    "        axes[i,j].set_title(f'Output {j+1}, t={t}')\n",
    "        plt.colorbar(im, ax=axes[i,j])\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
