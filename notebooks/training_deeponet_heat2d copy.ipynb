{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sciml.model.deeponet import DeepONet\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "tf.config.list_physical_devices('GPU')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_p = 40\n",
    "d_V = 40\n",
    "epochs = 300\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "internal_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(80,)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "])\n",
    "\n",
    "\n",
    "external_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(3,)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"data/test_data/example_data/heat2d/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-16 20:30:56,347 - sciml.model.deeponet.deeponet - INFO - Model initialized with 300 epochs, 32 batch size, 0.001 learning rate\n"
     ]
    }
   ],
   "source": [
    "model = DeepONet(regular_params={\"internal_model\": internal_model, \"external_model\": external_model}, hyper_params={\"d_p\": d_p, \"d_V\": d_V,\"device\": \"GPU\",\"n_epochs\":epochs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading mu data: 100%|██████████| 40/40 [00:00<00:00, 8696.91it/s]\n",
      "Loading x data: 100%|██████████| 40/40 [00:00<00:00, 3074.83it/s]\n",
      "Loading y data: 100%|██████████| 40/40 [00:00<00:00, 5204.66it/s]\n"
     ]
    }
   ],
   "source": [
    "mus, xs, sol = model.get_data(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 80)\n",
      "(40, 8000, 3)\n",
      "(40, 8000)\n"
     ]
    }
   ],
   "source": [
    "print(mus.shape)\n",
    "print(xs.shape)\n",
    "print(sol.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading mu data: 100%|██████████| 40/40 [00:00<00:00, 8964.10it/s]\n",
      "Loading x data: 100%|██████████| 40/40 [00:00<00:00, 4165.67it/s]\n",
      "Loading y data:   0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading y data: 100%|██████████| 40/40 [00:00<00:00, 5092.34it/s]\n",
      "2025-03-16 20:30:56.854850: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [40,8000]\n",
      "\t [[{{node Placeholder/_2}}]]\n",
      "Training progress:   0%|          | 0/300 [00:00<?, ?it/s]2025-03-16 20:30:56.874312: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,8000]\n",
      "\t [[{{node Placeholder/_2}}]]\n",
      "2025-03-16 20:30:57.004683: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [8,8000]\n",
      "\t [[{{node Placeholder/_2}}]]\n",
      "2025-03-16 20:30:57,027 - sciml.model.deeponet.deeponet - INFO - Epoch 1/300\n",
      "2025-03-16 20:30:57,028 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.298403\n",
      "2025-03-16 20:30:57,029 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.255638\n",
      "Training progress:   0%|          | 1/300 [00:00<00:47,  6.35it/s]2025-03-16 20:30:57,166 - sciml.model.deeponet.deeponet - INFO - Epoch 2/300\n",
      "2025-03-16 20:30:57,166 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.287951\n",
      "2025-03-16 20:30:57,167 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.250287\n",
      "Training progress:   1%|          | 2/300 [00:00<00:43,  6.84it/s]2025-03-16 20:30:57,305 - sciml.model.deeponet.deeponet - INFO - Epoch 3/300\n",
      "2025-03-16 20:30:57,306 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.281128\n",
      "2025-03-16 20:30:57,306 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.245404\n",
      "Training progress:   1%|          | 3/300 [00:00<00:42,  6.99it/s]2025-03-16 20:30:57,442 - sciml.model.deeponet.deeponet - INFO - Epoch 4/300\n",
      "2025-03-16 20:30:57,443 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.275511\n",
      "2025-03-16 20:30:57,444 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.241015\n",
      "Training progress:   1%|▏         | 4/300 [00:00<00:41,  7.10it/s]2025-03-16 20:30:57,580 - sciml.model.deeponet.deeponet - INFO - Epoch 5/300\n",
      "2025-03-16 20:30:57,581 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.269674\n",
      "2025-03-16 20:30:57,582 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.236834\n",
      "Training progress:   2%|▏         | 5/300 [00:00<00:41,  7.15it/s]2025-03-16 20:30:57,720 - sciml.model.deeponet.deeponet - INFO - Epoch 6/300\n",
      "2025-03-16 20:30:57,721 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.263859\n",
      "2025-03-16 20:30:57,721 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.232969\n",
      "Training progress:   2%|▏         | 6/300 [00:00<00:41,  7.16it/s]2025-03-16 20:30:57,854 - sciml.model.deeponet.deeponet - INFO - Epoch 7/300\n",
      "2025-03-16 20:30:57,855 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.258284\n",
      "2025-03-16 20:30:57,855 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.229461\n",
      "Training progress:   2%|▏         | 7/300 [00:00<00:40,  7.26it/s]2025-03-16 20:30:57,993 - sciml.model.deeponet.deeponet - INFO - Epoch 8/300\n",
      "2025-03-16 20:30:57,994 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.253051\n",
      "2025-03-16 20:30:57,994 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.226231\n",
      "Training progress:   3%|▎         | 8/300 [00:01<00:40,  7.24it/s]2025-03-16 20:30:58,133 - sciml.model.deeponet.deeponet - INFO - Epoch 9/300\n",
      "2025-03-16 20:30:58,134 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.247921\n",
      "2025-03-16 20:30:58,134 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.223287\n",
      "Training progress:   3%|▎         | 9/300 [00:01<00:40,  7.19it/s]2025-03-16 20:30:58,270 - sciml.model.deeponet.deeponet - INFO - Epoch 10/300\n",
      "2025-03-16 20:30:58,271 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.243187\n",
      "2025-03-16 20:30:58,271 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.220907\n",
      "Training progress:   3%|▎         | 10/300 [00:01<00:40,  7.24it/s]2025-03-16 20:30:58,417 - sciml.model.deeponet.deeponet - INFO - Epoch 11/300\n",
      "2025-03-16 20:30:58,418 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.239006\n",
      "2025-03-16 20:30:58,418 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.219330\n",
      "Training progress:   4%|▎         | 11/300 [00:01<00:40,  7.09it/s]2025-03-16 20:30:58,557 - sciml.model.deeponet.deeponet - INFO - Epoch 12/300\n",
      "2025-03-16 20:30:58,558 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.234999\n",
      "2025-03-16 20:30:58,558 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.218716\n",
      "Training progress:   4%|▍         | 12/300 [00:01<00:40,  7.12it/s]2025-03-16 20:30:58,696 - sciml.model.deeponet.deeponet - INFO - Epoch 13/300\n",
      "2025-03-16 20:30:58,696 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.231073\n",
      "2025-03-16 20:30:58,697 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.218593\n",
      "Training progress:   4%|▍         | 13/300 [00:01<00:40,  7.14it/s]2025-03-16 20:30:58,835 - sciml.model.deeponet.deeponet - INFO - Epoch 14/300\n",
      "2025-03-16 20:30:58,835 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.227082\n",
      "2025-03-16 20:30:58,836 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.218184\n",
      "Training progress:   5%|▍         | 14/300 [00:01<00:39,  7.16it/s]2025-03-16 20:30:58,976 - sciml.model.deeponet.deeponet - INFO - Epoch 15/300\n",
      "2025-03-16 20:30:58,977 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.222933\n",
      "2025-03-16 20:30:58,978 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.216759\n",
      "Training progress:   5%|▌         | 15/300 [00:02<00:40,  7.12it/s]2025-03-16 20:30:59,117 - sciml.model.deeponet.deeponet - INFO - Epoch 16/300\n",
      "2025-03-16 20:30:59,117 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.218570\n",
      "2025-03-16 20:30:59,118 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.214129\n",
      "Training progress:   5%|▌         | 16/300 [00:02<00:39,  7.13it/s]2025-03-16 20:30:59,255 - sciml.model.deeponet.deeponet - INFO - Epoch 17/300\n",
      "2025-03-16 20:30:59,255 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.214006\n",
      "2025-03-16 20:30:59,256 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.210707\n",
      "Training progress:   6%|▌         | 17/300 [00:02<00:39,  7.17it/s]2025-03-16 20:30:59,409 - sciml.model.deeponet.deeponet - INFO - Epoch 18/300\n",
      "2025-03-16 20:30:59,410 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.209327\n",
      "2025-03-16 20:30:59,410 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.206863\n",
      "Training progress:   6%|▌         | 18/300 [00:02<00:40,  6.94it/s]2025-03-16 20:30:59,548 - sciml.model.deeponet.deeponet - INFO - Epoch 19/300\n",
      "2025-03-16 20:30:59,549 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.204610\n",
      "2025-03-16 20:30:59,549 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.202953\n",
      "Training progress:   6%|▋         | 19/300 [00:02<00:40,  7.02it/s]2025-03-16 20:30:59,690 - sciml.model.deeponet.deeponet - INFO - Epoch 20/300\n",
      "2025-03-16 20:30:59,690 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.199853\n",
      "2025-03-16 20:30:59,691 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.199118\n",
      "Training progress:   7%|▋         | 20/300 [00:02<00:39,  7.03it/s]2025-03-16 20:30:59,827 - sciml.model.deeponet.deeponet - INFO - Epoch 21/300\n",
      "2025-03-16 20:30:59,828 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.195006\n",
      "2025-03-16 20:30:59,829 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.195296\n",
      "Training progress:   7%|▋         | 21/300 [00:02<00:39,  7.10it/s]2025-03-16 20:30:59,963 - sciml.model.deeponet.deeponet - INFO - Epoch 22/300\n",
      "2025-03-16 20:30:59,964 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.190102\n",
      "2025-03-16 20:30:59,965 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.191506\n",
      "Training progress:   7%|▋         | 22/300 [00:03<00:38,  7.17it/s]2025-03-16 20:31:00,100 - sciml.model.deeponet.deeponet - INFO - Epoch 23/300\n",
      "2025-03-16 20:31:00,101 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.185284\n",
      "2025-03-16 20:31:00,102 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.187759\n",
      "Training progress:   8%|▊         | 23/300 [00:03<00:38,  7.20it/s]2025-03-16 20:31:00,238 - sciml.model.deeponet.deeponet - INFO - Epoch 24/300\n",
      "2025-03-16 20:31:00,238 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.180554\n",
      "2025-03-16 20:31:00,239 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.184008\n",
      "Training progress:   8%|▊         | 24/300 [00:03<00:38,  7.24it/s]2025-03-16 20:31:00,376 - sciml.model.deeponet.deeponet - INFO - Epoch 25/300\n",
      "2025-03-16 20:31:00,377 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.175961\n",
      "2025-03-16 20:31:00,377 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.180377\n",
      "Training progress:   8%|▊         | 25/300 [00:03<00:38,  7.23it/s]2025-03-16 20:31:00,516 - sciml.model.deeponet.deeponet - INFO - Epoch 26/300\n",
      "2025-03-16 20:31:00,517 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.171506\n",
      "2025-03-16 20:31:00,518 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.176922\n",
      "Training progress:   9%|▊         | 26/300 [00:03<00:38,  7.19it/s]2025-03-16 20:31:00,672 - sciml.model.deeponet.deeponet - INFO - Epoch 27/300\n",
      "2025-03-16 20:31:00,673 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.167225\n",
      "2025-03-16 20:31:00,673 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.173736\n",
      "Training progress:   9%|▉         | 27/300 [00:03<00:39,  6.95it/s]2025-03-16 20:31:00,865 - sciml.model.deeponet.deeponet - INFO - Epoch 28/300\n",
      "2025-03-16 20:31:00,867 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.163178\n",
      "2025-03-16 20:31:00,869 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.170724\n",
      "Training progress:   9%|▉         | 28/300 [00:03<00:43,  6.27it/s]2025-03-16 20:31:01,055 - sciml.model.deeponet.deeponet - INFO - Epoch 29/300\n",
      "2025-03-16 20:31:01,056 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.159418\n",
      "2025-03-16 20:31:01,057 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.167803\n",
      "Training progress:  10%|▉         | 29/300 [00:04<00:45,  5.95it/s]2025-03-16 20:31:01,197 - sciml.model.deeponet.deeponet - INFO - Epoch 30/300\n",
      "2025-03-16 20:31:01,198 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.155937\n",
      "2025-03-16 20:31:01,199 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.165010\n",
      "Training progress:  10%|█         | 30/300 [00:04<00:43,  6.24it/s]2025-03-16 20:31:01,335 - sciml.model.deeponet.deeponet - INFO - Epoch 31/300\n",
      "2025-03-16 20:31:01,336 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.152785\n",
      "2025-03-16 20:31:01,337 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.162539\n",
      "Training progress:  10%|█         | 31/300 [00:04<00:41,  6.51it/s]2025-03-16 20:31:01,476 - sciml.model.deeponet.deeponet - INFO - Epoch 32/300\n",
      "2025-03-16 20:31:01,477 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.149980\n",
      "2025-03-16 20:31:01,478 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.160363\n",
      "Training progress:  11%|█         | 32/300 [00:04<00:40,  6.68it/s]2025-03-16 20:31:01,613 - sciml.model.deeponet.deeponet - INFO - Epoch 33/300\n",
      "2025-03-16 20:31:01,614 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.147540\n",
      "2025-03-16 20:31:01,614 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.158529\n",
      "Training progress:  11%|█         | 33/300 [00:04<00:38,  6.86it/s]2025-03-16 20:31:01,753 - sciml.model.deeponet.deeponet - INFO - Epoch 34/300\n",
      "2025-03-16 20:31:01,754 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.145496\n",
      "2025-03-16 20:31:01,755 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.156971\n",
      "Training progress:  11%|█▏        | 34/300 [00:04<00:38,  6.94it/s]2025-03-16 20:31:01,892 - sciml.model.deeponet.deeponet - INFO - Epoch 35/300\n",
      "2025-03-16 20:31:01,893 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.143767\n",
      "2025-03-16 20:31:01,894 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.155565\n",
      "Training progress:  12%|█▏        | 35/300 [00:05<00:37,  7.01it/s]2025-03-16 20:31:02,030 - sciml.model.deeponet.deeponet - INFO - Epoch 36/300\n",
      "2025-03-16 20:31:02,031 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.142229\n",
      "2025-03-16 20:31:02,032 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.154308\n",
      "Training progress:  12%|█▏        | 36/300 [00:05<00:37,  7.07it/s]2025-03-16 20:31:02,170 - sciml.model.deeponet.deeponet - INFO - Epoch 37/300\n",
      "2025-03-16 20:31:02,170 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.140800\n",
      "2025-03-16 20:31:02,171 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.153106\n",
      "Training progress:  12%|█▏        | 37/300 [00:05<00:36,  7.11it/s]2025-03-16 20:31:02,309 - sciml.model.deeponet.deeponet - INFO - Epoch 38/300\n",
      "2025-03-16 20:31:02,310 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.139442\n",
      "2025-03-16 20:31:02,310 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.151867\n",
      "Training progress:  13%|█▎        | 38/300 [00:05<00:36,  7.14it/s]2025-03-16 20:31:02,445 - sciml.model.deeponet.deeponet - INFO - Epoch 39/300\n",
      "2025-03-16 20:31:02,445 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.138142\n",
      "2025-03-16 20:31:02,446 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.150575\n",
      "Training progress:  13%|█▎        | 39/300 [00:05<00:36,  7.19it/s]2025-03-16 20:31:02,587 - sciml.model.deeponet.deeponet - INFO - Epoch 40/300\n",
      "2025-03-16 20:31:02,587 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.136896\n",
      "2025-03-16 20:31:02,588 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.149370\n",
      "Training progress:  13%|█▎        | 40/300 [00:05<00:36,  7.16it/s]2025-03-16 20:31:02,724 - sciml.model.deeponet.deeponet - INFO - Epoch 41/300\n",
      "2025-03-16 20:31:02,724 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.135721\n",
      "2025-03-16 20:31:02,725 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.148255\n",
      "Training progress:  14%|█▎        | 41/300 [00:05<00:35,  7.21it/s]2025-03-16 20:31:02,859 - sciml.model.deeponet.deeponet - INFO - Epoch 42/300\n",
      "2025-03-16 20:31:02,860 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.134629\n",
      "2025-03-16 20:31:02,861 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.147217\n",
      "Training progress:  14%|█▍        | 42/300 [00:05<00:35,  7.25it/s]2025-03-16 20:31:02,995 - sciml.model.deeponet.deeponet - INFO - Epoch 43/300\n",
      "2025-03-16 20:31:02,995 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.133610\n",
      "2025-03-16 20:31:02,996 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.146253\n",
      "Training progress:  14%|█▍        | 43/300 [00:06<00:35,  7.29it/s]2025-03-16 20:31:03,136 - sciml.model.deeponet.deeponet - INFO - Epoch 44/300\n",
      "2025-03-16 20:31:03,136 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.132642\n",
      "2025-03-16 20:31:03,137 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.145281\n",
      "Training progress:  15%|█▍        | 44/300 [00:06<00:35,  7.24it/s]2025-03-16 20:31:03,273 - sciml.model.deeponet.deeponet - INFO - Epoch 45/300\n",
      "2025-03-16 20:31:03,274 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.131678\n",
      "2025-03-16 20:31:03,275 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.144296\n",
      "Training progress:  15%|█▌        | 45/300 [00:06<00:35,  7.23it/s]2025-03-16 20:31:03,408 - sciml.model.deeponet.deeponet - INFO - Epoch 46/300\n",
      "2025-03-16 20:31:03,409 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.130685\n",
      "2025-03-16 20:31:03,410 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.143235\n",
      "Training progress:  15%|█▌        | 46/300 [00:06<00:34,  7.28it/s]2025-03-16 20:31:03,555 - sciml.model.deeponet.deeponet - INFO - Epoch 47/300\n",
      "2025-03-16 20:31:03,555 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.129647\n",
      "2025-03-16 20:31:03,556 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.142115\n",
      "Training progress:  16%|█▌        | 47/300 [00:06<00:35,  7.15it/s]2025-03-16 20:31:03,692 - sciml.model.deeponet.deeponet - INFO - Epoch 48/300\n",
      "2025-03-16 20:31:03,692 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.128603\n",
      "2025-03-16 20:31:03,693 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.140978\n",
      "Training progress:  16%|█▌        | 48/300 [00:06<00:35,  7.19it/s]2025-03-16 20:31:03,827 - sciml.model.deeponet.deeponet - INFO - Epoch 49/300\n",
      "2025-03-16 20:31:03,828 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.127592\n",
      "2025-03-16 20:31:03,829 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.139876\n",
      "Training progress:  16%|█▋        | 49/300 [00:06<00:34,  7.23it/s]2025-03-16 20:31:03,964 - sciml.model.deeponet.deeponet - INFO - Epoch 50/300\n",
      "2025-03-16 20:31:03,965 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.126634\n",
      "2025-03-16 20:31:03,966 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.138839\n",
      "Training progress:  17%|█▋        | 50/300 [00:07<00:34,  7.25it/s]2025-03-16 20:31:04,102 - sciml.model.deeponet.deeponet - INFO - Epoch 51/300\n",
      "2025-03-16 20:31:04,102 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.125744\n",
      "2025-03-16 20:31:04,103 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.137901\n",
      "Training progress:  17%|█▋        | 51/300 [00:07<00:34,  7.27it/s]2025-03-16 20:31:04,238 - sciml.model.deeponet.deeponet - INFO - Epoch 52/300\n",
      "2025-03-16 20:31:04,238 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.124935\n",
      "2025-03-16 20:31:04,239 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.137029\n",
      "Training progress:  17%|█▋        | 52/300 [00:07<00:33,  7.31it/s]2025-03-16 20:31:04,374 - sciml.model.deeponet.deeponet - INFO - Epoch 53/300\n",
      "2025-03-16 20:31:04,375 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.124168\n",
      "2025-03-16 20:31:04,376 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.136212\n",
      "Training progress:  18%|█▊        | 53/300 [00:07<00:33,  7.29it/s]2025-03-16 20:31:04,511 - sciml.model.deeponet.deeponet - INFO - Epoch 54/300\n",
      "2025-03-16 20:31:04,512 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.123397\n",
      "2025-03-16 20:31:04,512 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.135448\n",
      "Training progress:  18%|█▊        | 54/300 [00:07<00:33,  7.32it/s]2025-03-16 20:31:04,647 - sciml.model.deeponet.deeponet - INFO - Epoch 55/300\n",
      "2025-03-16 20:31:04,647 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.122634\n",
      "2025-03-16 20:31:04,648 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.134729\n",
      "Training progress:  18%|█▊        | 55/300 [00:07<00:33,  7.32it/s]2025-03-16 20:31:04,782 - sciml.model.deeponet.deeponet - INFO - Epoch 56/300\n",
      "2025-03-16 20:31:04,783 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.121858\n",
      "2025-03-16 20:31:04,784 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.134018\n",
      "Training progress:  19%|█▊        | 56/300 [00:07<00:33,  7.34it/s]2025-03-16 20:31:04,920 - sciml.model.deeponet.deeponet - INFO - Epoch 57/300\n",
      "2025-03-16 20:31:04,921 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.121062\n",
      "2025-03-16 20:31:04,922 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.133251\n",
      "Training progress:  19%|█▉        | 57/300 [00:08<00:33,  7.32it/s]2025-03-16 20:31:05,058 - sciml.model.deeponet.deeponet - INFO - Epoch 58/300\n",
      "2025-03-16 20:31:05,058 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.120252\n",
      "2025-03-16 20:31:05,059 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.132397\n",
      "Training progress:  19%|█▉        | 58/300 [00:08<00:33,  7.30it/s]2025-03-16 20:31:05,199 - sciml.model.deeponet.deeponet - INFO - Epoch 59/300\n",
      "2025-03-16 20:31:05,200 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.119437\n",
      "2025-03-16 20:31:05,201 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.131522\n",
      "Training progress:  20%|█▉        | 59/300 [00:08<00:33,  7.23it/s]2025-03-16 20:31:05,341 - sciml.model.deeponet.deeponet - INFO - Epoch 60/300\n",
      "2025-03-16 20:31:05,342 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.118613\n",
      "2025-03-16 20:31:05,342 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.130644\n",
      "Training progress:  20%|██        | 60/300 [00:08<00:33,  7.17it/s]2025-03-16 20:31:05,480 - sciml.model.deeponet.deeponet - INFO - Epoch 61/300\n",
      "2025-03-16 20:31:05,481 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.117783\n",
      "2025-03-16 20:31:05,481 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.129783\n",
      "Training progress:  20%|██        | 61/300 [00:08<00:33,  7.18it/s]2025-03-16 20:31:05,619 - sciml.model.deeponet.deeponet - INFO - Epoch 62/300\n",
      "2025-03-16 20:31:05,620 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.116965\n",
      "2025-03-16 20:31:05,620 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.128919\n",
      "Training progress:  21%|██        | 62/300 [00:08<00:33,  7.19it/s]2025-03-16 20:31:05,757 - sciml.model.deeponet.deeponet - INFO - Epoch 63/300\n",
      "2025-03-16 20:31:05,758 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.116178\n",
      "2025-03-16 20:31:05,759 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.128037\n",
      "Training progress:  21%|██        | 63/300 [00:08<00:33,  7.18it/s]2025-03-16 20:31:05,895 - sciml.model.deeponet.deeponet - INFO - Epoch 64/300\n",
      "2025-03-16 20:31:05,896 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.115420\n",
      "2025-03-16 20:31:05,897 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.127157\n",
      "Training progress:  21%|██▏       | 64/300 [00:09<00:32,  7.22it/s]2025-03-16 20:31:06,029 - sciml.model.deeponet.deeponet - INFO - Epoch 65/300\n",
      "2025-03-16 20:31:06,030 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.114684\n",
      "2025-03-16 20:31:06,031 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.126317\n",
      "Training progress:  22%|██▏       | 65/300 [00:09<00:32,  7.29it/s]2025-03-16 20:31:06,170 - sciml.model.deeponet.deeponet - INFO - Epoch 66/300\n",
      "2025-03-16 20:31:06,171 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.113979\n",
      "2025-03-16 20:31:06,172 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.125567\n",
      "Training progress:  22%|██▏       | 66/300 [00:09<00:32,  7.22it/s]2025-03-16 20:31:06,307 - sciml.model.deeponet.deeponet - INFO - Epoch 67/300\n",
      "2025-03-16 20:31:06,308 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.113293\n",
      "2025-03-16 20:31:06,309 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.124865\n",
      "Training progress:  22%|██▏       | 67/300 [00:09<00:32,  7.25it/s]2025-03-16 20:31:06,444 - sciml.model.deeponet.deeponet - INFO - Epoch 68/300\n",
      "2025-03-16 20:31:06,445 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.112630\n",
      "2025-03-16 20:31:06,445 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.124155\n",
      "Training progress:  23%|██▎       | 68/300 [00:09<00:31,  7.27it/s]2025-03-16 20:31:06,583 - sciml.model.deeponet.deeponet - INFO - Epoch 69/300\n",
      "2025-03-16 20:31:06,584 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.111985\n",
      "2025-03-16 20:31:06,584 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.123567\n",
      "Training progress:  23%|██▎       | 69/300 [00:09<00:31,  7.25it/s]2025-03-16 20:31:06,719 - sciml.model.deeponet.deeponet - INFO - Epoch 70/300\n",
      "2025-03-16 20:31:06,720 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.111361\n",
      "2025-03-16 20:31:06,721 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.122857\n",
      "Training progress:  23%|██▎       | 70/300 [00:09<00:31,  7.28it/s]2025-03-16 20:31:06,855 - sciml.model.deeponet.deeponet - INFO - Epoch 71/300\n",
      "2025-03-16 20:31:06,856 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.110746\n",
      "2025-03-16 20:31:06,857 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.122482\n",
      "Training progress:  24%|██▎       | 71/300 [00:09<00:31,  7.29it/s]2025-03-16 20:31:06,995 - sciml.model.deeponet.deeponet - INFO - Epoch 72/300\n",
      "2025-03-16 20:31:06,996 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.110150\n",
      "2025-03-16 20:31:06,996 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.121849\n",
      "Training progress:  24%|██▍       | 72/300 [00:10<00:31,  7.26it/s]2025-03-16 20:31:04,202 - sciml.model.deeponet.deeponet - INFO - Epoch 73/300\n",
      "2025-03-16 20:31:04,203 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.109605\n",
      "2025-03-16 20:31:04,204 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.121779\n",
      "2025-03-16 20:31:04,334 - sciml.model.deeponet.deeponet - INFO - Epoch 74/300\n",
      "2025-03-16 20:31:04,335 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.109120\n",
      "2025-03-16 20:31:04,336 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.121009\n",
      "2025-03-16 20:31:04,473 - sciml.model.deeponet.deeponet - INFO - Epoch 75/300\n",
      "2025-03-16 20:31:04,474 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.108807\n",
      "2025-03-16 20:31:04,474 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.121115\n",
      "2025-03-16 20:31:04,608 - sciml.model.deeponet.deeponet - INFO - Epoch 76/300\n",
      "2025-03-16 20:31:04,608 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.108199\n",
      "2025-03-16 20:31:04,609 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.120043\n",
      "2025-03-16 20:31:04,745 - sciml.model.deeponet.deeponet - INFO - Epoch 77/300\n",
      "2025-03-16 20:31:04,745 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.107473\n",
      "2025-03-16 20:31:04,746 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.119626\n",
      "2025-03-16 20:31:04,883 - sciml.model.deeponet.deeponet - INFO - Epoch 78/300\n",
      "2025-03-16 20:31:04,884 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.106868\n",
      "2025-03-16 20:31:04,885 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.119412\n",
      "2025-03-16 20:31:05,015 - sciml.model.deeponet.deeponet - INFO - Epoch 79/300\n",
      "2025-03-16 20:31:05,016 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.106572\n",
      "2025-03-16 20:31:05,016 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.118621\n",
      "2025-03-16 20:31:05,150 - sciml.model.deeponet.deeponet - INFO - Epoch 80/300\n",
      "2025-03-16 20:31:05,151 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.106248\n",
      "2025-03-16 20:31:05,152 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.118230\n",
      "2025-03-16 20:31:05,284 - sciml.model.deeponet.deeponet - INFO - Epoch 81/300\n",
      "2025-03-16 20:31:05,285 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.105600\n",
      "2025-03-16 20:31:05,285 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.117562\n",
      "2025-03-16 20:31:05,419 - sciml.model.deeponet.deeponet - INFO - Epoch 82/300\n",
      "2025-03-16 20:31:05,420 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.105109\n",
      "2025-03-16 20:31:05,421 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.116937\n",
      "2025-03-16 20:31:05,553 - sciml.model.deeponet.deeponet - INFO - Epoch 83/300\n",
      "2025-03-16 20:31:05,553 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.104853\n",
      "2025-03-16 20:31:05,554 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.116634\n",
      "2025-03-16 20:31:05,685 - sciml.model.deeponet.deeponet - INFO - Epoch 84/300\n",
      "2025-03-16 20:31:05,685 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.104457\n",
      "2025-03-16 20:31:05,686 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.115904\n",
      "2025-03-16 20:31:05,825 - sciml.model.deeponet.deeponet - INFO - Epoch 85/300\n",
      "2025-03-16 20:31:05,825 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.103930\n",
      "2025-03-16 20:31:05,826 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.115475\n",
      "2025-03-16 20:31:05,956 - sciml.model.deeponet.deeponet - INFO - Epoch 86/300\n",
      "2025-03-16 20:31:05,957 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.103411\n",
      "2025-03-16 20:31:05,958 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.115150\n",
      "2025-03-16 20:31:06,092 - sciml.model.deeponet.deeponet - INFO - Epoch 87/300\n",
      "2025-03-16 20:31:06,093 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.103082\n",
      "2025-03-16 20:31:06,093 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.114703\n",
      "2025-03-16 20:31:06,225 - sciml.model.deeponet.deeponet - INFO - Epoch 88/300\n",
      "2025-03-16 20:31:06,225 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.102832\n",
      "2025-03-16 20:31:06,226 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.114480\n",
      "2025-03-16 20:31:06,360 - sciml.model.deeponet.deeponet - INFO - Epoch 89/300\n",
      "2025-03-16 20:31:06,362 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.102386\n",
      "2025-03-16 20:31:06,362 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.113895\n",
      "2025-03-16 20:31:06,494 - sciml.model.deeponet.deeponet - INFO - Epoch 90/300\n",
      "2025-03-16 20:31:06,496 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.101835\n",
      "2025-03-16 20:31:06,496 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.113545\n",
      "2025-03-16 20:31:06,630 - sciml.model.deeponet.deeponet - INFO - Epoch 91/300\n",
      "2025-03-16 20:31:06,631 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.101385\n",
      "2025-03-16 20:31:06,632 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.113355\n",
      "2025-03-16 20:31:06,764 - sciml.model.deeponet.deeponet - INFO - Epoch 92/300\n",
      "2025-03-16 20:31:06,765 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.101094\n",
      "2025-03-16 20:31:06,765 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.112872\n",
      "2025-03-16 20:31:06,898 - sciml.model.deeponet.deeponet - INFO - Epoch 93/300\n",
      "2025-03-16 20:31:06,898 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.100840\n",
      "2025-03-16 20:31:06,899 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.112843\n",
      "2025-03-16 20:31:07,083 - sciml.model.deeponet.deeponet - INFO - Epoch 94/300\n",
      "2025-03-16 20:31:07,084 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.100433\n",
      "2025-03-16 20:31:07,085 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.112190\n",
      "2025-03-16 20:31:07,246 - sciml.model.deeponet.deeponet - INFO - Epoch 95/300\n",
      "2025-03-16 20:31:07,246 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.099959\n",
      "2025-03-16 20:31:07,247 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.112008\n",
      "Training progress:  32%|███▏      | 95/300 [00:10<00:04, 44.26it/s]2025-03-16 20:31:07,387 - sciml.model.deeponet.deeponet - INFO - Epoch 96/300\n",
      "2025-03-16 20:31:07,388 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.099521\n",
      "2025-03-16 20:31:07,389 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.111750\n",
      "2025-03-16 20:31:07,520 - sciml.model.deeponet.deeponet - INFO - Epoch 97/300\n",
      "2025-03-16 20:31:07,521 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.099184\n",
      "2025-03-16 20:31:07,522 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.111281\n",
      "2025-03-16 20:31:07,656 - sciml.model.deeponet.deeponet - INFO - Epoch 98/300\n",
      "2025-03-16 20:31:07,656 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.098917\n",
      "2025-03-16 20:31:07,657 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.111718\n",
      "2025-03-16 20:31:07,791 - sciml.model.deeponet.deeponet - INFO - Epoch 99/300\n",
      "2025-03-16 20:31:07,792 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.098663\n",
      "2025-03-16 20:31:07,793 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.110903\n",
      "Training progress:  33%|███▎      | 99/300 [00:10<00:08, 22.97it/s]2025-03-16 20:31:07,949 - sciml.model.deeponet.deeponet - INFO - Epoch 100/300\n",
      "2025-03-16 20:31:07,949 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.098391\n",
      "2025-03-16 20:31:07,950 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.111605\n",
      "2025-03-16 20:31:08,121 - sciml.model.deeponet.deeponet - INFO - Epoch 101/300\n",
      "2025-03-16 20:31:08,122 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.098011\n",
      "2025-03-16 20:31:08,131 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.110626\n",
      "2025-03-16 20:31:08,272 - sciml.model.deeponet.deeponet - INFO - Epoch 102/300\n",
      "2025-03-16 20:31:08,272 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.097634\n",
      "2025-03-16 20:31:08,273 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.111111\n",
      "Training progress:  34%|███▍      | 102/300 [00:11<00:12, 15.94it/s]2025-03-16 20:31:08,406 - sciml.model.deeponet.deeponet - INFO - Epoch 103/300\n",
      "2025-03-16 20:31:08,407 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.097224\n",
      "2025-03-16 20:31:08,408 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.110678\n",
      "2025-03-16 20:31:08,546 - sciml.model.deeponet.deeponet - INFO - Epoch 104/300\n",
      "2025-03-16 20:31:08,547 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.096878\n",
      "2025-03-16 20:31:08,548 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.110905\n",
      "Training progress:  35%|███▍      | 104/300 [00:11<00:14, 13.72it/s]2025-03-16 20:31:08,679 - sciml.model.deeponet.deeponet - INFO - Epoch 105/300\n",
      "2025-03-16 20:31:08,680 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.096561\n",
      "2025-03-16 20:31:08,681 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.111117\n",
      "2025-03-16 20:31:08,815 - sciml.model.deeponet.deeponet - INFO - Epoch 106/300\n",
      "2025-03-16 20:31:08,816 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.096274\n",
      "2025-03-16 20:31:08,816 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.110913\n",
      "Training progress:  35%|███▌      | 106/300 [00:11<00:16, 12.07it/s]2025-03-16 20:31:08,954 - sciml.model.deeponet.deeponet - INFO - Epoch 107/300\n",
      "2025-03-16 20:31:08,955 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.096008\n",
      "2025-03-16 20:31:08,956 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.111729\n",
      "2025-03-16 20:31:09,087 - sciml.model.deeponet.deeponet - INFO - Epoch 108/300\n",
      "2025-03-16 20:31:09,088 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.095776\n",
      "2025-03-16 20:31:09,089 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.110758\n",
      "Training progress:  36%|███▌      | 108/300 [00:12<00:17, 10.77it/s]2025-03-16 20:31:09,233 - sciml.model.deeponet.deeponet - INFO - Epoch 109/300\n",
      "2025-03-16 20:31:09,233 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.095608\n",
      "2025-03-16 20:31:09,234 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.112650\n",
      "2025-03-16 20:31:09,394 - sciml.model.deeponet.deeponet - INFO - Epoch 110/300\n",
      "2025-03-16 20:31:09,395 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.095492\n",
      "2025-03-16 20:31:09,396 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.110431\n",
      "Training progress:  37%|███▋      | 110/300 [00:12<00:20,  9.46it/s]2025-03-16 20:31:09,534 - sciml.model.deeponet.deeponet - INFO - Epoch 111/300\n",
      "2025-03-16 20:31:09,534 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.095597\n",
      "2025-03-16 20:31:09,535 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.113781\n",
      "Training progress:  37%|███▋      | 111/300 [00:12<00:20,  9.08it/s]2025-03-16 20:31:09,681 - sciml.model.deeponet.deeponet - INFO - Epoch 112/300\n",
      "2025-03-16 20:31:09,681 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.095406\n",
      "2025-03-16 20:31:09,682 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.110414\n",
      "Training progress:  37%|███▋      | 112/300 [00:12<00:21,  8.63it/s]2025-03-16 20:31:09,825 - sciml.model.deeponet.deeponet - INFO - Epoch 113/300\n",
      "2025-03-16 20:31:09,826 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.095162\n",
      "2025-03-16 20:31:09,826 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.112537\n",
      "Training progress:  38%|███▊      | 113/300 [00:12<00:22,  8.25it/s]2025-03-16 20:31:09,967 - sciml.model.deeponet.deeponet - INFO - Epoch 114/300\n",
      "2025-03-16 20:31:09,968 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.094250\n",
      "2025-03-16 20:31:09,969 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.112221\n",
      "Training progress:  38%|███▊      | 114/300 [00:13<00:23,  7.96it/s]2025-03-16 20:31:10,122 - sciml.model.deeponet.deeponet - INFO - Epoch 115/300\n",
      "2025-03-16 20:31:10,123 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.093893\n",
      "2025-03-16 20:31:10,123 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.110624\n",
      "Training progress:  38%|███▊      | 115/300 [00:13<00:24,  7.56it/s]2025-03-16 20:31:10,266 - sciml.model.deeponet.deeponet - INFO - Epoch 116/300\n",
      "2025-03-16 20:31:10,267 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.094053\n",
      "2025-03-16 20:31:10,267 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.113124\n",
      "Training progress:  39%|███▊      | 116/300 [00:13<00:24,  7.40it/s]2025-03-16 20:31:10,414 - sciml.model.deeponet.deeponet - INFO - Epoch 117/300\n",
      "2025-03-16 20:31:10,415 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.093862\n",
      "2025-03-16 20:31:10,416 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.109157\n",
      "Training progress:  39%|███▉      | 117/300 [00:13<00:25,  7.22it/s]2025-03-16 20:31:10,561 - sciml.model.deeponet.deeponet - INFO - Epoch 118/300\n",
      "2025-03-16 20:31:10,562 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.093434\n",
      "2025-03-16 20:31:10,562 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.109151\n",
      "Training progress:  39%|███▉      | 118/300 [00:13<00:25,  7.10it/s]2025-03-16 20:31:10,700 - sciml.model.deeponet.deeponet - INFO - Epoch 119/300\n",
      "2025-03-16 20:31:10,700 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.092861\n",
      "2025-03-16 20:31:10,701 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.108834\n",
      "Training progress:  40%|███▉      | 119/300 [00:13<00:25,  7.14it/s]2025-03-16 20:31:10,842 - sciml.model.deeponet.deeponet - INFO - Epoch 120/300\n",
      "2025-03-16 20:31:10,843 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.092779\n",
      "2025-03-16 20:31:10,844 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.106719\n",
      "Training progress:  40%|████      | 120/300 [00:13<00:25,  7.09it/s]2025-03-16 20:31:10,987 - sciml.model.deeponet.deeponet - INFO - Epoch 121/300\n",
      "2025-03-16 20:31:10,987 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.092884\n",
      "2025-03-16 20:31:10,988 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.107498\n",
      "Training progress:  40%|████      | 121/300 [00:14<00:25,  7.05it/s]2025-03-16 20:31:11,129 - sciml.model.deeponet.deeponet - INFO - Epoch 122/300\n",
      "2025-03-16 20:31:11,130 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.092438\n",
      "2025-03-16 20:31:11,130 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.105851\n",
      "Training progress:  41%|████      | 122/300 [00:14<00:25,  7.04it/s]2025-03-16 20:31:11,272 - sciml.model.deeponet.deeponet - INFO - Epoch 123/300\n",
      "2025-03-16 20:31:11,273 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.091955\n",
      "2025-03-16 20:31:11,273 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.105277\n",
      "Training progress:  41%|████      | 123/300 [00:14<00:25,  7.03it/s]2025-03-16 20:31:11,420 - sciml.model.deeponet.deeponet - INFO - Epoch 124/300\n",
      "2025-03-16 20:31:11,421 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.091758\n",
      "2025-03-16 20:31:11,422 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.105745\n",
      "Training progress:  41%|████▏     | 124/300 [00:14<00:25,  6.93it/s]2025-03-16 20:31:11,564 - sciml.model.deeponet.deeponet - INFO - Epoch 125/300\n",
      "2025-03-16 20:31:11,565 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.091767\n",
      "2025-03-16 20:31:11,566 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.104302\n",
      "Training progress:  42%|████▏     | 125/300 [00:14<00:25,  6.94it/s]2025-03-16 20:31:11,702 - sciml.model.deeponet.deeponet - INFO - Epoch 126/300\n",
      "2025-03-16 20:31:11,702 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.091688\n",
      "2025-03-16 20:31:11,703 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.104682\n",
      "Training progress:  42%|████▏     | 126/300 [00:14<00:24,  7.04it/s]2025-03-16 20:31:11,841 - sciml.model.deeponet.deeponet - INFO - Epoch 127/300\n",
      "2025-03-16 20:31:11,842 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.091220\n",
      "2025-03-16 20:31:11,843 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.103967\n",
      "Training progress:  42%|████▏     | 127/300 [00:14<00:24,  7.08it/s]2025-03-16 20:31:11,985 - sciml.model.deeponet.deeponet - INFO - Epoch 128/300\n",
      "2025-03-16 20:31:11,985 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.090861\n",
      "2025-03-16 20:31:11,986 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.103497\n",
      "Training progress:  43%|████▎     | 128/300 [00:15<00:24,  7.04it/s]2025-03-16 20:31:12,122 - sciml.model.deeponet.deeponet - INFO - Epoch 129/300\n",
      "2025-03-16 20:31:12,123 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.090774\n",
      "2025-03-16 20:31:12,124 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.103810\n",
      "Training progress:  43%|████▎     | 129/300 [00:15<00:24,  7.11it/s]2025-03-16 20:31:12,269 - sciml.model.deeponet.deeponet - INFO - Epoch 130/300\n",
      "2025-03-16 20:31:12,270 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.090703\n",
      "2025-03-16 20:31:12,271 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.102695\n",
      "Training progress:  43%|████▎     | 130/300 [00:15<00:24,  7.01it/s]2025-03-16 20:31:12,423 - sciml.model.deeponet.deeponet - INFO - Epoch 131/300\n",
      "2025-03-16 20:31:12,423 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.090496\n",
      "2025-03-16 20:31:12,424 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.102806\n",
      "Training progress:  44%|████▎     | 131/300 [00:15<00:24,  6.86it/s]2025-03-16 20:31:12,564 - sciml.model.deeponet.deeponet - INFO - Epoch 132/300\n",
      "2025-03-16 20:31:12,565 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.090151\n",
      "2025-03-16 20:31:12,565 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.102589\n",
      "Training progress:  44%|████▍     | 132/300 [00:15<00:24,  6.93it/s]2025-03-16 20:31:12,700 - sciml.model.deeponet.deeponet - INFO - Epoch 133/300\n",
      "2025-03-16 20:31:12,700 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.089943\n",
      "2025-03-16 20:31:12,701 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.102244\n",
      "Training progress:  44%|████▍     | 133/300 [00:15<00:23,  7.05it/s]2025-03-16 20:31:12,837 - sciml.model.deeponet.deeponet - INFO - Epoch 134/300\n",
      "2025-03-16 20:31:12,838 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.089872\n",
      "2025-03-16 20:31:12,838 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.102570\n",
      "Training progress:  45%|████▍     | 134/300 [00:15<00:23,  7.12it/s]2025-03-16 20:31:12,975 - sciml.model.deeponet.deeponet - INFO - Epoch 135/300\n",
      "2025-03-16 20:31:12,975 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.089818\n",
      "2025-03-16 20:31:12,976 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.101682\n",
      "Training progress:  45%|████▌     | 135/300 [00:16<00:23,  7.16it/s]2025-03-16 20:31:13,111 - sciml.model.deeponet.deeponet - INFO - Epoch 136/300\n",
      "2025-03-16 20:31:13,112 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.089683\n",
      "2025-03-16 20:31:13,113 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.101896\n",
      "Training progress:  45%|████▌     | 136/300 [00:16<00:22,  7.21it/s]2025-03-16 20:31:13,246 - sciml.model.deeponet.deeponet - INFO - Epoch 137/300\n",
      "2025-03-16 20:31:13,247 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.089390\n",
      "2025-03-16 20:31:13,248 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.101445\n",
      "Training progress:  46%|████▌     | 137/300 [00:16<00:22,  7.27it/s]2025-03-16 20:31:13,387 - sciml.model.deeponet.deeponet - INFO - Epoch 138/300\n",
      "2025-03-16 20:31:13,387 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.089152\n",
      "2025-03-16 20:31:13,388 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.101281\n",
      "Training progress:  46%|████▌     | 138/300 [00:16<00:22,  7.22it/s]2025-03-16 20:31:13,526 - sciml.model.deeponet.deeponet - INFO - Epoch 139/300\n",
      "2025-03-16 20:31:13,527 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.089001\n",
      "2025-03-16 20:31:13,527 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.101520\n",
      "Training progress:  46%|████▋     | 139/300 [00:16<00:22,  7.21it/s]2025-03-16 20:31:13,660 - sciml.model.deeponet.deeponet - INFO - Epoch 140/300\n",
      "2025-03-16 20:31:13,661 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.088935\n",
      "2025-03-16 20:31:13,662 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.101011\n",
      "Training progress:  47%|████▋     | 140/300 [00:16<00:21,  7.28it/s]2025-03-16 20:31:13,802 - sciml.model.deeponet.deeponet - INFO - Epoch 141/300\n",
      "2025-03-16 20:31:13,803 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.088856\n",
      "2025-03-16 20:31:13,803 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.101473\n",
      "Training progress:  47%|████▋     | 141/300 [00:16<00:22,  7.22it/s]2025-03-16 20:31:13,979 - sciml.model.deeponet.deeponet - INFO - Epoch 142/300\n",
      "2025-03-16 20:31:13,980 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.088702\n",
      "2025-03-16 20:31:13,981 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.100756\n",
      "Training progress:  47%|████▋     | 142/300 [00:17<00:23,  6.65it/s]2025-03-16 20:31:14,131 - sciml.model.deeponet.deeponet - INFO - Epoch 143/300\n",
      "2025-03-16 20:31:14,132 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.088519\n",
      "2025-03-16 20:31:14,132 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.100932\n",
      "Training progress:  48%|████▊     | 143/300 [00:17<00:23,  6.64it/s]2025-03-16 20:31:14,267 - sciml.model.deeponet.deeponet - INFO - Epoch 144/300\n",
      "2025-03-16 20:31:14,268 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.088309\n",
      "2025-03-16 20:31:14,268 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.100792\n",
      "Training progress:  48%|████▊     | 144/300 [00:17<00:22,  6.83it/s]2025-03-16 20:31:14,404 - sciml.model.deeponet.deeponet - INFO - Epoch 145/300\n",
      "2025-03-16 20:31:14,405 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.088140\n",
      "2025-03-16 20:31:14,405 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.100727\n",
      "Training progress:  48%|████▊     | 145/300 [00:17<00:22,  6.98it/s]2025-03-16 20:31:14,544 - sciml.model.deeponet.deeponet - INFO - Epoch 146/300\n",
      "2025-03-16 20:31:14,545 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.088027\n",
      "2025-03-16 20:31:14,545 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.100982\n",
      "Training progress:  49%|████▊     | 146/300 [00:17<00:21,  7.01it/s]2025-03-16 20:31:14,680 - sciml.model.deeponet.deeponet - INFO - Epoch 147/300\n",
      "2025-03-16 20:31:14,680 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.087932\n",
      "2025-03-16 20:31:14,681 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.100441\n",
      "Training progress:  49%|████▉     | 147/300 [00:17<00:21,  7.12it/s]2025-03-16 20:31:14,816 - sciml.model.deeponet.deeponet - INFO - Epoch 148/300\n",
      "2025-03-16 20:31:14,817 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.087861\n",
      "2025-03-16 20:31:14,817 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.101177\n",
      "Training progress:  49%|████▉     | 148/300 [00:17<00:21,  7.19it/s]2025-03-16 20:31:14,952 - sciml.model.deeponet.deeponet - INFO - Epoch 149/300\n",
      "2025-03-16 20:31:14,953 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.087752\n",
      "2025-03-16 20:31:14,953 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.100604\n",
      "Training progress:  50%|████▉     | 149/300 [00:18<00:20,  7.24it/s]2025-03-16 20:31:15,091 - sciml.model.deeponet.deeponet - INFO - Epoch 150/300\n",
      "2025-03-16 20:31:15,092 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.087650\n",
      "2025-03-16 20:31:15,092 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.101624\n",
      "Training progress:  50%|█████     | 150/300 [00:18<00:20,  7.22it/s]2025-03-16 20:31:15,227 - sciml.model.deeponet.deeponet - INFO - Epoch 151/300\n",
      "2025-03-16 20:31:15,228 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.087530\n",
      "2025-03-16 20:31:15,229 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.100912\n",
      "Training progress:  50%|█████     | 151/300 [00:18<00:20,  7.25it/s]2025-03-16 20:31:15,365 - sciml.model.deeponet.deeponet - INFO - Epoch 152/300\n",
      "2025-03-16 20:31:15,366 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.087422\n",
      "2025-03-16 20:31:15,366 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.101916\n",
      "Training progress:  51%|█████     | 152/300 [00:18<00:20,  7.26it/s]2025-03-16 20:31:15,504 - sciml.model.deeponet.deeponet - INFO - Epoch 153/300\n",
      "2025-03-16 20:31:15,505 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.087269\n",
      "2025-03-16 20:31:15,505 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.101326\n",
      "Training progress:  51%|█████     | 153/300 [00:18<00:20,  7.24it/s]2025-03-16 20:31:15,653 - sciml.model.deeponet.deeponet - INFO - Epoch 154/300\n",
      "2025-03-16 20:31:15,653 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.087124\n",
      "2025-03-16 20:31:15,654 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.102128\n",
      "Training progress:  51%|█████▏    | 154/300 [00:18<00:20,  7.08it/s]2025-03-16 20:31:15,787 - sciml.model.deeponet.deeponet - INFO - Epoch 155/300\n",
      "2025-03-16 20:31:15,788 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.086983\n",
      "2025-03-16 20:31:15,788 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.101845\n",
      "Training progress:  52%|█████▏    | 155/300 [00:18<00:20,  7.18it/s]2025-03-16 20:31:15,926 - sciml.model.deeponet.deeponet - INFO - Epoch 156/300\n",
      "2025-03-16 20:31:15,927 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.086864\n",
      "2025-03-16 20:31:15,927 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.102496\n",
      "Training progress:  52%|█████▏    | 156/300 [00:19<00:20,  7.18it/s]2025-03-16 20:31:16,064 - sciml.model.deeponet.deeponet - INFO - Epoch 157/300\n",
      "2025-03-16 20:31:16,065 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.086749\n",
      "2025-03-16 20:31:16,065 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.102590\n",
      "Training progress:  52%|█████▏    | 157/300 [00:19<00:19,  7.21it/s]2025-03-16 20:31:16,203 - sciml.model.deeponet.deeponet - INFO - Epoch 158/300\n",
      "2025-03-16 20:31:16,204 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.086638\n",
      "2025-03-16 20:31:16,204 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.103023\n",
      "Training progress:  53%|█████▎    | 158/300 [00:19<00:19,  7.20it/s]2025-03-16 20:31:16,341 - sciml.model.deeponet.deeponet - INFO - Epoch 159/300\n",
      "2025-03-16 20:31:16,342 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.086533\n",
      "2025-03-16 20:31:16,342 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.103482\n",
      "Training progress:  53%|█████▎    | 159/300 [00:19<00:19,  7.22it/s]2025-03-16 20:31:16,485 - sciml.model.deeponet.deeponet - INFO - Epoch 160/300\n",
      "2025-03-16 20:31:16,485 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.086434\n",
      "2025-03-16 20:31:16,486 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.103643\n",
      "Training progress:  53%|█████▎    | 160/300 [00:19<00:19,  7.14it/s]2025-03-16 20:31:16,626 - sciml.model.deeponet.deeponet - INFO - Epoch 161/300\n",
      "2025-03-16 20:31:16,626 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.086342\n",
      "2025-03-16 20:31:16,627 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.103143\n",
      "Training progress:  54%|█████▎    | 161/300 [00:19<00:19,  7.12it/s]2025-03-16 20:31:16,763 - sciml.model.deeponet.deeponet - INFO - Epoch 162/300\n",
      "2025-03-16 20:31:16,764 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.086251\n",
      "2025-03-16 20:31:16,764 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.101762\n",
      "Training progress:  54%|█████▍    | 162/300 [00:19<00:19,  7.18it/s]2025-03-16 20:31:16,900 - sciml.model.deeponet.deeponet - INFO - Epoch 163/300\n",
      "2025-03-16 20:31:16,901 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.086179\n",
      "2025-03-16 20:31:16,902 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.102121\n",
      "Training progress:  54%|█████▍    | 163/300 [00:20<00:19,  7.20it/s]2025-03-16 20:31:17,037 - sciml.model.deeponet.deeponet - INFO - Epoch 164/300\n",
      "2025-03-16 20:31:17,037 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.086152\n",
      "2025-03-16 20:31:17,038 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.100466\n",
      "Training progress:  55%|█████▍    | 164/300 [00:20<00:18,  7.24it/s]2025-03-16 20:31:17,173 - sciml.model.deeponet.deeponet - INFO - Epoch 165/300\n",
      "2025-03-16 20:31:17,173 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.086257\n",
      "2025-03-16 20:31:17,174 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.102684\n",
      "Training progress:  55%|█████▌    | 165/300 [00:20<00:18,  7.27it/s]2025-03-16 20:31:17,313 - sciml.model.deeponet.deeponet - INFO - Epoch 166/300\n",
      "2025-03-16 20:31:17,314 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.086551\n",
      "2025-03-16 20:31:17,323 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.100153\n",
      "Training progress:  55%|█████▌    | 166/300 [00:20<00:18,  7.09it/s]2025-03-16 20:31:17,469 - sciml.model.deeponet.deeponet - INFO - Epoch 167/300\n",
      "2025-03-16 20:31:17,470 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.087548\n",
      "2025-03-16 20:31:17,470 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.103778\n",
      "Training progress:  56%|█████▌    | 167/300 [00:20<00:18,  7.00it/s]2025-03-16 20:31:17,606 - sciml.model.deeponet.deeponet - INFO - Epoch 168/300\n",
      "2025-03-16 20:31:17,607 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.087580\n",
      "2025-03-16 20:31:17,608 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.099832\n",
      "Training progress:  56%|█████▌    | 168/300 [00:20<00:18,  7.08it/s]2025-03-16 20:31:17,746 - sciml.model.deeponet.deeponet - INFO - Epoch 169/300\n",
      "2025-03-16 20:31:17,747 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.087360\n",
      "2025-03-16 20:31:17,748 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.100908\n",
      "Training progress:  56%|█████▋    | 169/300 [00:20<00:18,  7.10it/s]2025-03-16 20:31:17,882 - sciml.model.deeponet.deeponet - INFO - Epoch 170/300\n",
      "2025-03-16 20:31:17,883 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.085642\n",
      "2025-03-16 20:31:17,884 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.101815\n",
      "Training progress:  57%|█████▋    | 170/300 [00:21<00:18,  7.17it/s]2025-03-16 20:31:18,023 - sciml.model.deeponet.deeponet - INFO - Epoch 171/300\n",
      "2025-03-16 20:31:18,023 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.085943\n",
      "2025-03-16 20:31:18,024 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.099714\n",
      "Training progress:  57%|█████▋    | 171/300 [00:21<00:18,  7.16it/s]2025-03-16 20:31:18,162 - sciml.model.deeponet.deeponet - INFO - Epoch 172/300\n",
      "2025-03-16 20:31:18,162 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.087132\n",
      "2025-03-16 20:31:18,163 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.101744\n",
      "Training progress:  57%|█████▋    | 172/300 [00:21<00:17,  7.18it/s]2025-03-16 20:31:18,299 - sciml.model.deeponet.deeponet - INFO - Epoch 173/300\n",
      "2025-03-16 20:31:18,300 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.085814\n",
      "2025-03-16 20:31:18,301 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.100754\n",
      "Training progress:  58%|█████▊    | 173/300 [00:21<00:17,  7.19it/s]2025-03-16 20:31:18,440 - sciml.model.deeponet.deeponet - INFO - Epoch 174/300\n",
      "2025-03-16 20:31:18,440 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.085252\n",
      "2025-03-16 20:31:18,441 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.099714\n",
      "Training progress:  58%|█████▊    | 174/300 [00:21<00:17,  7.18it/s]2025-03-16 20:31:18,576 - sciml.model.deeponet.deeponet - INFO - Epoch 175/300\n",
      "2025-03-16 20:31:18,576 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.085998\n",
      "2025-03-16 20:31:18,577 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.102325\n",
      "Training progress:  58%|█████▊    | 175/300 [00:21<00:17,  7.23it/s]2025-03-16 20:31:18,713 - sciml.model.deeponet.deeponet - INFO - Epoch 176/300\n",
      "2025-03-16 20:31:18,714 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.085539\n",
      "2025-03-16 20:31:18,715 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.100654\n",
      "Training progress:  59%|█████▊    | 176/300 [00:21<00:17,  7.24it/s]2025-03-16 20:31:18,848 - sciml.model.deeponet.deeponet - INFO - Epoch 177/300\n",
      "2025-03-16 20:31:18,850 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084977\n",
      "2025-03-16 20:31:18,850 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.100158\n",
      "Training progress:  59%|█████▉    | 177/300 [00:21<00:16,  7.28it/s]2025-03-16 20:31:18,990 - sciml.model.deeponet.deeponet - INFO - Epoch 178/300\n",
      "2025-03-16 20:31:18,991 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.085205\n",
      "2025-03-16 20:31:18,991 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.102849\n",
      "Training progress:  59%|█████▉    | 178/300 [00:22<00:16,  7.23it/s]2025-03-16 20:31:19,125 - sciml.model.deeponet.deeponet - INFO - Epoch 179/300\n",
      "2025-03-16 20:31:19,125 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.085248\n",
      "2025-03-16 20:31:19,126 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.100664\n",
      "Training progress:  60%|█████▉    | 179/300 [00:22<00:16,  7.28it/s]2025-03-16 20:31:19,260 - sciml.model.deeponet.deeponet - INFO - Epoch 180/300\n",
      "2025-03-16 20:31:19,261 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084866\n",
      "2025-03-16 20:31:19,261 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.099535\n",
      "Training progress:  60%|██████    | 180/300 [00:22<00:16,  7.31it/s]2025-03-16 20:31:19,402 - sciml.model.deeponet.deeponet - INFO - Epoch 181/300\n",
      "2025-03-16 20:31:19,403 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084732\n",
      "2025-03-16 20:31:19,404 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.099976\n",
      "Training progress:  60%|██████    | 181/300 [00:22<00:16,  7.22it/s]2025-03-16 20:31:19,540 - sciml.model.deeponet.deeponet - INFO - Epoch 182/300\n",
      "2025-03-16 20:31:19,541 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084920\n",
      "2025-03-16 20:31:19,541 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.097855\n",
      "Training progress:  61%|██████    | 182/300 [00:22<00:16,  7.24it/s]2025-03-16 20:31:19,677 - sciml.model.deeponet.deeponet - INFO - Epoch 183/300\n",
      "2025-03-16 20:31:19,678 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084799\n",
      "2025-03-16 20:31:19,679 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.097453\n",
      "Training progress:  61%|██████    | 183/300 [00:22<00:16,  7.24it/s]2025-03-16 20:31:19,824 - sciml.model.deeponet.deeponet - INFO - Epoch 184/300\n",
      "2025-03-16 20:31:19,824 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084479\n",
      "2025-03-16 20:31:19,825 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.097401\n",
      "Training progress:  61%|██████▏   | 184/300 [00:22<00:16,  7.12it/s]2025-03-16 20:31:19,961 - sciml.model.deeponet.deeponet - INFO - Epoch 185/300\n",
      "2025-03-16 20:31:19,962 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084615\n",
      "2025-03-16 20:31:19,963 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.096582\n",
      "Training progress:  62%|██████▏   | 185/300 [00:23<00:16,  7.16it/s]2025-03-16 20:31:20,097 - sciml.model.deeponet.deeponet - INFO - Epoch 186/300\n",
      "2025-03-16 20:31:20,098 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084708\n",
      "2025-03-16 20:31:20,098 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.096564\n",
      "Training progress:  62%|██████▏   | 186/300 [00:23<00:15,  7.23it/s]2025-03-16 20:31:20,243 - sciml.model.deeponet.deeponet - INFO - Epoch 187/300\n",
      "2025-03-16 20:31:20,244 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084333\n",
      "2025-03-16 20:31:20,244 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.096356\n",
      "Training progress:  62%|██████▏   | 187/300 [00:23<00:15,  7.10it/s]2025-03-16 20:31:20,382 - sciml.model.deeponet.deeponet - INFO - Epoch 188/300\n",
      "2025-03-16 20:31:20,382 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084296\n",
      "2025-03-16 20:31:20,383 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.096024\n",
      "Training progress:  63%|██████▎   | 188/300 [00:23<00:15,  7.14it/s]2025-03-16 20:31:20,516 - sciml.model.deeponet.deeponet - INFO - Epoch 189/300\n",
      "2025-03-16 20:31:20,516 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084458\n",
      "2025-03-16 20:31:20,517 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.095931\n",
      "Training progress:  63%|██████▎   | 189/300 [00:23<00:15,  7.22it/s]2025-03-16 20:31:20,655 - sciml.model.deeponet.deeponet - INFO - Epoch 190/300\n",
      "2025-03-16 20:31:20,655 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084219\n",
      "2025-03-16 20:31:20,656 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.095439\n",
      "Training progress:  63%|██████▎   | 190/300 [00:23<00:15,  7.22it/s]2025-03-16 20:31:20,793 - sciml.model.deeponet.deeponet - INFO - Epoch 191/300\n",
      "2025-03-16 20:31:20,794 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084034\n",
      "2025-03-16 20:31:20,794 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.095359\n",
      "Training progress:  64%|██████▎   | 191/300 [00:23<00:15,  7.22it/s]2025-03-16 20:31:20,932 - sciml.model.deeponet.deeponet - INFO - Epoch 192/300\n",
      "2025-03-16 20:31:20,932 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084107\n",
      "2025-03-16 20:31:20,933 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.095567\n",
      "Training progress:  64%|██████▍   | 192/300 [00:24<00:14,  7.23it/s]2025-03-16 20:31:21,066 - sciml.model.deeponet.deeponet - INFO - Epoch 193/300\n",
      "2025-03-16 20:31:21,067 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084058\n",
      "2025-03-16 20:31:21,067 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.095390\n",
      "Training progress:  64%|██████▍   | 193/300 [00:24<00:14,  7.28it/s]2025-03-16 20:31:21,207 - sciml.model.deeponet.deeponet - INFO - Epoch 194/300\n",
      "2025-03-16 20:31:21,208 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.083884\n",
      "2025-03-16 20:31:21,209 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.095301\n",
      "Training progress:  65%|██████▍   | 194/300 [00:24<00:14,  7.22it/s]2025-03-16 20:31:21,345 - sciml.model.deeponet.deeponet - INFO - Epoch 195/300\n",
      "2025-03-16 20:31:21,345 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.083805\n",
      "2025-03-16 20:31:21,346 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.095351\n",
      "Training progress:  65%|██████▌   | 195/300 [00:24<00:14,  7.24it/s]2025-03-16 20:31:21,481 - sciml.model.deeponet.deeponet - INFO - Epoch 196/300\n",
      "2025-03-16 20:31:21,482 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.083838\n",
      "2025-03-16 20:31:21,483 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.095208\n",
      "Training progress:  65%|██████▌   | 196/300 [00:24<00:14,  7.26it/s]2025-03-16 20:31:21,619 - sciml.model.deeponet.deeponet - INFO - Epoch 197/300\n",
      "2025-03-16 20:31:21,619 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.083788\n",
      "2025-03-16 20:31:21,620 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.095194\n",
      "Training progress:  66%|██████▌   | 197/300 [00:24<00:14,  7.27it/s]2025-03-16 20:31:21,751 - sciml.model.deeponet.deeponet - INFO - Epoch 198/300\n",
      "2025-03-16 20:31:21,752 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.083636\n",
      "2025-03-16 20:31:21,753 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.095193\n",
      "Training progress:  66%|██████▌   | 198/300 [00:24<00:13,  7.34it/s]2025-03-16 20:31:21,896 - sciml.model.deeponet.deeponet - INFO - Epoch 199/300\n",
      "2025-03-16 20:31:21,897 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.083565\n",
      "2025-03-16 20:31:21,898 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.095224\n",
      "Training progress:  66%|██████▋   | 199/300 [00:25<00:14,  7.21it/s]2025-03-16 20:31:22,041 - sciml.model.deeponet.deeponet - INFO - Epoch 200/300\n",
      "2025-03-16 20:31:22,042 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.083571\n",
      "2025-03-16 20:31:22,042 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.095378\n",
      "Training progress:  67%|██████▋   | 200/300 [00:25<00:14,  7.12it/s]2025-03-16 20:31:22,180 - sciml.model.deeponet.deeponet - INFO - Epoch 201/300\n",
      "2025-03-16 20:31:22,181 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.083532\n",
      "2025-03-16 20:31:22,182 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.095050\n",
      "Training progress:  67%|██████▋   | 201/300 [00:25<00:13,  7.14it/s]2025-03-16 20:31:22,316 - sciml.model.deeponet.deeponet - INFO - Epoch 202/300\n",
      "2025-03-16 20:31:22,317 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.083419\n",
      "2025-03-16 20:31:22,327 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.095033\n",
      "Training progress:  67%|██████▋   | 202/300 [00:25<00:13,  7.06it/s]2025-03-16 20:31:22,481 - sciml.model.deeponet.deeponet - INFO - Epoch 203/300\n",
      "2025-03-16 20:31:22,482 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.083331\n",
      "2025-03-16 20:31:22,483 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.095183\n",
      "Training progress:  68%|██████▊   | 203/300 [00:25<00:14,  6.85it/s]2025-03-16 20:31:22,619 - sciml.model.deeponet.deeponet - INFO - Epoch 204/300\n",
      "2025-03-16 20:31:22,620 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.083293\n",
      "2025-03-16 20:31:22,620 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.095124\n",
      "Training progress:  68%|██████▊   | 204/300 [00:25<00:13,  6.97it/s]2025-03-16 20:31:22,756 - sciml.model.deeponet.deeponet - INFO - Epoch 205/300\n",
      "2025-03-16 20:31:22,757 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.083266\n",
      "2025-03-16 20:31:22,758 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.095110\n",
      "Training progress:  68%|██████▊   | 205/300 [00:25<00:13,  7.05it/s]2025-03-16 20:31:22,895 - sciml.model.deeponet.deeponet - INFO - Epoch 206/300\n",
      "2025-03-16 20:31:22,896 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.083198\n",
      "2025-03-16 20:31:22,896 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.094857\n",
      "Training progress:  69%|██████▊   | 206/300 [00:26<00:13,  7.11it/s]2025-03-16 20:31:23,029 - sciml.model.deeponet.deeponet - INFO - Epoch 207/300\n",
      "2025-03-16 20:31:23,029 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.083118\n",
      "2025-03-16 20:31:23,030 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.094872\n",
      "Training progress:  69%|██████▉   | 207/300 [00:26<00:12,  7.23it/s]2025-03-16 20:31:23,164 - sciml.model.deeponet.deeponet - INFO - Epoch 208/300\n",
      "2025-03-16 20:31:23,165 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.083059\n",
      "2025-03-16 20:31:23,165 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.094981\n",
      "Training progress:  69%|██████▉   | 208/300 [00:26<00:12,  7.27it/s]2025-03-16 20:31:23,300 - sciml.model.deeponet.deeponet - INFO - Epoch 209/300\n",
      "2025-03-16 20:31:23,301 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.083023\n",
      "2025-03-16 20:31:23,301 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.094804\n",
      "Training progress:  70%|██████▉   | 209/300 [00:26<00:12,  7.29it/s]2025-03-16 20:31:23,437 - sciml.model.deeponet.deeponet - INFO - Epoch 210/300\n",
      "2025-03-16 20:31:23,438 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082984\n",
      "2025-03-16 20:31:23,439 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.094854\n",
      "Training progress:  70%|███████   | 210/300 [00:26<00:12,  7.28it/s]2025-03-16 20:31:23,572 - sciml.model.deeponet.deeponet - INFO - Epoch 211/300\n",
      "2025-03-16 20:31:23,573 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082928\n",
      "2025-03-16 20:31:23,573 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.094694\n",
      "Training progress:  70%|███████   | 211/300 [00:26<00:12,  7.33it/s]2025-03-16 20:31:23,703 - sciml.model.deeponet.deeponet - INFO - Epoch 212/300\n",
      "2025-03-16 20:31:23,704 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082857\n",
      "2025-03-16 20:31:23,704 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.094754\n",
      "Training progress:  71%|███████   | 212/300 [00:26<00:11,  7.42it/s]2025-03-16 20:31:23,837 - sciml.model.deeponet.deeponet - INFO - Epoch 213/300\n",
      "2025-03-16 20:31:23,838 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082792\n",
      "2025-03-16 20:31:23,839 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.094727\n",
      "Training progress:  71%|███████   | 213/300 [00:26<00:11,  7.43it/s]2025-03-16 20:31:23,976 - sciml.model.deeponet.deeponet - INFO - Epoch 214/300\n",
      "2025-03-16 20:31:23,977 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082740\n",
      "2025-03-16 20:31:23,978 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.094631\n",
      "Training progress:  71%|███████▏  | 214/300 [00:27<00:11,  7.35it/s]2025-03-16 20:31:24,114 - sciml.model.deeponet.deeponet - INFO - Epoch 215/300\n",
      "2025-03-16 20:31:24,114 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082697\n",
      "2025-03-16 20:31:24,115 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.094708\n",
      "Training progress:  72%|███████▏  | 215/300 [00:27<00:11,  7.33it/s]2025-03-16 20:31:24,249 - sciml.model.deeponet.deeponet - INFO - Epoch 216/300\n",
      "2025-03-16 20:31:24,250 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082660\n",
      "2025-03-16 20:31:24,250 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.094555\n",
      "Training progress:  72%|███████▏  | 216/300 [00:27<00:11,  7.35it/s]2025-03-16 20:31:24,381 - sciml.model.deeponet.deeponet - INFO - Epoch 217/300\n",
      "2025-03-16 20:31:24,382 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082616\n",
      "2025-03-16 20:31:24,382 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.094716\n",
      "Training progress:  72%|███████▏  | 217/300 [00:27<00:11,  7.42it/s]2025-03-16 20:31:24,511 - sciml.model.deeponet.deeponet - INFO - Epoch 218/300\n",
      "2025-03-16 20:31:24,512 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082562\n",
      "2025-03-16 20:31:24,513 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.094554\n",
      "Training progress:  73%|███████▎  | 218/300 [00:27<00:10,  7.49it/s]2025-03-16 20:31:24,654 - sciml.model.deeponet.deeponet - INFO - Epoch 219/300\n",
      "2025-03-16 20:31:24,655 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082507\n",
      "2025-03-16 20:31:24,656 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.094667\n",
      "Training progress:  73%|███████▎  | 219/300 [00:27<00:11,  7.34it/s]2025-03-16 20:31:24,802 - sciml.model.deeponet.deeponet - INFO - Epoch 220/300\n",
      "2025-03-16 20:31:24,803 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082447\n",
      "2025-03-16 20:31:24,803 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.094509\n",
      "Training progress:  73%|███████▎  | 220/300 [00:27<00:11,  7.15it/s]2025-03-16 20:31:24,958 - sciml.model.deeponet.deeponet - INFO - Epoch 221/300\n",
      "2025-03-16 20:31:24,959 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082392\n",
      "2025-03-16 20:31:24,960 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.094543\n",
      "Training progress:  74%|███████▎  | 221/300 [00:28<00:11,  6.91it/s]2025-03-16 20:31:25,126 - sciml.model.deeponet.deeponet - INFO - Epoch 222/300\n",
      "2025-03-16 20:31:25,127 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082335\n",
      "2025-03-16 20:31:25,128 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.094540\n",
      "Training progress:  74%|███████▍  | 222/300 [00:28<00:11,  6.59it/s]2025-03-16 20:31:25,284 - sciml.model.deeponet.deeponet - INFO - Epoch 223/300\n",
      "2025-03-16 20:31:25,285 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082282\n",
      "2025-03-16 20:31:25,286 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.094586\n",
      "Training progress:  74%|███████▍  | 223/300 [00:28<00:11,  6.50it/s]2025-03-16 20:31:25,441 - sciml.model.deeponet.deeponet - INFO - Epoch 224/300\n",
      "2025-03-16 20:31:25,442 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082231\n",
      "2025-03-16 20:31:25,443 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.094537\n",
      "Training progress:  75%|███████▍  | 224/300 [00:28<00:11,  6.47it/s]2025-03-16 20:31:25,596 - sciml.model.deeponet.deeponet - INFO - Epoch 225/300\n",
      "2025-03-16 20:31:25,597 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082179\n",
      "2025-03-16 20:31:25,598 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.094580\n",
      "Training progress:  75%|███████▌  | 225/300 [00:28<00:11,  6.46it/s]2025-03-16 20:31:25,738 - sciml.model.deeponet.deeponet - INFO - Epoch 226/300\n",
      "2025-03-16 20:31:25,739 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082129\n",
      "2025-03-16 20:31:25,740 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.094636\n",
      "Training progress:  75%|███████▌  | 226/300 [00:28<00:11,  6.63it/s]2025-03-16 20:31:25,875 - sciml.model.deeponet.deeponet - INFO - Epoch 227/300\n",
      "2025-03-16 20:31:25,875 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082079\n",
      "2025-03-16 20:31:25,876 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.094669\n",
      "Training progress:  76%|███████▌  | 227/300 [00:29<00:10,  6.83it/s]2025-03-16 20:31:26,020 - sciml.model.deeponet.deeponet - INFO - Epoch 228/300\n",
      "2025-03-16 20:31:26,021 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082029\n",
      "2025-03-16 20:31:26,021 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.094622\n",
      "Training progress:  76%|███████▌  | 228/300 [00:29<00:10,  6.84it/s]2025-03-16 20:31:26,168 - sciml.model.deeponet.deeponet - INFO - Epoch 229/300\n",
      "2025-03-16 20:31:26,169 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.081979\n",
      "2025-03-16 20:31:26,170 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.094632\n",
      "Training progress:  76%|███████▋  | 229/300 [00:29<00:10,  6.81it/s]2025-03-16 20:31:26,310 - sciml.model.deeponet.deeponet - INFO - Epoch 230/300\n",
      "2025-03-16 20:31:26,310 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.081930\n",
      "2025-03-16 20:31:26,311 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.094584\n",
      "Training progress:  77%|███████▋  | 230/300 [00:29<00:10,  6.88it/s]2025-03-16 20:31:26,451 - sciml.model.deeponet.deeponet - INFO - Epoch 231/300\n",
      "2025-03-16 20:31:26,452 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.081882\n",
      "2025-03-16 20:31:26,452 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.094662\n",
      "Training progress:  77%|███████▋  | 231/300 [00:29<00:09,  6.94it/s]2025-03-16 20:31:26,589 - sciml.model.deeponet.deeponet - INFO - Epoch 232/300\n",
      "2025-03-16 20:31:26,590 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.081835\n",
      "2025-03-16 20:31:26,591 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.094579\n",
      "Training progress:  77%|███████▋  | 232/300 [00:29<00:09,  7.02it/s]2025-03-16 20:31:26,728 - sciml.model.deeponet.deeponet - INFO - Epoch 233/300\n",
      "2025-03-16 20:31:26,729 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.081789\n",
      "2025-03-16 20:31:26,730 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.094689\n",
      "Training progress:  78%|███████▊  | 233/300 [00:29<00:09,  7.07it/s]2025-03-16 20:31:26,876 - sciml.model.deeponet.deeponet - INFO - Epoch 234/300\n",
      "2025-03-16 20:31:26,877 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.081745\n",
      "2025-03-16 20:31:26,878 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.093538\n",
      "Training progress:  78%|███████▊  | 234/300 [00:30<00:09,  6.98it/s]2025-03-16 20:31:27,020 - sciml.model.deeponet.deeponet - INFO - Epoch 235/300\n",
      "2025-03-16 20:31:27,021 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.081715\n",
      "2025-03-16 20:31:27,021 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.093030\n",
      "Training progress:  78%|███████▊  | 235/300 [00:30<00:09,  6.97it/s]2025-03-16 20:31:27,184 - sciml.model.deeponet.deeponet - INFO - Epoch 236/300\n",
      "2025-03-16 20:31:27,185 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.081707\n",
      "2025-03-16 20:31:27,186 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.093041\n",
      "Training progress:  79%|███████▊  | 236/300 [00:30<00:09,  6.68it/s]2025-03-16 20:31:27,333 - sciml.model.deeponet.deeponet - INFO - Epoch 237/300\n",
      "2025-03-16 20:31:27,334 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.081768\n",
      "2025-03-16 20:31:27,334 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092721\n",
      "Training progress:  79%|███████▉  | 237/300 [00:30<00:09,  6.70it/s]2025-03-16 20:31:27,480 - sciml.model.deeponet.deeponet - INFO - Epoch 238/300\n",
      "2025-03-16 20:31:27,481 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.081892\n",
      "2025-03-16 20:31:27,481 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.093864\n",
      "Training progress:  79%|███████▉  | 238/300 [00:30<00:09,  6.71it/s]2025-03-16 20:31:27,633 - sciml.model.deeponet.deeponet - INFO - Epoch 239/300\n",
      "2025-03-16 20:31:27,634 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082285\n",
      "2025-03-16 20:31:27,635 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092957\n",
      "Training progress:  80%|███████▉  | 239/300 [00:30<00:09,  6.66it/s]2025-03-16 20:31:27,770 - sciml.model.deeponet.deeponet - INFO - Epoch 240/300\n",
      "2025-03-16 20:31:27,771 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082592\n",
      "2025-03-16 20:31:27,771 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.094988\n",
      "Training progress:  80%|████████  | 240/300 [00:30<00:08,  6.85it/s]2025-03-16 20:31:27,909 - sciml.model.deeponet.deeponet - INFO - Epoch 241/300\n",
      "2025-03-16 20:31:27,910 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.083269\n",
      "2025-03-16 20:31:27,911 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092897\n",
      "Training progress:  80%|████████  | 241/300 [00:31<00:08,  6.95it/s]2025-03-16 20:31:28,047 - sciml.model.deeponet.deeponet - INFO - Epoch 242/300\n",
      "2025-03-16 20:31:28,048 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082526\n",
      "2025-03-16 20:31:28,048 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.093503\n",
      "Training progress:  81%|████████  | 242/300 [00:31<00:08,  7.04it/s]2025-03-16 20:31:28,183 - sciml.model.deeponet.deeponet - INFO - Epoch 243/300\n",
      "2025-03-16 20:31:28,184 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.081890\n",
      "2025-03-16 20:31:28,184 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092493\n",
      "Training progress:  81%|████████  | 243/300 [00:31<00:07,  7.13it/s]2025-03-16 20:31:28,317 - sciml.model.deeponet.deeponet - INFO - Epoch 244/300\n",
      "2025-03-16 20:31:28,318 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.081288\n",
      "2025-03-16 20:31:28,319 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092419\n",
      "Training progress:  81%|████████▏ | 244/300 [00:31<00:07,  7.22it/s]2025-03-16 20:31:28,453 - sciml.model.deeponet.deeponet - INFO - Epoch 245/300\n",
      "2025-03-16 20:31:28,453 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.081462\n",
      "2025-03-16 20:31:28,454 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.093763\n",
      "Training progress:  82%|████████▏ | 245/300 [00:31<00:07,  7.27it/s]2025-03-16 20:31:28,590 - sciml.model.deeponet.deeponet - INFO - Epoch 246/300\n",
      "2025-03-16 20:31:28,591 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082097\n",
      "2025-03-16 20:31:28,592 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092683\n",
      "Training progress:  82%|████████▏ | 246/300 [00:31<00:07,  7.25it/s]2025-03-16 20:31:28,731 - sciml.model.deeponet.deeponet - INFO - Epoch 247/300\n",
      "2025-03-16 20:31:28,732 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.081985\n",
      "2025-03-16 20:31:28,733 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.093381\n",
      "Training progress:  82%|████████▏ | 247/300 [00:31<00:07,  7.22it/s]2025-03-16 20:31:28,869 - sciml.model.deeponet.deeponet - INFO - Epoch 248/300\n",
      "2025-03-16 20:31:28,870 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.081590\n",
      "2025-03-16 20:31:28,871 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092481\n",
      "Training progress:  83%|████████▎ | 248/300 [00:31<00:07,  7.23it/s]2025-03-16 20:31:29,006 - sciml.model.deeponet.deeponet - INFO - Epoch 249/300\n",
      "2025-03-16 20:31:29,007 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.081077\n",
      "2025-03-16 20:31:29,008 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092428\n",
      "Training progress:  83%|████████▎ | 249/300 [00:32<00:07,  7.25it/s]2025-03-16 20:31:29,144 - sciml.model.deeponet.deeponet - INFO - Epoch 250/300\n",
      "2025-03-16 20:31:29,145 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.081181\n",
      "2025-03-16 20:31:29,145 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.093344\n",
      "Training progress:  83%|████████▎ | 250/300 [00:32<00:06,  7.25it/s]2025-03-16 20:31:29,282 - sciml.model.deeponet.deeponet - INFO - Epoch 251/300\n",
      "2025-03-16 20:31:29,283 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.081588\n",
      "2025-03-16 20:31:29,283 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092354\n",
      "Training progress:  84%|████████▎ | 251/300 [00:32<00:06,  7.25it/s]2025-03-16 20:31:29,419 - sciml.model.deeponet.deeponet - INFO - Epoch 252/300\n",
      "2025-03-16 20:31:29,420 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.081427\n",
      "2025-03-16 20:31:29,420 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092809\n",
      "Training progress:  84%|████████▍ | 252/300 [00:32<00:06,  7.27it/s]2025-03-16 20:31:29,555 - sciml.model.deeponet.deeponet - INFO - Epoch 253/300\n",
      "2025-03-16 20:31:29,556 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.081056\n",
      "2025-03-16 20:31:29,557 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092501\n",
      "Training progress:  84%|████████▍ | 253/300 [00:32<00:06,  7.28it/s]2025-03-16 20:31:29,734 - sciml.model.deeponet.deeponet - INFO - Epoch 254/300\n",
      "2025-03-16 20:31:29,734 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.080845\n",
      "2025-03-16 20:31:29,735 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092293\n",
      "Training progress:  85%|████████▍ | 254/300 [00:32<00:06,  6.68it/s]2025-03-16 20:31:29,889 - sciml.model.deeponet.deeponet - INFO - Epoch 255/300\n",
      "2025-03-16 20:31:29,889 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.081035\n",
      "2025-03-16 20:31:29,890 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.093029\n",
      "Training progress:  85%|████████▌ | 255/300 [00:33<00:06,  6.61it/s]2025-03-16 20:31:30,025 - sciml.model.deeponet.deeponet - INFO - Epoch 256/300\n",
      "2025-03-16 20:31:30,026 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.081268\n",
      "2025-03-16 20:31:30,027 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092023\n",
      "Training progress:  85%|████████▌ | 256/300 [00:33<00:06,  6.81it/s]2025-03-16 20:31:30,167 - sciml.model.deeponet.deeponet - INFO - Epoch 257/300\n",
      "2025-03-16 20:31:30,167 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.081023\n",
      "2025-03-16 20:31:30,169 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092327\n",
      "Training progress:  86%|████████▌ | 257/300 [00:33<00:06,  6.88it/s]2025-03-16 20:31:30,304 - sciml.model.deeponet.deeponet - INFO - Epoch 258/300\n",
      "2025-03-16 20:31:30,305 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.080725\n",
      "2025-03-16 20:31:30,306 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092392\n",
      "Training progress:  86%|████████▌ | 258/300 [00:33<00:05,  7.00it/s]2025-03-16 20:31:30,439 - sciml.model.deeponet.deeponet - INFO - Epoch 259/300\n",
      "2025-03-16 20:31:30,439 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.080658\n",
      "2025-03-16 20:31:30,440 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092180\n",
      "Training progress:  86%|████████▋ | 259/300 [00:33<00:05,  7.13it/s]2025-03-16 20:31:30,575 - sciml.model.deeponet.deeponet - INFO - Epoch 260/300\n",
      "2025-03-16 20:31:30,576 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.080798\n",
      "2025-03-16 20:31:30,577 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092768\n",
      "Training progress:  87%|████████▋ | 260/300 [00:33<00:05,  7.18it/s]2025-03-16 20:31:30,714 - sciml.model.deeponet.deeponet - INFO - Epoch 261/300\n",
      "2025-03-16 20:31:30,715 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.080881\n",
      "2025-03-16 20:31:30,716 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.091883\n",
      "Training progress:  87%|████████▋ | 261/300 [00:33<00:05,  7.19it/s]2025-03-16 20:31:30,849 - sciml.model.deeponet.deeponet - INFO - Epoch 262/300\n",
      "2025-03-16 20:31:30,850 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.080685\n",
      "2025-03-16 20:31:30,851 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092163\n",
      "Training progress:  87%|████████▋ | 262/300 [00:33<00:05,  7.25it/s]2025-03-16 20:31:31,012 - sciml.model.deeponet.deeponet - INFO - Epoch 263/300\n",
      "2025-03-16 20:31:31,013 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.080486\n",
      "2025-03-16 20:31:31,014 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092309\n",
      "Training progress:  88%|████████▊ | 263/300 [00:34<00:05,  6.87it/s]2025-03-16 20:31:31,152 - sciml.model.deeponet.deeponet - INFO - Epoch 264/300\n",
      "2025-03-16 20:31:31,153 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.080452\n",
      "2025-03-16 20:31:31,153 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092073\n",
      "Training progress:  88%|████████▊ | 264/300 [00:34<00:05,  6.96it/s]2025-03-16 20:31:31,285 - sciml.model.deeponet.deeponet - INFO - Epoch 265/300\n",
      "2025-03-16 20:31:31,286 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.080533\n",
      "2025-03-16 20:31:31,287 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092550\n",
      "Training progress:  88%|████████▊ | 265/300 [00:34<00:04,  7.11it/s]2025-03-16 20:31:31,423 - sciml.model.deeponet.deeponet - INFO - Epoch 266/300\n",
      "2025-03-16 20:31:31,424 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.080562\n",
      "2025-03-16 20:31:31,425 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.091786\n",
      "Training progress:  89%|████████▊ | 266/300 [00:34<00:04,  7.16it/s]2025-03-16 20:31:31,558 - sciml.model.deeponet.deeponet - INFO - Epoch 267/300\n",
      "2025-03-16 20:31:31,558 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.080426\n",
      "2025-03-16 20:31:31,559 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092102\n",
      "Training progress:  89%|████████▉ | 267/300 [00:34<00:04,  7.24it/s]2025-03-16 20:31:31,693 - sciml.model.deeponet.deeponet - INFO - Epoch 268/300\n",
      "2025-03-16 20:31:31,694 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.080282\n",
      "2025-03-16 20:31:31,695 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092161\n",
      "Training progress:  89%|████████▉ | 268/300 [00:34<00:04,  7.27it/s]2025-03-16 20:31:31,830 - sciml.model.deeponet.deeponet - INFO - Epoch 269/300\n",
      "2025-03-16 20:31:31,831 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.080229\n",
      "2025-03-16 20:31:31,831 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.091974\n",
      "Training progress:  90%|████████▉ | 269/300 [00:34<00:04,  7.30it/s]2025-03-16 20:31:31,965 - sciml.model.deeponet.deeponet - INFO - Epoch 270/300\n",
      "2025-03-16 20:31:31,966 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.080249\n",
      "2025-03-16 20:31:31,967 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092353\n",
      "Training progress:  90%|█████████ | 270/300 [00:35<00:04,  7.32it/s]2025-03-16 20:31:32,099 - sciml.model.deeponet.deeponet - INFO - Epoch 271/300\n",
      "2025-03-16 20:31:32,100 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.080273\n",
      "2025-03-16 20:31:32,100 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.091732\n",
      "Training progress:  90%|█████████ | 271/300 [00:35<00:03,  7.37it/s]2025-03-16 20:31:32,233 - sciml.model.deeponet.deeponet - INFO - Epoch 272/300\n",
      "2025-03-16 20:31:32,233 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.080215\n",
      "2025-03-16 20:31:32,234 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092154\n",
      "Training progress:  91%|█████████ | 272/300 [00:35<00:03,  7.40it/s]2025-03-16 20:31:32,371 - sciml.model.deeponet.deeponet - INFO - Epoch 273/300\n",
      "2025-03-16 20:31:32,372 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.080125\n",
      "2025-03-16 20:31:32,381 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.091953\n",
      "Training progress:  91%|█████████ | 273/300 [00:35<00:03,  7.21it/s]2025-03-16 20:31:32,530 - sciml.model.deeponet.deeponet - INFO - Epoch 274/300\n",
      "2025-03-16 20:31:32,531 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.080034\n",
      "2025-03-16 20:31:32,531 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.091943\n",
      "Training progress:  91%|█████████▏| 274/300 [00:35<00:03,  7.03it/s]2025-03-16 20:31:32,668 - sciml.model.deeponet.deeponet - INFO - Epoch 275/300\n",
      "2025-03-16 20:31:32,668 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.079983\n",
      "2025-03-16 20:31:32,669 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092106\n",
      "Training progress:  92%|█████████▏| 275/300 [00:35<00:03,  7.10it/s]2025-03-16 20:31:32,803 - sciml.model.deeponet.deeponet - INFO - Epoch 276/300\n",
      "2025-03-16 20:31:32,804 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.079970\n",
      "2025-03-16 20:31:32,804 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.091813\n",
      "Training progress:  92%|█████████▏| 276/300 [00:35<00:03,  7.19it/s]2025-03-16 20:31:32,936 - sciml.model.deeponet.deeponet - INFO - Epoch 277/300\n",
      "2025-03-16 20:31:32,937 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.079977\n",
      "2025-03-16 20:31:32,938 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092165\n",
      "Training progress:  92%|█████████▏| 277/300 [00:36<00:03,  7.27it/s]2025-03-16 20:31:33,071 - sciml.model.deeponet.deeponet - INFO - Epoch 278/300\n",
      "2025-03-16 20:31:33,072 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.079982\n",
      "2025-03-16 20:31:33,073 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.091699\n",
      "Training progress:  93%|█████████▎| 278/300 [00:36<00:03,  7.32it/s]2025-03-16 20:31:33,205 - sciml.model.deeponet.deeponet - INFO - Epoch 279/300\n",
      "2025-03-16 20:31:33,206 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.079955\n",
      "2025-03-16 20:31:33,207 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092301\n",
      "Training progress:  93%|█████████▎| 279/300 [00:36<00:02,  7.36it/s]2025-03-16 20:31:33,341 - sciml.model.deeponet.deeponet - INFO - Epoch 280/300\n",
      "2025-03-16 20:31:33,342 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.079918\n",
      "2025-03-16 20:31:33,343 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.091760\n",
      "Training progress:  93%|█████████▎| 280/300 [00:36<00:02,  7.36it/s]2025-03-16 20:31:33,482 - sciml.model.deeponet.deeponet - INFO - Epoch 281/300\n",
      "2025-03-16 20:31:33,483 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.079836\n",
      "2025-03-16 20:31:33,484 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092080\n",
      "Training progress:  94%|█████████▎| 281/300 [00:36<00:02,  7.27it/s]2025-03-16 20:31:33,621 - sciml.model.deeponet.deeponet - INFO - Epoch 282/300\n",
      "2025-03-16 20:31:33,622 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.079761\n",
      "2025-03-16 20:31:33,622 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.091895\n",
      "Training progress:  94%|█████████▍| 282/300 [00:36<00:02,  7.25it/s]2025-03-16 20:31:33,755 - sciml.model.deeponet.deeponet - INFO - Epoch 283/300\n",
      "2025-03-16 20:31:33,756 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.079692\n",
      "2025-03-16 20:31:33,757 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.091936\n",
      "Training progress:  94%|█████████▍| 283/300 [00:36<00:02,  7.31it/s]2025-03-16 20:31:33,891 - sciml.model.deeponet.deeponet - INFO - Epoch 284/300\n",
      "2025-03-16 20:31:33,892 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.079640\n",
      "2025-03-16 20:31:33,893 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.091897\n",
      "Training progress:  95%|█████████▍| 284/300 [00:37<00:02,  7.32it/s]2025-03-16 20:31:34,029 - sciml.model.deeponet.deeponet - INFO - Epoch 285/300\n",
      "2025-03-16 20:31:34,031 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.079602\n",
      "2025-03-16 20:31:34,031 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.091934\n",
      "Training progress:  95%|█████████▌| 285/300 [00:37<00:02,  7.29it/s]2025-03-16 20:31:34,168 - sciml.model.deeponet.deeponet - INFO - Epoch 286/300\n",
      "2025-03-16 20:31:34,169 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.079571\n",
      "2025-03-16 20:31:34,170 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092184\n",
      "Training progress:  95%|█████████▌| 286/300 [00:37<00:01,  7.27it/s]2025-03-16 20:31:34,304 - sciml.model.deeponet.deeponet - INFO - Epoch 287/300\n",
      "2025-03-16 20:31:34,305 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.079550\n",
      "2025-03-16 20:31:34,306 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.091844\n",
      "Training progress:  96%|█████████▌| 287/300 [00:37<00:01,  7.30it/s]2025-03-16 20:31:34,438 - sciml.model.deeponet.deeponet - INFO - Epoch 288/300\n",
      "2025-03-16 20:31:34,439 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.079542\n",
      "2025-03-16 20:31:34,440 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092286\n",
      "Training progress:  96%|█████████▌| 288/300 [00:37<00:01,  7.35it/s]2025-03-16 20:31:34,579 - sciml.model.deeponet.deeponet - INFO - Epoch 289/300\n",
      "2025-03-16 20:31:34,580 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.079557\n",
      "2025-03-16 20:31:34,581 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.091789\n",
      "Training progress:  96%|█████████▋| 289/300 [00:37<00:01,  7.26it/s]2025-03-16 20:31:34,719 - sciml.model.deeponet.deeponet - INFO - Epoch 290/300\n",
      "2025-03-16 20:31:34,720 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.079585\n",
      "2025-03-16 20:31:34,721 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092716\n",
      "Training progress:  97%|█████████▋| 290/300 [00:37<00:01,  7.23it/s]2025-03-16 20:31:34,858 - sciml.model.deeponet.deeponet - INFO - Epoch 291/300\n",
      "2025-03-16 20:31:34,858 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.079685\n",
      "2025-03-16 20:31:34,859 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.091860\n",
      "Training progress:  97%|█████████▋| 291/300 [00:37<00:01,  7.23it/s]2025-03-16 20:31:34,992 - sciml.model.deeponet.deeponet - INFO - Epoch 292/300\n",
      "2025-03-16 20:31:34,993 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.079776\n",
      "2025-03-16 20:31:34,993 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.093251\n",
      "Training progress:  97%|█████████▋| 292/300 [00:38<00:01,  7.29it/s]2025-03-16 20:31:35,129 - sciml.model.deeponet.deeponet - INFO - Epoch 293/300\n",
      "2025-03-16 20:31:35,130 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.079993\n",
      "2025-03-16 20:31:35,131 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.091899\n",
      "Training progress:  98%|█████████▊| 293/300 [00:38<00:00,  7.29it/s]2025-03-16 20:31:35,266 - sciml.model.deeponet.deeponet - INFO - Epoch 294/300\n",
      "2025-03-16 20:31:35,267 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.079980\n",
      "2025-03-16 20:31:35,268 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.093456\n",
      "Training progress:  98%|█████████▊| 294/300 [00:38<00:00,  7.29it/s]2025-03-16 20:31:35,404 - sciml.model.deeponet.deeponet - INFO - Epoch 295/300\n",
      "2025-03-16 20:31:35,405 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.080090\n",
      "2025-03-16 20:31:35,406 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.091908\n",
      "Training progress:  98%|█████████▊| 295/300 [00:38<00:00,  7.27it/s]2025-03-16 20:31:35,541 - sciml.model.deeponet.deeponet - INFO - Epoch 296/300\n",
      "2025-03-16 20:31:35,542 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.079751\n",
      "2025-03-16 20:31:35,542 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092737\n",
      "Training progress:  99%|█████████▊| 296/300 [00:38<00:00,  7.29it/s]2025-03-16 20:31:35,675 - sciml.model.deeponet.deeponet - INFO - Epoch 297/300\n",
      "2025-03-16 20:31:35,676 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.079513\n",
      "2025-03-16 20:31:35,676 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.091679\n",
      "Training progress:  99%|█████████▉| 297/300 [00:38<00:00,  7.33it/s]2025-03-16 20:31:35,812 - sciml.model.deeponet.deeponet - INFO - Epoch 298/300\n",
      "2025-03-16 20:31:35,812 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.079248\n",
      "2025-03-16 20:31:35,813 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.091911\n",
      "Training progress:  99%|█████████▉| 298/300 [00:38<00:00,  7.33it/s]2025-03-16 20:31:35,947 - sciml.model.deeponet.deeponet - INFO - Epoch 299/300\n",
      "2025-03-16 20:31:35,948 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.079117\n",
      "2025-03-16 20:31:35,948 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092132\n",
      "Training progress: 100%|█████████▉| 299/300 [00:39<00:00,  7.35it/s]2025-03-16 20:31:36,081 - sciml.model.deeponet.deeponet - INFO - Epoch 300/300\n",
      "2025-03-16 20:31:36,082 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.079118\n",
      "2025-03-16 20:31:36,082 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.091677\n",
      "Training progress: 100%|██████████| 300/300 [00:39<00:00,  7.65it/s]\n"
     ]
    }
   ],
   "source": [
    "loss_history_train,loss_history_test = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.29840314388275146, 0.28795090317726135, 0.28112757205963135, 0.2755112648010254, 0.26967430114746094, 0.2638587951660156, 0.2582840025424957, 0.2530507743358612, 0.24792127311229706, 0.24318674206733704, 0.2390056550502777, 0.23499874770641327, 0.23107263445854187, 0.2270817756652832, 0.22293275594711304, 0.21857039630413055, 0.2140057235956192, 0.20932675898075104, 0.20461034774780273, 0.19985303282737732, 0.19500552117824554, 0.19010186195373535, 0.1852838695049286, 0.18055373430252075, 0.17596115171909332, 0.17150619626045227, 0.16722480952739716, 0.1631781905889511, 0.15941816568374634, 0.15593722462654114, 0.15278507769107819, 0.14998000860214233, 0.14754042029380798, 0.14549604058265686, 0.14376704394817352, 0.14222918450832367, 0.1407996416091919, 0.13944247364997864, 0.13814207911491394, 0.13689590990543365, 0.1357206404209137, 0.13462863862514496, 0.13360969722270966, 0.1326417326927185, 0.1316778063774109, 0.13068479299545288, 0.12964677810668945, 0.12860307097434998, 0.1275920569896698, 0.12663352489471436, 0.12574388086795807, 0.12493450939655304, 0.12416790425777435, 0.12339746206998825, 0.12263350188732147, 0.1218583956360817, 0.12106221914291382, 0.12025222927331924, 0.11943662911653519, 0.11861332505941391, 0.11778329312801361, 0.11696499586105347, 0.11617793142795563, 0.11541979014873505, 0.11468397825956345, 0.11397895216941833, 0.11329323053359985, 0.11262999475002289, 0.1119854673743248, 0.11136141419410706, 0.11074559390544891, 0.11014954745769501, 0.10960516333580017, 0.10911966860294342, 0.10880672931671143, 0.10819897800683975, 0.10747309029102325, 0.1068677231669426, 0.10657161474227905, 0.1062481701374054, 0.10559962689876556, 0.10510872304439545, 0.1048528254032135, 0.10445664823055267, 0.10393036901950836, 0.10341054201126099, 0.10308152437210083, 0.10283216089010239, 0.10238587856292725, 0.1018354594707489, 0.1013849526643753, 0.1010938286781311, 0.1008404865860939, 0.10043316334486008, 0.09995859861373901, 0.09952060878276825, 0.09918449819087982, 0.09891654551029205, 0.09866313636302948, 0.09839066863059998, 0.09801134467124939, 0.09763400256633759, 0.09722412377595901, 0.09687802195549011, 0.09656131267547607, 0.09627434611320496, 0.09600809216499329, 0.09577629715204239, 0.09560762345790863, 0.0954919382929802, 0.09559662640094757, 0.09540554881095886, 0.09516193717718124, 0.0942499190568924, 0.09389254450798035, 0.09405301511287689, 0.09386178851127625, 0.09343387186527252, 0.0928606241941452, 0.09277871251106262, 0.09288445115089417, 0.09243842214345932, 0.09195512533187866, 0.09175842255353928, 0.09176668524742126, 0.09168750792741776, 0.09122040867805481, 0.09086079895496368, 0.09077399969100952, 0.09070326387882233, 0.09049567580223083, 0.0901508778333664, 0.08994252234697342, 0.0898716151714325, 0.08981756120920181, 0.08968309313058853, 0.08939018845558167, 0.08915175497531891, 0.08900085836648941, 0.08893530070781708, 0.08885642886161804, 0.08870221674442291, 0.08851867914199829, 0.08830931782722473, 0.08814016729593277, 0.08802688866853714, 0.08793248981237411, 0.08786076307296753, 0.08775188028812408, 0.08765006810426712, 0.0875302404165268, 0.08742202818393707, 0.08726869523525238, 0.08712365478277206, 0.08698275685310364, 0.08686371147632599, 0.08674877882003784, 0.08663816750049591, 0.08653289079666138, 0.08643381297588348, 0.08634236454963684, 0.08625096827745438, 0.08617915213108063, 0.08615173399448395, 0.08625684678554535, 0.08655064553022385, 0.08754785358905792, 0.08757992088794708, 0.08736027777194977, 0.08564239740371704, 0.08594334870576859, 0.08713248372077942, 0.08581423759460449, 0.0852515771985054, 0.08599764853715897, 0.08553941547870636, 0.08497689664363861, 0.08520542085170746, 0.08524785935878754, 0.08486568927764893, 0.08473226428031921, 0.08492003381252289, 0.08479928970336914, 0.08447946608066559, 0.08461486548185349, 0.08470819145441055, 0.08433295786380768, 0.08429642021656036, 0.084457628428936, 0.0842193067073822, 0.08403431624174118, 0.08410672098398209, 0.08405783772468567, 0.0838836282491684, 0.08380511403083801, 0.08383806049823761, 0.08378799259662628, 0.0836358517408371, 0.08356454968452454, 0.08357059955596924, 0.08353236317634583, 0.08341949433088303, 0.08333128690719604, 0.08329285681247711, 0.08326572179794312, 0.08319779485464096, 0.08311819285154343, 0.08305864036083221, 0.08302299678325653, 0.08298404514789581, 0.08292810618877411, 0.08285697549581528, 0.08279199153184891, 0.08274014294147491, 0.08269739151000977, 0.08265965431928635, 0.08261603116989136, 0.08256205916404724, 0.08250682055950165, 0.08244721591472626, 0.082391656935215, 0.08233519643545151, 0.08228234946727753, 0.08223065733909607, 0.08217930793762207, 0.08212865144014359, 0.08207885175943375, 0.08202920109033585, 0.08197931945323944, 0.08193033188581467, 0.08188233524560928, 0.08183519542217255, 0.08178916573524475, 0.08174514770507812, 0.08171524107456207, 0.08170673251152039, 0.08176843076944351, 0.08189206570386887, 0.08228497207164764, 0.08259155601263046, 0.083269402384758, 0.0825260728597641, 0.08189041912555695, 0.08128762245178223, 0.08146218955516815, 0.0820973813533783, 0.08198481053113937, 0.08158981800079346, 0.08107659220695496, 0.08118133246898651, 0.08158834278583527, 0.08142727613449097, 0.08105591684579849, 0.08084480464458466, 0.08103452622890472, 0.08126809448003769, 0.08102253824472427, 0.08072495460510254, 0.08065757155418396, 0.0807979553937912, 0.08088149130344391, 0.08068514615297318, 0.08048620074987411, 0.08045201748609543, 0.08053314685821533, 0.08056183159351349, 0.08042645454406738, 0.08028178662061691, 0.08022893965244293, 0.0802488699555397, 0.08027252554893494, 0.08021518588066101, 0.08012473583221436, 0.08003390580415726, 0.07998338341712952, 0.07996977865695953, 0.07997654378414154, 0.07998234033584595, 0.07995481044054031, 0.07991847395896912, 0.07983623445034027, 0.07976084202528, 0.07969176769256592, 0.0796397402882576, 0.07960239052772522, 0.07957110553979874, 0.07955002039670944, 0.07954156398773193, 0.07955655455589294, 0.07958526909351349, 0.07968524098396301, 0.07977551221847534, 0.07999328523874283, 0.0799795463681221, 0.0800900086760521, 0.07975086569786072, 0.0795130655169487, 0.07924818992614746, 0.07911732792854309, 0.07911751419305801]\n"
     ]
    }
   ],
   "source": [
    "print(loss_history_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_history_train,color='blue')\n",
    "plt.plot(loss_history_test,color='red')\n",
    "plt.legend(['train','test'])\n",
    "#log \n",
    "plt.yscale('log')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
