{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sciml.model.deeponet import DeepONet\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "tf.config.list_physical_devices('GPU')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_p = 40\n",
    "d_V = 80\n",
    "epochs = 300\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "internal_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(80,)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "])\n",
    "\n",
    "\n",
    "external_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(3,)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"data/test_data/example_data/heat2d/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-16 20:32:27,608 - sciml.model.deeponet.deeponet - INFO - Model initialized with 300 epochs, 32 batch size, 0.001 learning rate\n"
     ]
    }
   ],
   "source": [
    "model = DeepONet(regular_params={\"internal_model\": internal_model, \"external_model\": external_model}, hyper_params={\"d_p\": d_p, \"d_V\": d_V,\"device\": \"GPU\",\"n_epochs\":epochs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading mu data: 100%|██████████| 40/40 [00:00<00:00, 7439.68it/s]\n",
      "Loading x data: 100%|██████████| 40/40 [00:00<00:00, 2861.74it/s]\n",
      "Loading y data: 100%|██████████| 40/40 [00:00<00:00, 4455.03it/s]\n"
     ]
    }
   ],
   "source": [
    "mus, xs, sol = model.get_data(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 80)\n",
      "(40, 8000, 3)\n",
      "(40, 8000)\n"
     ]
    }
   ],
   "source": [
    "print(mus.shape)\n",
    "print(xs.shape)\n",
    "print(sol.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading mu data: 100%|██████████| 40/40 [00:00<00:00, 8190.80it/s]\n",
      "Loading x data: 100%|██████████| 40/40 [00:00<00:00, 4091.90it/s]\n",
      "Loading y data: 100%|██████████| 40/40 [00:00<00:00, 5483.11it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-03-16 20:32:28.116649: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [40,8000]\n",
      "\t [[{{node Placeholder/_2}}]]\n",
      "Training progress:   0%|          | 0/300 [00:00<?, ?it/s]2025-03-16 20:32:28.137438: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [32,8000]\n",
      "\t [[{{node Placeholder/_2}}]]\n",
      "2025-03-16 20:32:28.506918: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype float and shape [8,8000]\n",
      "\t [[{{node Placeholder/_2}}]]\n",
      "2025-03-16 20:32:28,555 - sciml.model.deeponet.deeponet - INFO - Epoch 1/300\n",
      "2025-03-16 20:32:28,556 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.323381\n",
      "2025-03-16 20:32:28,557 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.245469\n",
      "Training progress:   0%|          | 1/300 [00:00<02:06,  2.37it/s]2025-03-16 20:32:28,932 - sciml.model.deeponet.deeponet - INFO - Epoch 2/300\n",
      "2025-03-16 20:32:28,933 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.292729\n",
      "2025-03-16 20:32:28,933 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.248998\n",
      "Training progress:   1%|          | 2/300 [00:00<01:57,  2.53it/s]2025-03-16 20:32:29,301 - sciml.model.deeponet.deeponet - INFO - Epoch 3/300\n",
      "2025-03-16 20:32:29,301 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.294569\n",
      "2025-03-16 20:32:29,302 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.246065\n",
      "Training progress:   1%|          | 3/300 [00:01<01:53,  2.61it/s]2025-03-16 20:32:29,680 - sciml.model.deeponet.deeponet - INFO - Epoch 4/300\n",
      "2025-03-16 20:32:29,681 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.288038\n",
      "2025-03-16 20:32:29,681 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.238267\n",
      "Training progress:   1%|▏         | 4/300 [00:01<01:52,  2.62it/s]2025-03-16 20:32:30,060 - sciml.model.deeponet.deeponet - INFO - Epoch 5/300\n",
      "2025-03-16 20:32:30,061 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.277087\n",
      "2025-03-16 20:32:30,062 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.231404\n",
      "Training progress:   2%|▏         | 5/300 [00:01<01:52,  2.62it/s]2025-03-16 20:32:30,433 - sciml.model.deeponet.deeponet - INFO - Epoch 6/300\n",
      "2025-03-16 20:32:30,434 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.269236\n",
      "2025-03-16 20:32:30,434 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.231437\n",
      "Training progress:   2%|▏         | 6/300 [00:02<01:51,  2.64it/s]2025-03-16 20:32:30,814 - sciml.model.deeponet.deeponet - INFO - Epoch 7/300\n",
      "2025-03-16 20:32:30,815 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.268726\n",
      "2025-03-16 20:32:30,816 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.234882\n",
      "Training progress:   2%|▏         | 7/300 [00:02<01:51,  2.63it/s]2025-03-16 20:32:31,185 - sciml.model.deeponet.deeponet - INFO - Epoch 8/300\n",
      "2025-03-16 20:32:31,186 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.266762\n",
      "2025-03-16 20:32:31,187 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.233041\n",
      "Training progress:   3%|▎         | 8/300 [00:03<01:49,  2.66it/s]2025-03-16 20:32:31,546 - sciml.model.deeponet.deeponet - INFO - Epoch 9/300\n",
      "2025-03-16 20:32:31,547 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.258820\n",
      "2025-03-16 20:32:31,547 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.227865\n",
      "Training progress:   3%|▎         | 9/300 [00:03<01:48,  2.69it/s]2025-03-16 20:32:31,915 - sciml.model.deeponet.deeponet - INFO - Epoch 10/300\n",
      "2025-03-16 20:32:31,916 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.251298\n",
      "2025-03-16 20:32:31,917 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.223141\n",
      "Training progress:   3%|▎         | 10/300 [00:03<01:47,  2.70it/s]2025-03-16 20:32:32,286 - sciml.model.deeponet.deeponet - INFO - Epoch 11/300\n",
      "2025-03-16 20:32:32,287 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.247079\n",
      "2025-03-16 20:32:32,287 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.219990\n",
      "Training progress:   4%|▎         | 11/300 [00:04<01:47,  2.70it/s]2025-03-16 20:32:32,649 - sciml.model.deeponet.deeponet - INFO - Epoch 12/300\n",
      "2025-03-16 20:32:32,650 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.243962\n",
      "2025-03-16 20:32:32,651 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.218105\n",
      "Training progress:   4%|▍         | 12/300 [00:04<01:46,  2.71it/s]2025-03-16 20:32:33,026 - sciml.model.deeponet.deeponet - INFO - Epoch 13/300\n",
      "2025-03-16 20:32:33,026 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.239695\n",
      "2025-03-16 20:32:33,029 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.217373\n",
      "Training progress:   4%|▍         | 13/300 [00:04<01:46,  2.69it/s]2025-03-16 20:32:33,397 - sciml.model.deeponet.deeponet - INFO - Epoch 14/300\n",
      "2025-03-16 20:32:33,398 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.234188\n",
      "2025-03-16 20:32:33,399 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.217585\n",
      "Training progress:   5%|▍         | 14/300 [00:05<01:46,  2.70it/s]2025-03-16 20:32:33,775 - sciml.model.deeponet.deeponet - INFO - Epoch 15/300\n",
      "2025-03-16 20:32:33,776 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.229026\n",
      "2025-03-16 20:32:33,777 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.216702\n",
      "Training progress:   5%|▌         | 15/300 [00:05<01:46,  2.68it/s]2025-03-16 20:32:34,144 - sciml.model.deeponet.deeponet - INFO - Epoch 16/300\n",
      "2025-03-16 20:32:34,144 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.224989\n",
      "2025-03-16 20:32:34,145 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.212042\n",
      "Training progress:   5%|▌         | 16/300 [00:06<01:45,  2.69it/s]2025-03-16 20:32:34,508 - sciml.model.deeponet.deeponet - INFO - Epoch 17/300\n",
      "2025-03-16 20:32:34,509 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.220324\n",
      "2025-03-16 20:32:34,509 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.205261\n",
      "Training progress:   6%|▌         | 17/300 [00:06<01:44,  2.71it/s]2025-03-16 20:32:34,869 - sciml.model.deeponet.deeponet - INFO - Epoch 18/300\n",
      "2025-03-16 20:32:34,869 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.213962\n",
      "2025-03-16 20:32:34,870 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.200433\n",
      "Training progress:   6%|▌         | 18/300 [00:06<01:43,  2.73it/s]2025-03-16 20:32:32,271 - sciml.model.deeponet.deeponet - INFO - Epoch 19/300\n",
      "2025-03-16 20:32:32,272 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.207772\n",
      "2025-03-16 20:32:32,273 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.197925\n",
      "2025-03-16 20:32:32,637 - sciml.model.deeponet.deeponet - INFO - Epoch 20/300\n",
      "2025-03-16 20:32:32,638 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.202563\n",
      "2025-03-16 20:32:32,639 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.195039\n",
      "2025-03-16 20:32:33,003 - sciml.model.deeponet.deeponet - INFO - Epoch 21/300\n",
      "2025-03-16 20:32:33,004 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.196739\n",
      "2025-03-16 20:32:33,005 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.190256\n",
      "2025-03-16 20:32:33,363 - sciml.model.deeponet.deeponet - INFO - Epoch 22/300\n",
      "2025-03-16 20:32:33,364 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.189907\n",
      "2025-03-16 20:32:33,364 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.184949\n",
      "2025-03-16 20:32:33,739 - sciml.model.deeponet.deeponet - INFO - Epoch 23/300\n",
      "2025-03-16 20:32:33,740 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.183696\n",
      "2025-03-16 20:32:33,741 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.180502\n",
      "2025-03-16 20:32:34,105 - sciml.model.deeponet.deeponet - INFO - Epoch 24/300\n",
      "2025-03-16 20:32:34,105 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.177177\n",
      "2025-03-16 20:32:34,106 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.176984\n",
      "2025-03-16 20:32:34,470 - sciml.model.deeponet.deeponet - INFO - Epoch 25/300\n",
      "2025-03-16 20:32:34,471 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.170064\n",
      "2025-03-16 20:32:34,471 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.173809\n",
      "2025-03-16 20:32:34,839 - sciml.model.deeponet.deeponet - INFO - Epoch 26/300\n",
      "2025-03-16 20:32:34,840 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.163965\n",
      "2025-03-16 20:32:34,840 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.169019\n",
      "2025-03-16 20:32:35,212 - sciml.model.deeponet.deeponet - INFO - Epoch 27/300\n",
      "2025-03-16 20:32:35,212 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.157672\n",
      "2025-03-16 20:32:35,213 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.164020\n",
      "Training progress:   9%|▉         | 27/300 [00:07<00:28,  9.46it/s]2025-03-16 20:32:35,559 - sciml.model.deeponet.deeponet - INFO - Epoch 28/300\n",
      "2025-03-16 20:32:35,560 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.153085\n",
      "2025-03-16 20:32:35,561 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.160803\n",
      "Training progress:   9%|▉         | 28/300 [00:07<00:36,  7.53it/s]2025-03-16 20:32:35,921 - sciml.model.deeponet.deeponet - INFO - Epoch 29/300\n",
      "2025-03-16 20:32:35,922 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.148599\n",
      "2025-03-16 20:32:35,922 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.159003\n",
      "Training progress:  10%|▉         | 29/300 [00:07<00:44,  6.09it/s]2025-03-16 20:32:36,265 - sciml.model.deeponet.deeponet - INFO - Epoch 30/300\n",
      "2025-03-16 20:32:36,266 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.145402\n",
      "2025-03-16 20:32:36,267 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.155143\n",
      "Training progress:  10%|█         | 30/300 [00:08<00:52,  5.16it/s]2025-03-16 20:32:36,614 - sciml.model.deeponet.deeponet - INFO - Epoch 31/300\n",
      "2025-03-16 20:32:36,615 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.142283\n",
      "2025-03-16 20:32:36,616 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.151704\n",
      "Training progress:  10%|█         | 31/300 [00:08<01:00,  4.47it/s]2025-03-16 20:32:36,964 - sciml.model.deeponet.deeponet - INFO - Epoch 32/300\n",
      "2025-03-16 20:32:36,965 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.140721\n",
      "2025-03-16 20:32:36,966 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.149914\n",
      "Training progress:  11%|█         | 32/300 [00:08<01:07,  3.99it/s]2025-03-16 20:32:37,303 - sciml.model.deeponet.deeponet - INFO - Epoch 33/300\n",
      "2025-03-16 20:32:37,304 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.138340\n",
      "2025-03-16 20:32:37,305 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.147732\n",
      "Training progress:  11%|█         | 33/300 [00:09<01:12,  3.69it/s]2025-03-16 20:32:37,655 - sciml.model.deeponet.deeponet - INFO - Epoch 34/300\n",
      "2025-03-16 20:32:37,655 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.136654\n",
      "2025-03-16 20:32:37,656 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.144476\n",
      "Training progress:  11%|█▏        | 34/300 [00:09<01:17,  3.43it/s]2025-03-16 20:32:38,022 - sciml.model.deeponet.deeponet - INFO - Epoch 35/300\n",
      "2025-03-16 20:32:38,023 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.134818\n",
      "2025-03-16 20:32:38,024 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.142572\n",
      "Training progress:  12%|█▏        | 35/300 [00:09<01:22,  3.21it/s]2025-03-16 20:32:38,365 - sciml.model.deeponet.deeponet - INFO - Epoch 36/300\n",
      "2025-03-16 20:32:38,366 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.132462\n",
      "2025-03-16 20:32:38,367 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.141007\n",
      "Training progress:  12%|█▏        | 36/300 [00:10<01:24,  3.12it/s]2025-03-16 20:32:38,720 - sciml.model.deeponet.deeponet - INFO - Epoch 37/300\n",
      "2025-03-16 20:32:38,721 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.130721\n",
      "2025-03-16 20:32:38,722 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.139151\n",
      "Training progress:  12%|█▏        | 37/300 [00:10<01:26,  3.03it/s]2025-03-16 20:32:39,066 - sciml.model.deeponet.deeponet - INFO - Epoch 38/300\n",
      "2025-03-16 20:32:39,067 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.128570\n",
      "2025-03-16 20:32:39,068 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.137529\n",
      "Training progress:  13%|█▎        | 38/300 [00:10<01:27,  2.99it/s]2025-03-16 20:32:39,415 - sciml.model.deeponet.deeponet - INFO - Epoch 39/300\n",
      "2025-03-16 20:32:39,416 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.126344\n",
      "2025-03-16 20:32:39,417 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.135940\n",
      "Training progress:  13%|█▎        | 39/300 [00:11<01:28,  2.95it/s]2025-03-16 20:32:39,765 - sciml.model.deeponet.deeponet - INFO - Epoch 40/300\n",
      "2025-03-16 20:32:39,766 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.124603\n",
      "2025-03-16 20:32:39,767 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.134713\n",
      "Training progress:  13%|█▎        | 40/300 [00:11<01:28,  2.92it/s]2025-03-16 20:32:40,114 - sciml.model.deeponet.deeponet - INFO - Epoch 41/300\n",
      "2025-03-16 20:32:40,115 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.122606\n",
      "2025-03-16 20:32:40,115 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.133056\n",
      "Training progress:  14%|█▎        | 41/300 [00:11<01:29,  2.91it/s]2025-03-16 20:32:40,460 - sciml.model.deeponet.deeponet - INFO - Epoch 42/300\n",
      "2025-03-16 20:32:40,460 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.120740\n",
      "2025-03-16 20:32:40,461 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.131549\n",
      "Training progress:  14%|█▍        | 42/300 [00:12<01:28,  2.90it/s]2025-03-16 20:32:40,817 - sciml.model.deeponet.deeponet - INFO - Epoch 43/300\n",
      "2025-03-16 20:32:40,818 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.119329\n",
      "2025-03-16 20:32:40,818 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.130539\n",
      "Training progress:  14%|█▍        | 43/300 [00:12<01:29,  2.87it/s]2025-03-16 20:32:41,159 - sciml.model.deeponet.deeponet - INFO - Epoch 44/300\n",
      "2025-03-16 20:32:41,160 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.117766\n",
      "2025-03-16 20:32:41,160 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.128938\n",
      "Training progress:  15%|█▍        | 44/300 [00:13<01:28,  2.89it/s]2025-03-16 20:32:41,515 - sciml.model.deeponet.deeponet - INFO - Epoch 45/300\n",
      "2025-03-16 20:32:41,515 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.116116\n",
      "2025-03-16 20:32:41,516 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.127486\n",
      "Training progress:  15%|█▌        | 45/300 [00:13<01:29,  2.86it/s]2025-03-16 20:32:41,867 - sciml.model.deeponet.deeponet - INFO - Epoch 46/300\n",
      "2025-03-16 20:32:41,867 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.114554\n",
      "2025-03-16 20:32:41,868 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.126041\n",
      "Training progress:  15%|█▌        | 46/300 [00:13<01:28,  2.86it/s]2025-03-16 20:32:42,214 - sciml.model.deeponet.deeponet - INFO - Epoch 47/300\n",
      "2025-03-16 20:32:42,215 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.113124\n",
      "2025-03-16 20:32:42,215 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.124689\n",
      "Training progress:  16%|█▌        | 47/300 [00:14<01:28,  2.86it/s]2025-03-16 20:32:42,576 - sciml.model.deeponet.deeponet - INFO - Epoch 48/300\n",
      "2025-03-16 20:32:42,576 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.111743\n",
      "2025-03-16 20:32:42,577 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.123157\n",
      "Training progress:  16%|█▌        | 48/300 [00:14<01:28,  2.83it/s]2025-03-16 20:32:42,931 - sciml.model.deeponet.deeponet - INFO - Epoch 49/300\n",
      "2025-03-16 20:32:42,932 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.110281\n",
      "2025-03-16 20:32:42,933 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.121864\n",
      "Training progress:  16%|█▋        | 49/300 [00:14<01:28,  2.83it/s]2025-03-16 20:32:43,275 - sciml.model.deeponet.deeponet - INFO - Epoch 50/300\n",
      "2025-03-16 20:32:43,276 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.108959\n",
      "2025-03-16 20:32:43,277 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.120371\n",
      "Training progress:  17%|█▋        | 50/300 [00:15<01:27,  2.85it/s]2025-03-16 20:32:43,632 - sciml.model.deeponet.deeponet - INFO - Epoch 51/300\n",
      "2025-03-16 20:32:43,633 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.107727\n",
      "2025-03-16 20:32:43,634 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.119064\n",
      "Training progress:  17%|█▋        | 51/300 [00:15<01:27,  2.84it/s]2025-03-16 20:32:43,983 - sciml.model.deeponet.deeponet - INFO - Epoch 52/300\n",
      "2025-03-16 20:32:43,983 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.106496\n",
      "2025-03-16 20:32:43,984 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.117845\n",
      "Training progress:  17%|█▋        | 52/300 [00:15<01:27,  2.84it/s]2025-03-16 20:32:44,325 - sciml.model.deeponet.deeponet - INFO - Epoch 53/300\n",
      "2025-03-16 20:32:44,326 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.105380\n",
      "2025-03-16 20:32:44,326 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.116696\n",
      "Training progress:  18%|█▊        | 53/300 [00:16<01:26,  2.86it/s]2025-03-16 20:32:44,672 - sciml.model.deeponet.deeponet - INFO - Epoch 54/300\n",
      "2025-03-16 20:32:44,673 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.104457\n",
      "2025-03-16 20:32:44,673 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.116016\n",
      "Training progress:  18%|█▊        | 54/300 [00:16<01:25,  2.87it/s]2025-03-16 20:32:45,023 - sciml.model.deeponet.deeponet - INFO - Epoch 55/300\n",
      "2025-03-16 20:32:45,024 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.103739\n",
      "2025-03-16 20:32:45,025 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.115177\n",
      "Training progress:  18%|█▊        | 55/300 [00:16<01:25,  2.86it/s]2025-03-16 20:32:45,374 - sciml.model.deeponet.deeponet - INFO - Epoch 56/300\n",
      "2025-03-16 20:32:45,375 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.103472\n",
      "2025-03-16 20:32:45,375 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.115111\n",
      "Training progress:  19%|█▊        | 56/300 [00:17<01:25,  2.86it/s]2025-03-16 20:32:45,722 - sciml.model.deeponet.deeponet - INFO - Epoch 57/300\n",
      "2025-03-16 20:32:45,722 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.102949\n",
      "2025-03-16 20:32:45,723 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.113734\n",
      "Training progress:  19%|█▉        | 57/300 [00:17<01:24,  2.86it/s]2025-03-16 20:32:46,061 - sciml.model.deeponet.deeponet - INFO - Epoch 58/300\n",
      "2025-03-16 20:32:46,062 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.102371\n",
      "2025-03-16 20:32:46,062 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.112331\n",
      "Training progress:  19%|█▉        | 58/300 [00:17<01:23,  2.89it/s]2025-03-16 20:32:46,405 - sciml.model.deeponet.deeponet - INFO - Epoch 59/300\n",
      "2025-03-16 20:32:46,406 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.100198\n",
      "2025-03-16 20:32:46,407 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.111282\n",
      "Training progress:  20%|█▉        | 59/300 [00:18<01:23,  2.89it/s]2025-03-16 20:32:46,744 - sciml.model.deeponet.deeponet - INFO - Epoch 60/300\n",
      "2025-03-16 20:32:46,745 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.099333\n",
      "2025-03-16 20:32:46,745 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.110626\n",
      "Training progress:  20%|██        | 60/300 [00:18<01:22,  2.91it/s]2025-03-16 20:32:47,089 - sciml.model.deeponet.deeponet - INFO - Epoch 61/300\n",
      "2025-03-16 20:32:47,090 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.099651\n",
      "2025-03-16 20:32:47,090 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.110063\n",
      "Training progress:  20%|██        | 61/300 [00:18<01:22,  2.91it/s]2025-03-16 20:32:47,440 - sciml.model.deeponet.deeponet - INFO - Epoch 62/300\n",
      "2025-03-16 20:32:47,441 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.098698\n",
      "2025-03-16 20:32:47,441 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.108147\n",
      "Training progress:  21%|██        | 62/300 [00:19<01:22,  2.89it/s]2025-03-16 20:32:47,781 - sciml.model.deeponet.deeponet - INFO - Epoch 63/300\n",
      "2025-03-16 20:32:47,781 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.097275\n",
      "2025-03-16 20:32:47,791 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.107355\n",
      "Training progress:  21%|██        | 63/300 [00:19<01:22,  2.88it/s]2025-03-16 20:32:48,151 - sciml.model.deeponet.deeponet - INFO - Epoch 64/300\n",
      "2025-03-16 20:32:48,152 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.096323\n",
      "2025-03-16 20:32:48,152 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.107688\n",
      "Training progress:  21%|██▏       | 64/300 [00:20<01:22,  2.85it/s]2025-03-16 20:32:48,500 - sciml.model.deeponet.deeponet - INFO - Epoch 65/300\n",
      "2025-03-16 20:32:48,500 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.096332\n",
      "2025-03-16 20:32:48,501 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.106889\n",
      "Training progress:  22%|██▏       | 65/300 [00:20<01:22,  2.85it/s]2025-03-16 20:32:48,850 - sciml.model.deeponet.deeponet - INFO - Epoch 66/300\n",
      "2025-03-16 20:32:48,851 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.096422\n",
      "2025-03-16 20:32:48,851 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.106176\n",
      "Training progress:  22%|██▏       | 66/300 [00:20<01:21,  2.85it/s]2025-03-16 20:32:49,196 - sciml.model.deeponet.deeponet - INFO - Epoch 67/300\n",
      "2025-03-16 20:32:49,196 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.094940\n",
      "2025-03-16 20:32:49,197 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.104955\n",
      "Training progress:  22%|██▏       | 67/300 [00:21<01:21,  2.86it/s]2025-03-16 20:32:49,551 - sciml.model.deeponet.deeponet - INFO - Epoch 68/300\n",
      "2025-03-16 20:32:49,551 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.093926\n",
      "2025-03-16 20:32:49,552 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.104451\n",
      "Training progress:  23%|██▎       | 68/300 [00:21<01:21,  2.85it/s]2025-03-16 20:32:49,899 - sciml.model.deeponet.deeponet - INFO - Epoch 69/300\n",
      "2025-03-16 20:32:49,900 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.093792\n",
      "2025-03-16 20:32:49,900 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.104477\n",
      "Training progress:  23%|██▎       | 69/300 [00:21<01:20,  2.86it/s]2025-03-16 20:32:50,247 - sciml.model.deeponet.deeponet - INFO - Epoch 70/300\n",
      "2025-03-16 20:32:50,248 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.093795\n",
      "2025-03-16 20:32:50,248 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.103606\n",
      "Training progress:  23%|██▎       | 70/300 [00:22<01:20,  2.86it/s]2025-03-16 20:32:50,592 - sciml.model.deeponet.deeponet - INFO - Epoch 71/300\n",
      "2025-03-16 20:32:50,592 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.093620\n",
      "2025-03-16 20:32:50,593 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.102817\n",
      "Training progress:  24%|██▎       | 71/300 [00:22<01:19,  2.87it/s]2025-03-16 20:32:50,933 - sciml.model.deeponet.deeponet - INFO - Epoch 72/300\n",
      "2025-03-16 20:32:50,934 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.092377\n",
      "2025-03-16 20:32:50,935 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.101921\n",
      "Training progress:  24%|██▍       | 72/300 [00:22<01:18,  2.89it/s]2025-03-16 20:32:51,282 - sciml.model.deeponet.deeponet - INFO - Epoch 73/300\n",
      "2025-03-16 20:32:51,283 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.091593\n",
      "2025-03-16 20:32:51,283 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.101397\n",
      "Training progress:  24%|██▍       | 73/300 [00:23<01:18,  2.88it/s]2025-03-16 20:32:51,636 - sciml.model.deeponet.deeponet - INFO - Epoch 74/300\n",
      "2025-03-16 20:32:51,637 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.091520\n",
      "2025-03-16 20:32:51,638 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.101503\n",
      "Training progress:  25%|██▍       | 74/300 [00:23<01:18,  2.86it/s]2025-03-16 20:32:51,989 - sciml.model.deeponet.deeponet - INFO - Epoch 75/300\n",
      "2025-03-16 20:32:51,990 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.091539\n",
      "2025-03-16 20:32:51,990 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.100648\n",
      "Training progress:  25%|██▌       | 75/300 [00:23<01:18,  2.86it/s]2025-03-16 20:32:52,340 - sciml.model.deeponet.deeponet - INFO - Epoch 76/300\n",
      "2025-03-16 20:32:52,340 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.091447\n",
      "2025-03-16 20:32:52,341 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.100748\n",
      "Training progress:  25%|██▌       | 76/300 [00:24<01:18,  2.85it/s]2025-03-16 20:32:52,683 - sciml.model.deeponet.deeponet - INFO - Epoch 77/300\n",
      "2025-03-16 20:32:52,684 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.090482\n",
      "2025-03-16 20:32:52,684 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.099860\n",
      "Training progress:  26%|██▌       | 77/300 [00:24<01:17,  2.87it/s]2025-03-16 20:32:53,028 - sciml.model.deeponet.deeponet - INFO - Epoch 78/300\n",
      "2025-03-16 20:32:53,029 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.089682\n",
      "2025-03-16 20:32:53,030 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.099166\n",
      "Training progress:  26%|██▌       | 78/300 [00:24<01:17,  2.88it/s]2025-03-16 20:32:53,372 - sciml.model.deeponet.deeponet - INFO - Epoch 79/300\n",
      "2025-03-16 20:32:53,373 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.089480\n",
      "2025-03-16 20:32:53,373 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.099490\n",
      "Training progress:  26%|██▋       | 79/300 [00:25<01:16,  2.89it/s]2025-03-16 20:32:53,725 - sciml.model.deeponet.deeponet - INFO - Epoch 80/300\n",
      "2025-03-16 20:32:53,726 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.089649\n",
      "2025-03-16 20:32:53,727 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.099161\n",
      "Training progress:  27%|██▋       | 80/300 [00:25<01:16,  2.87it/s]2025-03-16 20:32:54,072 - sciml.model.deeponet.deeponet - INFO - Epoch 81/300\n",
      "2025-03-16 20:32:54,073 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.090022\n",
      "2025-03-16 20:32:54,073 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.099617\n",
      "Training progress:  27%|██▋       | 81/300 [00:25<01:16,  2.88it/s]2025-03-16 20:32:54,433 - sciml.model.deeponet.deeponet - INFO - Epoch 82/300\n",
      "2025-03-16 20:32:54,434 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.089454\n",
      "2025-03-16 20:32:54,434 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.097928\n",
      "Training progress:  27%|██▋       | 82/300 [00:26<01:16,  2.84it/s]2025-03-16 20:32:54,778 - sciml.model.deeponet.deeponet - INFO - Epoch 83/300\n",
      "2025-03-16 20:32:54,779 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.088639\n",
      "2025-03-16 20:32:54,780 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.097674\n",
      "Training progress:  28%|██▊       | 83/300 [00:26<01:15,  2.86it/s]2025-03-16 20:32:55,146 - sciml.model.deeponet.deeponet - INFO - Epoch 84/300\n",
      "2025-03-16 20:32:55,147 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.087835\n",
      "2025-03-16 20:32:55,147 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.097333\n",
      "Training progress:  28%|██▊       | 84/300 [00:27<01:16,  2.82it/s]2025-03-16 20:32:55,494 - sciml.model.deeponet.deeponet - INFO - Epoch 85/300\n",
      "2025-03-16 20:32:55,495 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.087616\n",
      "2025-03-16 20:32:55,495 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.096509\n",
      "Training progress:  28%|██▊       | 85/300 [00:27<01:15,  2.83it/s]2025-03-16 20:32:55,858 - sciml.model.deeponet.deeponet - INFO - Epoch 86/300\n",
      "2025-03-16 20:32:55,859 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.087841\n",
      "2025-03-16 20:32:55,860 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.097186\n",
      "Training progress:  29%|██▊       | 86/300 [00:27<01:16,  2.81it/s]2025-03-16 20:32:56,210 - sciml.model.deeponet.deeponet - INFO - Epoch 87/300\n",
      "2025-03-16 20:32:56,211 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.087916\n",
      "2025-03-16 20:32:56,212 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.096706\n",
      "Training progress:  29%|██▉       | 87/300 [00:28<01:15,  2.81it/s]2025-03-16 20:32:56,560 - sciml.model.deeponet.deeponet - INFO - Epoch 88/300\n",
      "2025-03-16 20:32:56,560 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.087855\n",
      "2025-03-16 20:32:56,561 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.096400\n",
      "Training progress:  29%|██▉       | 88/300 [00:28<01:14,  2.83it/s]2025-03-16 20:32:56,913 - sciml.model.deeponet.deeponet - INFO - Epoch 89/300\n",
      "2025-03-16 20:32:56,913 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.087077\n",
      "2025-03-16 20:32:56,914 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.095178\n",
      "Training progress:  30%|██▉       | 89/300 [00:28<01:14,  2.83it/s]2025-03-16 20:32:57,335 - sciml.model.deeponet.deeponet - INFO - Epoch 90/300\n",
      "2025-03-16 20:32:57,335 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.086435\n",
      "2025-03-16 20:32:57,336 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.094998\n",
      "Training progress:  30%|███       | 90/300 [00:29<01:18,  2.68it/s]2025-03-16 20:32:57,680 - sciml.model.deeponet.deeponet - INFO - Epoch 91/300\n",
      "2025-03-16 20:32:57,681 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.085977\n",
      "2025-03-16 20:32:57,682 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.094522\n",
      "Training progress:  30%|███       | 91/300 [00:29<01:16,  2.74it/s]2025-03-16 20:32:58,040 - sciml.model.deeponet.deeponet - INFO - Epoch 92/300\n",
      "2025-03-16 20:32:58,041 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.085739\n",
      "2025-03-16 20:32:58,051 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.094098\n",
      "Training progress:  31%|███       | 92/300 [00:29<01:16,  2.73it/s]2025-03-16 20:32:58,400 - sciml.model.deeponet.deeponet - INFO - Epoch 93/300\n",
      "2025-03-16 20:32:58,401 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.085789\n",
      "2025-03-16 20:32:58,402 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.095022\n",
      "Training progress:  31%|███       | 93/300 [00:30<01:14,  2.76it/s]2025-03-16 20:32:58,756 - sciml.model.deeponet.deeponet - INFO - Epoch 94/300\n",
      "2025-03-16 20:32:58,757 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.085978\n",
      "2025-03-16 20:32:58,757 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.094793\n",
      "Training progress:  31%|███▏      | 94/300 [00:30<01:14,  2.78it/s]2025-03-16 20:32:59,102 - sciml.model.deeponet.deeponet - INFO - Epoch 95/300\n",
      "2025-03-16 20:32:59,103 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.086867\n",
      "2025-03-16 20:32:59,104 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.095503\n",
      "Training progress:  32%|███▏      | 95/300 [00:30<01:12,  2.81it/s]2025-03-16 20:32:59,449 - sciml.model.deeponet.deeponet - INFO - Epoch 96/300\n",
      "2025-03-16 20:32:59,450 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.086900\n",
      "2025-03-16 20:32:59,451 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.094398\n",
      "Training progress:  32%|███▏      | 96/300 [00:31<01:12,  2.83it/s]2025-03-16 20:32:59,840 - sciml.model.deeponet.deeponet - INFO - Epoch 97/300\n",
      "2025-03-16 20:32:59,841 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.086664\n",
      "2025-03-16 20:32:59,842 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.093608\n",
      "Training progress:  32%|███▏      | 97/300 [00:31<01:14,  2.74it/s]2025-03-16 20:33:00,235 - sciml.model.deeponet.deeponet - INFO - Epoch 98/300\n",
      "2025-03-16 20:33:00,236 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.085032\n",
      "2025-03-16 20:33:00,236 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092181\n",
      "Training progress:  33%|███▎      | 98/300 [00:32<01:15,  2.68it/s]2025-03-16 20:33:00,604 - sciml.model.deeponet.deeponet - INFO - Epoch 99/300\n",
      "2025-03-16 20:33:00,613 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084219\n",
      "2025-03-16 20:33:00,613 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092663\n",
      "Training progress:  33%|███▎      | 99/300 [00:32<01:15,  2.67it/s]2025-03-16 20:33:00,969 - sciml.model.deeponet.deeponet - INFO - Epoch 100/300\n",
      "2025-03-16 20:33:00,970 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084179\n",
      "2025-03-16 20:33:00,971 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.093022\n",
      "Training progress:  33%|███▎      | 100/300 [00:32<01:13,  2.71it/s]2025-03-16 20:33:01,357 - sciml.model.deeponet.deeponet - INFO - Epoch 101/300\n",
      "2025-03-16 20:33:01,358 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084372\n",
      "2025-03-16 20:33:01,358 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092263\n",
      "Training progress:  34%|███▎      | 101/300 [00:33<01:14,  2.67it/s]2025-03-16 20:33:01,726 - sciml.model.deeponet.deeponet - INFO - Epoch 102/300\n",
      "2025-03-16 20:33:01,727 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084773\n",
      "2025-03-16 20:33:01,727 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.093099\n",
      "Training progress:  34%|███▍      | 102/300 [00:33<01:13,  2.68it/s]2025-03-16 20:33:02,108 - sciml.model.deeponet.deeponet - INFO - Epoch 103/300\n",
      "2025-03-16 20:33:02,109 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084448\n",
      "2025-03-16 20:33:02,109 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.091827\n",
      "Training progress:  34%|███▍      | 103/300 [00:33<01:14,  2.66it/s]2025-03-16 20:33:02,497 - sciml.model.deeponet.deeponet - INFO - Epoch 104/300\n",
      "2025-03-16 20:33:02,498 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084274\n",
      "2025-03-16 20:33:02,498 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.091588\n",
      "Training progress:  35%|███▍      | 104/300 [00:34<01:14,  2.63it/s]2025-03-16 20:33:02,897 - sciml.model.deeponet.deeponet - INFO - Epoch 105/300\n",
      "2025-03-16 20:33:02,899 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.083591\n",
      "2025-03-16 20:33:02,900 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.091428\n",
      "Training progress:  35%|███▌      | 105/300 [00:34<01:15,  2.59it/s]2025-03-16 20:33:03,326 - sciml.model.deeponet.deeponet - INFO - Epoch 106/300\n",
      "2025-03-16 20:33:03,327 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082940\n",
      "2025-03-16 20:33:03,327 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.090794\n",
      "Training progress:  35%|███▌      | 106/300 [00:35<01:17,  2.51it/s]2025-03-16 20:33:03,715 - sciml.model.deeponet.deeponet - INFO - Epoch 107/300\n",
      "2025-03-16 20:33:03,716 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082908\n",
      "2025-03-16 20:33:03,717 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.090448\n",
      "Training progress:  36%|███▌      | 107/300 [00:35<01:16,  2.53it/s]2025-03-16 20:33:04,093 - sciml.model.deeponet.deeponet - INFO - Epoch 108/300\n",
      "2025-03-16 20:33:04,094 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082987\n",
      "2025-03-16 20:33:04,094 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.090639\n",
      "Training progress:  36%|███▌      | 108/300 [00:35<01:14,  2.56it/s]2025-03-16 20:33:01,579 - sciml.model.deeponet.deeponet - INFO - Epoch 109/300\n",
      "2025-03-16 20:33:01,580 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.083349\n",
      "2025-03-16 20:33:01,581 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.091213\n",
      "2025-03-16 20:33:01,938 - sciml.model.deeponet.deeponet - INFO - Epoch 110/300\n",
      "2025-03-16 20:33:01,939 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.083279\n",
      "2025-03-16 20:33:01,940 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.090562\n",
      "2025-03-16 20:33:02,295 - sciml.model.deeponet.deeponet - INFO - Epoch 111/300\n",
      "2025-03-16 20:33:02,296 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.083110\n",
      "2025-03-16 20:33:02,297 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.090994\n",
      "2025-03-16 20:33:02,654 - sciml.model.deeponet.deeponet - INFO - Epoch 112/300\n",
      "2025-03-16 20:33:02,654 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082715\n",
      "2025-03-16 20:33:02,655 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.089616\n",
      "2025-03-16 20:33:03,008 - sciml.model.deeponet.deeponet - INFO - Epoch 113/300\n",
      "2025-03-16 20:33:03,009 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082503\n",
      "2025-03-16 20:33:03,010 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.089538\n",
      "2025-03-16 20:33:03,366 - sciml.model.deeponet.deeponet - INFO - Epoch 114/300\n",
      "2025-03-16 20:33:03,367 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082277\n",
      "2025-03-16 20:33:03,367 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.089399\n",
      "2025-03-16 20:33:03,715 - sciml.model.deeponet.deeponet - INFO - Epoch 115/300\n",
      "2025-03-16 20:33:03,715 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.081842\n",
      "2025-03-16 20:33:03,716 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.089407\n",
      "2025-03-16 20:33:04,070 - sciml.model.deeponet.deeponet - INFO - Epoch 116/300\n",
      "2025-03-16 20:33:04,070 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.081587\n",
      "2025-03-16 20:33:04,071 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.088755\n",
      "2025-03-16 20:33:04,421 - sciml.model.deeponet.deeponet - INFO - Epoch 117/300\n",
      "2025-03-16 20:33:04,422 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.081312\n",
      "2025-03-16 20:33:04,422 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.088843\n",
      "Training progress:  39%|███▉      | 117/300 [00:36<00:20,  9.15it/s]2025-03-16 20:33:04,779 - sciml.model.deeponet.deeponet - INFO - Epoch 118/300\n",
      "2025-03-16 20:33:04,780 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.081257\n",
      "2025-03-16 20:33:04,781 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.088005\n",
      "2025-03-16 20:33:05,122 - sciml.model.deeponet.deeponet - INFO - Epoch 119/300\n",
      "2025-03-16 20:33:05,123 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.081074\n",
      "2025-03-16 20:33:05,124 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.088503\n",
      "Training progress:  40%|███▉      | 119/300 [00:36<00:28,  6.33it/s]2025-03-16 20:33:05,484 - sciml.model.deeponet.deeponet - INFO - Epoch 120/300\n",
      "2025-03-16 20:33:05,485 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.081030\n",
      "2025-03-16 20:33:05,486 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.088560\n",
      "Training progress:  40%|████      | 120/300 [00:37<00:33,  5.45it/s]2025-03-16 20:33:05,838 - sciml.model.deeponet.deeponet - INFO - Epoch 121/300\n",
      "2025-03-16 20:33:05,839 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.081234\n",
      "2025-03-16 20:33:05,840 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.089160\n",
      "Training progress:  40%|████      | 121/300 [00:37<00:37,  4.77it/s]2025-03-16 20:33:06,197 - sciml.model.deeponet.deeponet - INFO - Epoch 122/300\n",
      "2025-03-16 20:33:06,197 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.081894\n",
      "2025-03-16 20:33:06,198 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.090501\n",
      "Training progress:  41%|████      | 122/300 [00:38<00:42,  4.24it/s]2025-03-16 20:33:06,552 - sciml.model.deeponet.deeponet - INFO - Epoch 123/300\n",
      "2025-03-16 20:33:06,553 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084612\n",
      "2025-03-16 20:33:06,553 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092945\n",
      "Training progress:  41%|████      | 123/300 [00:38<00:46,  3.84it/s]2025-03-16 20:33:06,904 - sciml.model.deeponet.deeponet - INFO - Epoch 124/300\n",
      "2025-03-16 20:33:06,905 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.085809\n",
      "2025-03-16 20:33:06,915 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.093913\n",
      "Training progress:  41%|████▏     | 124/300 [00:38<00:49,  3.53it/s]2025-03-16 20:33:07,270 - sciml.model.deeponet.deeponet - INFO - Epoch 125/300\n",
      "2025-03-16 20:33:07,271 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.088591\n",
      "2025-03-16 20:33:07,271 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.088158\n",
      "Training progress:  42%|████▏     | 125/300 [00:39<00:52,  3.32it/s]2025-03-16 20:33:07,632 - sciml.model.deeponet.deeponet - INFO - Epoch 126/300\n",
      "2025-03-16 20:33:07,633 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.081036\n",
      "2025-03-16 20:33:07,633 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.090328\n",
      "Training progress:  42%|████▏     | 126/300 [00:39<00:55,  3.16it/s]2025-03-16 20:33:07,991 - sciml.model.deeponet.deeponet - INFO - Epoch 127/300\n",
      "2025-03-16 20:33:07,991 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082746\n",
      "2025-03-16 20:33:07,992 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.093826\n",
      "Training progress:  42%|████▏     | 127/300 [00:39<00:56,  3.05it/s]2025-03-16 20:33:08,354 - sciml.model.deeponet.deeponet - INFO - Epoch 128/300\n",
      "2025-03-16 20:33:08,355 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.089141\n",
      "2025-03-16 20:33:08,355 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.087036\n",
      "Training progress:  43%|████▎     | 128/300 [00:40<00:58,  2.96it/s]2025-03-16 20:33:08,710 - sciml.model.deeponet.deeponet - INFO - Epoch 129/300\n",
      "2025-03-16 20:33:08,711 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.080501\n",
      "2025-03-16 20:33:08,711 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.091123\n",
      "Training progress:  43%|████▎     | 129/300 [00:40<00:58,  2.92it/s]2025-03-16 20:33:09,066 - sciml.model.deeponet.deeponet - INFO - Epoch 130/300\n",
      "2025-03-16 20:33:09,067 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084465\n",
      "2025-03-16 20:33:09,067 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.095015\n",
      "Training progress:  43%|████▎     | 130/300 [00:40<00:58,  2.88it/s]2025-03-16 20:33:09,420 - sciml.model.deeponet.deeponet - INFO - Epoch 131/300\n",
      "2025-03-16 20:33:09,421 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.089834\n",
      "2025-03-16 20:33:09,421 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.087955\n",
      "Training progress:  44%|████▎     | 131/300 [00:41<00:58,  2.87it/s]2025-03-16 20:33:09,815 - sciml.model.deeponet.deeponet - INFO - Epoch 132/300\n",
      "2025-03-16 20:33:09,816 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.080816\n",
      "2025-03-16 20:33:09,816 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.099071\n",
      "Training progress:  44%|████▍     | 132/300 [00:41<01:00,  2.76it/s]2025-03-16 20:33:10,171 - sciml.model.deeponet.deeponet - INFO - Epoch 133/300\n",
      "2025-03-16 20:33:10,173 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.093049\n",
      "2025-03-16 20:33:10,173 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.091286\n",
      "Training progress:  44%|████▍     | 133/300 [00:42<01:00,  2.77it/s]2025-03-16 20:33:10,530 - sciml.model.deeponet.deeponet - INFO - Epoch 134/300\n",
      "2025-03-16 20:33:10,530 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.087705\n",
      "2025-03-16 20:33:10,531 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.089040\n",
      "Training progress:  45%|████▍     | 134/300 [00:42<00:59,  2.78it/s]2025-03-16 20:33:10,885 - sciml.model.deeponet.deeponet - INFO - Epoch 135/300\n",
      "2025-03-16 20:33:10,886 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.086415\n",
      "2025-03-16 20:33:10,888 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.097098\n",
      "Training progress:  45%|████▌     | 135/300 [00:42<00:59,  2.78it/s]2025-03-16 20:33:11,242 - sciml.model.deeponet.deeponet - INFO - Epoch 136/300\n",
      "2025-03-16 20:33:11,243 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.089904\n",
      "2025-03-16 20:33:11,244 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.086859\n",
      "Training progress:  45%|████▌     | 136/300 [00:43<00:58,  2.79it/s]2025-03-16 20:33:11,596 - sciml.model.deeponet.deeponet - INFO - Epoch 137/300\n",
      "2025-03-16 20:33:11,597 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.081172\n",
      "2025-03-16 20:33:11,597 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.091684\n",
      "Training progress:  46%|████▌     | 137/300 [00:43<00:58,  2.80it/s]2025-03-16 20:33:11,947 - sciml.model.deeponet.deeponet - INFO - Epoch 138/300\n",
      "2025-03-16 20:33:11,948 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.084609\n",
      "2025-03-16 20:33:11,948 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.092018\n",
      "Training progress:  46%|████▌     | 138/300 [00:43<00:57,  2.82it/s]2025-03-16 20:33:12,347 - sciml.model.deeponet.deeponet - INFO - Epoch 139/300\n",
      "2025-03-16 20:33:12,348 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.081840\n",
      "2025-03-16 20:33:12,349 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.094914\n",
      "Training progress:  46%|████▋     | 139/300 [00:44<00:59,  2.71it/s]2025-03-16 20:33:12,735 - sciml.model.deeponet.deeponet - INFO - Epoch 140/300\n",
      "2025-03-16 20:33:12,735 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.085406\n",
      "2025-03-16 20:33:12,736 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.089219\n",
      "Training progress:  47%|████▋     | 140/300 [00:44<00:59,  2.67it/s]2025-03-16 20:33:13,100 - sciml.model.deeponet.deeponet - INFO - Epoch 141/300\n",
      "2025-03-16 20:33:13,101 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.080941\n",
      "2025-03-16 20:33:13,102 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.088605\n",
      "Training progress:  47%|████▋     | 141/300 [00:44<00:59,  2.69it/s]2025-03-16 20:33:13,503 - sciml.model.deeponet.deeponet - INFO - Epoch 142/300\n",
      "2025-03-16 20:33:13,504 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082726\n",
      "2025-03-16 20:33:13,505 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.086585\n",
      "Training progress:  47%|████▋     | 142/300 [00:45<01:00,  2.63it/s]2025-03-16 20:33:13,856 - sciml.model.deeponet.deeponet - INFO - Epoch 143/300\n",
      "2025-03-16 20:33:13,857 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.080934\n",
      "2025-03-16 20:33:13,858 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.088070\n",
      "Training progress:  48%|████▊     | 143/300 [00:45<00:58,  2.68it/s]2025-03-16 20:33:14,197 - sciml.model.deeponet.deeponet - INFO - Epoch 144/300\n",
      "2025-03-16 20:33:14,198 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.082684\n",
      "2025-03-16 20:33:14,198 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.084185\n",
      "Training progress:  48%|████▊     | 144/300 [00:46<00:56,  2.75it/s]2025-03-16 20:33:14,548 - sciml.model.deeponet.deeponet - INFO - Epoch 145/300\n",
      "2025-03-16 20:33:14,549 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.080686\n",
      "2025-03-16 20:33:14,549 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.086301\n",
      "Training progress:  48%|████▊     | 145/300 [00:46<00:55,  2.78it/s]2025-03-16 20:33:14,903 - sciml.model.deeponet.deeponet - INFO - Epoch 146/300\n",
      "2025-03-16 20:33:14,904 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.081172\n",
      "2025-03-16 20:33:14,905 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.088188\n",
      "Training progress:  49%|████▊     | 146/300 [00:46<00:55,  2.79it/s]2025-03-16 20:33:15,249 - sciml.model.deeponet.deeponet - INFO - Epoch 147/300\n",
      "2025-03-16 20:33:15,250 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.080405\n",
      "2025-03-16 20:33:15,251 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.088529\n",
      "Training progress:  49%|████▉     | 147/300 [00:47<00:54,  2.82it/s]2025-03-16 20:33:15,609 - sciml.model.deeponet.deeponet - INFO - Epoch 148/300\n",
      "2025-03-16 20:33:15,610 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.081065\n",
      "2025-03-16 20:33:15,610 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.086214\n",
      "Training progress:  49%|████▉     | 148/300 [00:47<00:54,  2.81it/s]2025-03-16 20:33:15,953 - sciml.model.deeponet.deeponet - INFO - Epoch 149/300\n",
      "2025-03-16 20:33:15,954 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.080230\n",
      "2025-03-16 20:33:15,954 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.086675\n",
      "Training progress:  50%|████▉     | 149/300 [00:47<00:53,  2.84it/s]2025-03-16 20:33:16,301 - sciml.model.deeponet.deeponet - INFO - Epoch 150/300\n",
      "2025-03-16 20:33:16,302 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.080441\n",
      "2025-03-16 20:33:16,303 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.087216\n",
      "Training progress:  50%|█████     | 150/300 [00:48<00:52,  2.85it/s]2025-03-16 20:33:16,650 - sciml.model.deeponet.deeponet - INFO - Epoch 151/300\n",
      "2025-03-16 20:33:16,651 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.079756\n",
      "2025-03-16 20:33:16,651 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.086874\n",
      "Training progress:  50%|█████     | 151/300 [00:48<00:52,  2.85it/s]2025-03-16 20:33:17,003 - sciml.model.deeponet.deeponet - INFO - Epoch 152/300\n",
      "2025-03-16 20:33:17,004 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.080018\n",
      "2025-03-16 20:33:17,004 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.084031\n",
      "Training progress:  51%|█████     | 152/300 [00:48<00:51,  2.85it/s]2025-03-16 20:33:17,356 - sciml.model.deeponet.deeponet - INFO - Epoch 153/300\n",
      "2025-03-16 20:33:17,357 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.079694\n",
      "2025-03-16 20:33:17,358 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.083743\n",
      "Training progress:  51%|█████     | 153/300 [00:49<00:51,  2.84it/s]2025-03-16 20:33:17,712 - sciml.model.deeponet.deeponet - INFO - Epoch 154/300\n",
      "2025-03-16 20:33:17,713 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.079430\n",
      "2025-03-16 20:33:17,713 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.085104\n",
      "Training progress:  51%|█████▏    | 154/300 [00:49<00:51,  2.83it/s]2025-03-16 20:33:18,062 - sciml.model.deeponet.deeponet - INFO - Epoch 155/300\n",
      "2025-03-16 20:33:18,063 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.079549\n",
      "2025-03-16 20:33:18,064 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.084374\n",
      "Training progress:  52%|█████▏    | 155/300 [00:49<00:51,  2.84it/s]2025-03-16 20:33:18,416 - sciml.model.deeponet.deeponet - INFO - Epoch 156/300\n",
      "2025-03-16 20:33:18,417 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.079066\n",
      "2025-03-16 20:33:18,417 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.084046\n",
      "Training progress:  52%|█████▏    | 156/300 [00:50<00:50,  2.84it/s]2025-03-16 20:33:18,763 - sciml.model.deeponet.deeponet - INFO - Epoch 157/300\n",
      "2025-03-16 20:33:18,764 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.079287\n",
      "2025-03-16 20:33:18,765 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.084989\n",
      "Training progress:  52%|█████▏    | 157/300 [00:50<00:50,  2.85it/s]2025-03-16 20:33:19,127 - sciml.model.deeponet.deeponet - INFO - Epoch 158/300\n",
      "2025-03-16 20:33:19,127 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.078781\n",
      "2025-03-16 20:33:19,128 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.086560\n",
      "Training progress:  53%|█████▎    | 158/300 [00:50<00:50,  2.82it/s]2025-03-16 20:33:19,493 - sciml.model.deeponet.deeponet - INFO - Epoch 159/300\n",
      "2025-03-16 20:33:19,494 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.079133\n",
      "2025-03-16 20:33:19,494 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.085033\n",
      "Training progress:  53%|█████▎    | 159/300 [00:51<00:50,  2.79it/s]2025-03-16 20:33:19,846 - sciml.model.deeponet.deeponet - INFO - Epoch 160/300\n",
      "2025-03-16 20:33:19,847 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.078462\n",
      "2025-03-16 20:33:19,848 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.084104\n",
      "Training progress:  53%|█████▎    | 160/300 [00:51<00:49,  2.80it/s]2025-03-16 20:33:20,206 - sciml.model.deeponet.deeponet - INFO - Epoch 161/300\n",
      "2025-03-16 20:33:20,207 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.078793\n",
      "2025-03-16 20:33:20,208 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.084111\n",
      "Training progress:  54%|█████▎    | 161/300 [00:52<00:49,  2.79it/s]2025-03-16 20:33:20,578 - sciml.model.deeponet.deeponet - INFO - Epoch 162/300\n",
      "2025-03-16 20:33:20,579 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.078324\n",
      "2025-03-16 20:33:20,580 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.084718\n",
      "Training progress:  54%|█████▍    | 162/300 [00:52<00:49,  2.76it/s]2025-03-16 20:33:20,927 - sciml.model.deeponet.deeponet - INFO - Epoch 163/300\n",
      "2025-03-16 20:33:20,928 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.078656\n",
      "2025-03-16 20:33:20,929 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.083490\n",
      "Training progress:  54%|█████▍    | 163/300 [00:52<00:49,  2.79it/s]2025-03-16 20:33:21,290 - sciml.model.deeponet.deeponet - INFO - Epoch 164/300\n",
      "2025-03-16 20:33:21,291 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.078364\n",
      "2025-03-16 20:33:21,292 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.083176\n",
      "Training progress:  55%|█████▍    | 164/300 [00:53<00:48,  2.78it/s]2025-03-16 20:33:21,647 - sciml.model.deeponet.deeponet - INFO - Epoch 165/300\n",
      "2025-03-16 20:33:21,648 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.078210\n",
      "2025-03-16 20:33:21,648 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.084065\n",
      "Training progress:  55%|█████▌    | 165/300 [00:53<00:48,  2.79it/s]2025-03-16 20:33:22,004 - sciml.model.deeponet.deeponet - INFO - Epoch 166/300\n",
      "2025-03-16 20:33:22,005 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.078281\n",
      "2025-03-16 20:33:22,005 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.083804\n",
      "Training progress:  55%|█████▌    | 166/300 [00:53<00:47,  2.79it/s]2025-03-16 20:33:22,367 - sciml.model.deeponet.deeponet - INFO - Epoch 167/300\n",
      "2025-03-16 20:33:22,367 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.077982\n",
      "2025-03-16 20:33:22,368 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.083283\n",
      "Training progress:  56%|█████▌    | 167/300 [00:54<00:47,  2.78it/s]2025-03-16 20:33:22,721 - sciml.model.deeponet.deeponet - INFO - Epoch 168/300\n",
      "2025-03-16 20:33:22,722 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.078143\n",
      "2025-03-16 20:33:22,723 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.083165\n",
      "Training progress:  56%|█████▌    | 168/300 [00:54<00:47,  2.79it/s]2025-03-16 20:33:23,069 - sciml.model.deeponet.deeponet - INFO - Epoch 169/300\n",
      "2025-03-16 20:33:23,070 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.077848\n",
      "2025-03-16 20:33:23,071 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.083363\n",
      "Training progress:  56%|█████▋    | 169/300 [00:54<00:46,  2.82it/s]2025-03-16 20:33:23,427 - sciml.model.deeponet.deeponet - INFO - Epoch 170/300\n",
      "2025-03-16 20:33:23,428 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.077912\n",
      "2025-03-16 20:33:23,429 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.082769\n",
      "Training progress:  57%|█████▋    | 170/300 [00:55<00:46,  2.81it/s]2025-03-16 20:33:23,773 - sciml.model.deeponet.deeponet - INFO - Epoch 171/300\n",
      "2025-03-16 20:33:23,774 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.077811\n",
      "2025-03-16 20:33:23,774 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.082676\n",
      "Training progress:  57%|█████▋    | 171/300 [00:55<00:45,  2.83it/s]2025-03-16 20:33:24,120 - sciml.model.deeponet.deeponet - INFO - Epoch 172/300\n",
      "2025-03-16 20:33:24,121 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.077638\n",
      "2025-03-16 20:33:24,121 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.083607\n",
      "Training progress:  57%|█████▋    | 172/300 [00:55<00:44,  2.85it/s]2025-03-16 20:33:24,471 - sciml.model.deeponet.deeponet - INFO - Epoch 173/300\n",
      "2025-03-16 20:33:24,472 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.077721\n",
      "2025-03-16 20:33:24,473 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.083594\n",
      "Training progress:  58%|█████▊    | 173/300 [00:56<00:44,  2.85it/s]2025-03-16 20:33:24,823 - sciml.model.deeponet.deeponet - INFO - Epoch 174/300\n",
      "2025-03-16 20:33:24,823 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.077515\n",
      "2025-03-16 20:33:24,824 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.083318\n",
      "Training progress:  58%|█████▊    | 174/300 [00:56<00:44,  2.85it/s]2025-03-16 20:33:25,181 - sciml.model.deeponet.deeponet - INFO - Epoch 175/300\n",
      "2025-03-16 20:33:25,182 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.077490\n",
      "2025-03-16 20:33:25,183 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.083145\n",
      "Training progress:  58%|█████▊    | 175/300 [00:57<00:44,  2.83it/s]2025-03-16 20:33:25,534 - sciml.model.deeponet.deeponet - INFO - Epoch 176/300\n",
      "2025-03-16 20:33:25,535 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.077490\n",
      "2025-03-16 20:33:25,535 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.082387\n",
      "Training progress:  59%|█████▊    | 176/300 [00:57<00:43,  2.83it/s]2025-03-16 20:33:25,881 - sciml.model.deeponet.deeponet - INFO - Epoch 177/300\n",
      "2025-03-16 20:33:25,882 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.077303\n",
      "2025-03-16 20:33:25,882 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.082080\n",
      "Training progress:  59%|█████▉    | 177/300 [00:57<00:43,  2.85it/s]2025-03-16 20:33:26,232 - sciml.model.deeponet.deeponet - INFO - Epoch 178/300\n",
      "2025-03-16 20:33:26,233 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.077303\n",
      "2025-03-16 20:33:26,234 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.082349\n",
      "Training progress:  59%|█████▉    | 178/300 [00:58<00:42,  2.85it/s]2025-03-16 20:33:26,583 - sciml.model.deeponet.deeponet - INFO - Epoch 179/300\n",
      "2025-03-16 20:33:26,584 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.077250\n",
      "2025-03-16 20:33:26,584 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.082119\n",
      "Training progress:  60%|█████▉    | 179/300 [00:58<00:42,  2.85it/s]2025-03-16 20:33:26,941 - sciml.model.deeponet.deeponet - INFO - Epoch 180/300\n",
      "2025-03-16 20:33:26,942 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.077117\n",
      "2025-03-16 20:33:26,943 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.082411\n",
      "Training progress:  60%|██████    | 180/300 [00:58<00:42,  2.83it/s]2025-03-16 20:33:27,307 - sciml.model.deeponet.deeponet - INFO - Epoch 181/300\n",
      "2025-03-16 20:33:27,308 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.077107\n",
      "2025-03-16 20:33:27,309 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.082800\n",
      "Training progress:  60%|██████    | 181/300 [00:59<00:42,  2.80it/s]2025-03-16 20:33:27,688 - sciml.model.deeponet.deeponet - INFO - Epoch 182/300\n",
      "2025-03-16 20:33:27,689 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.077023\n",
      "2025-03-16 20:33:27,690 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.082683\n",
      "Training progress:  61%|██████    | 182/300 [00:59<00:42,  2.75it/s]2025-03-16 20:33:28,041 - sciml.model.deeponet.deeponet - INFO - Epoch 183/300\n",
      "2025-03-16 20:33:28,041 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.076935\n",
      "2025-03-16 20:33:28,042 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.082434\n",
      "Training progress:  61%|██████    | 183/300 [00:59<00:42,  2.77it/s]2025-03-16 20:33:28,392 - sciml.model.deeponet.deeponet - INFO - Epoch 184/300\n",
      "2025-03-16 20:33:28,392 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.076915\n",
      "2025-03-16 20:33:28,393 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.081835\n",
      "Training progress:  61%|██████▏   | 184/300 [01:00<00:41,  2.79it/s]2025-03-16 20:33:28,738 - sciml.model.deeponet.deeponet - INFO - Epoch 185/300\n",
      "2025-03-16 20:33:28,739 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.076845\n",
      "2025-03-16 20:33:28,739 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.081353\n",
      "Training progress:  62%|██████▏   | 185/300 [01:00<00:40,  2.82it/s]2025-03-16 20:33:29,089 - sciml.model.deeponet.deeponet - INFO - Epoch 186/300\n",
      "2025-03-16 20:33:29,090 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.076760\n",
      "2025-03-16 20:33:29,091 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.081542\n",
      "Training progress:  62%|██████▏   | 186/300 [01:00<00:40,  2.83it/s]2025-03-16 20:33:29,432 - sciml.model.deeponet.deeponet - INFO - Epoch 187/300\n",
      "2025-03-16 20:33:29,433 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.076724\n",
      "2025-03-16 20:33:29,434 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.081444\n",
      "Training progress:  62%|██████▏   | 187/300 [01:01<00:39,  2.85it/s]2025-03-16 20:33:29,784 - sciml.model.deeponet.deeponet - INFO - Epoch 188/300\n",
      "2025-03-16 20:33:29,785 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.076648\n",
      "2025-03-16 20:33:29,785 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.081552\n",
      "Training progress:  63%|██████▎   | 188/300 [01:01<00:39,  2.85it/s]2025-03-16 20:33:30,144 - sciml.model.deeponet.deeponet - INFO - Epoch 189/300\n",
      "2025-03-16 20:33:30,144 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.076580\n",
      "2025-03-16 20:33:30,145 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.082066\n",
      "Training progress:  63%|██████▎   | 189/300 [01:02<00:39,  2.83it/s]2025-03-16 20:33:30,513 - sciml.model.deeponet.deeponet - INFO - Epoch 190/300\n",
      "2025-03-16 20:33:30,514 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.076534\n",
      "2025-03-16 20:33:30,515 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.081695\n",
      "Training progress:  63%|██████▎   | 190/300 [01:02<00:39,  2.79it/s]2025-03-16 20:33:30,873 - sciml.model.deeponet.deeponet - INFO - Epoch 191/300\n",
      "2025-03-16 20:33:30,873 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.076487\n",
      "2025-03-16 20:33:30,874 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.081999\n",
      "Training progress:  64%|██████▎   | 191/300 [01:02<00:39,  2.79it/s]2025-03-16 20:33:31,225 - sciml.model.deeponet.deeponet - INFO - Epoch 192/300\n",
      "2025-03-16 20:33:31,226 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.076432\n",
      "2025-03-16 20:33:31,226 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.081236\n",
      "Training progress:  64%|██████▍   | 192/300 [01:03<00:38,  2.80it/s]2025-03-16 20:33:31,573 - sciml.model.deeponet.deeponet - INFO - Epoch 193/300\n",
      "2025-03-16 20:33:31,574 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.076341\n",
      "2025-03-16 20:33:31,574 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.081131\n",
      "Training progress:  64%|██████▍   | 193/300 [01:03<00:37,  2.82it/s]2025-03-16 20:33:31,929 - sciml.model.deeponet.deeponet - INFO - Epoch 194/300\n",
      "2025-03-16 20:33:31,930 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.076294\n",
      "2025-03-16 20:33:31,931 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.080873\n",
      "Training progress:  65%|██████▍   | 194/300 [01:03<00:37,  2.82it/s]2025-03-16 20:33:32,286 - sciml.model.deeponet.deeponet - INFO - Epoch 195/300\n",
      "2025-03-16 20:33:32,287 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.076248\n",
      "2025-03-16 20:33:32,288 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.080857\n",
      "Training progress:  65%|██████▌   | 195/300 [01:04<00:37,  2.81it/s]2025-03-16 20:33:32,638 - sciml.model.deeponet.deeponet - INFO - Epoch 196/300\n",
      "2025-03-16 20:33:32,639 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.076204\n",
      "2025-03-16 20:33:32,640 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.080950\n",
      "Training progress:  65%|██████▌   | 196/300 [01:04<00:36,  2.82it/s]2025-03-16 20:33:32,994 - sciml.model.deeponet.deeponet - INFO - Epoch 197/300\n",
      "2025-03-16 20:33:32,995 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.076165\n",
      "2025-03-16 20:33:32,995 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.081259\n",
      "Training progress:  66%|██████▌   | 197/300 [01:04<00:36,  2.82it/s]2025-03-16 20:33:33,342 - sciml.model.deeponet.deeponet - INFO - Epoch 198/300\n",
      "2025-03-16 20:33:33,343 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.076133\n",
      "2025-03-16 20:33:33,344 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.080771\n",
      "Training progress:  66%|██████▌   | 198/300 [01:05<00:35,  2.84it/s]2025-03-16 20:33:30,756 - sciml.model.deeponet.deeponet - INFO - Epoch 199/300\n",
      "2025-03-16 20:33:30,757 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.076122\n",
      "2025-03-16 20:33:30,757 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.081205\n",
      "2025-03-16 20:33:31,111 - sciml.model.deeponet.deeponet - INFO - Epoch 200/300\n",
      "2025-03-16 20:33:31,112 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.076223\n",
      "2025-03-16 20:33:31,112 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.080023\n",
      "2025-03-16 20:33:31,465 - sciml.model.deeponet.deeponet - INFO - Epoch 201/300\n",
      "2025-03-16 20:33:31,466 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.076298\n",
      "2025-03-16 20:33:31,466 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.081175\n",
      "2025-03-16 20:33:31,816 - sciml.model.deeponet.deeponet - INFO - Epoch 202/300\n",
      "2025-03-16 20:33:31,817 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.076354\n",
      "2025-03-16 20:33:31,817 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.080618\n",
      "2025-03-16 20:33:32,166 - sciml.model.deeponet.deeponet - INFO - Epoch 203/300\n",
      "2025-03-16 20:33:32,167 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.076174\n",
      "2025-03-16 20:33:32,167 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.080429\n",
      "2025-03-16 20:33:32,510 - sciml.model.deeponet.deeponet - INFO - Epoch 204/300\n",
      "2025-03-16 20:33:32,511 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075984\n",
      "2025-03-16 20:33:32,512 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.080935\n",
      "2025-03-16 20:33:32,864 - sciml.model.deeponet.deeponet - INFO - Epoch 205/300\n",
      "2025-03-16 20:33:32,865 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075958\n",
      "2025-03-16 20:33:32,865 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.079364\n",
      "2025-03-16 20:33:33,215 - sciml.model.deeponet.deeponet - INFO - Epoch 206/300\n",
      "2025-03-16 20:33:33,216 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075903\n",
      "2025-03-16 20:33:33,217 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.080429\n",
      "2025-03-16 20:33:33,566 - sciml.model.deeponet.deeponet - INFO - Epoch 207/300\n",
      "2025-03-16 20:33:33,567 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075868\n",
      "2025-03-16 20:33:33,568 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.080037\n",
      "Training progress:  69%|██████▉   | 207/300 [01:05<00:08, 10.82it/s]2025-03-16 20:33:33,914 - sciml.model.deeponet.deeponet - INFO - Epoch 208/300\n",
      "2025-03-16 20:33:33,914 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075867\n",
      "2025-03-16 20:33:33,915 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.079968\n",
      "2025-03-16 20:33:34,264 - sciml.model.deeponet.deeponet - INFO - Epoch 209/300\n",
      "2025-03-16 20:33:34,265 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.076009\n",
      "2025-03-16 20:33:34,266 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.080970\n",
      "Training progress:  70%|██████▉   | 209/300 [01:06<00:13,  6.94it/s]2025-03-16 20:33:34,618 - sciml.model.deeponet.deeponet - INFO - Epoch 210/300\n",
      "2025-03-16 20:33:34,619 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.076225\n",
      "2025-03-16 20:33:34,619 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.079480\n",
      "2025-03-16 20:33:34,969 - sciml.model.deeponet.deeponet - INFO - Epoch 211/300\n",
      "2025-03-16 20:33:34,969 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.076138\n",
      "2025-03-16 20:33:34,970 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.080050\n",
      "Training progress:  70%|███████   | 211/300 [01:06<00:16,  5.25it/s]2025-03-16 20:33:35,324 - sciml.model.deeponet.deeponet - INFO - Epoch 212/300\n",
      "2025-03-16 20:33:35,325 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075829\n",
      "2025-03-16 20:33:35,326 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.079452\n",
      "Training progress:  71%|███████   | 212/300 [01:07<00:18,  4.69it/s]2025-03-16 20:33:35,675 - sciml.model.deeponet.deeponet - INFO - Epoch 213/300\n",
      "2025-03-16 20:33:35,676 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075487\n",
      "2025-03-16 20:33:35,676 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.078998\n",
      "Training progress:  71%|███████   | 213/300 [01:07<00:20,  4.24it/s]2025-03-16 20:33:36,023 - sciml.model.deeponet.deeponet - INFO - Epoch 214/300\n",
      "2025-03-16 20:33:36,024 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075519\n",
      "2025-03-16 20:33:36,024 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.080513\n",
      "Training progress:  71%|███████▏  | 214/300 [01:07<00:22,  3.89it/s]2025-03-16 20:33:36,372 - sciml.model.deeponet.deeponet - INFO - Epoch 215/300\n",
      "2025-03-16 20:33:36,372 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075860\n",
      "2025-03-16 20:33:36,373 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.078739\n",
      "Training progress:  72%|███████▏  | 215/300 [01:08<00:23,  3.61it/s]2025-03-16 20:33:36,720 - sciml.model.deeponet.deeponet - INFO - Epoch 216/300\n",
      "2025-03-16 20:33:36,721 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075624\n",
      "2025-03-16 20:33:36,722 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.079186\n",
      "Training progress:  72%|███████▏  | 216/300 [01:08<00:24,  3.41it/s]2025-03-16 20:33:37,071 - sciml.model.deeponet.deeponet - INFO - Epoch 217/300\n",
      "2025-03-16 20:33:37,072 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075537\n",
      "2025-03-16 20:33:37,073 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.080036\n",
      "Training progress:  72%|███████▏  | 217/300 [01:08<00:25,  3.25it/s]2025-03-16 20:33:37,422 - sciml.model.deeponet.deeponet - INFO - Epoch 218/300\n",
      "2025-03-16 20:33:37,423 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075866\n",
      "2025-03-16 20:33:37,424 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.078874\n",
      "Training progress:  73%|███████▎  | 218/300 [01:09<00:26,  3.13it/s]2025-03-16 20:33:37,770 - sciml.model.deeponet.deeponet - INFO - Epoch 219/300\n",
      "2025-03-16 20:33:37,771 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.076291\n",
      "2025-03-16 20:33:37,771 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.080483\n",
      "Training progress:  73%|███████▎  | 219/300 [01:09<00:26,  3.06it/s]2025-03-16 20:33:38,114 - sciml.model.deeponet.deeponet - INFO - Epoch 220/300\n",
      "2025-03-16 20:33:38,114 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.076650\n",
      "2025-03-16 20:33:38,116 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.080786\n",
      "Training progress:  73%|███████▎  | 220/300 [01:09<00:26,  3.01it/s]2025-03-16 20:33:38,461 - sciml.model.deeponet.deeponet - INFO - Epoch 221/300\n",
      "2025-03-16 20:33:38,462 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.076888\n",
      "2025-03-16 20:33:38,463 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.078550\n",
      "Training progress:  74%|███████▎  | 221/300 [01:10<00:26,  2.97it/s]2025-03-16 20:33:38,817 - sciml.model.deeponet.deeponet - INFO - Epoch 222/300\n",
      "2025-03-16 20:33:38,818 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.077224\n",
      "2025-03-16 20:33:38,818 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.080596\n",
      "Training progress:  74%|███████▍  | 222/300 [01:10<00:26,  2.92it/s]2025-03-16 20:33:39,166 - sciml.model.deeponet.deeponet - INFO - Epoch 223/300\n",
      "2025-03-16 20:33:39,167 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.077010\n",
      "2025-03-16 20:33:39,167 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.078250\n",
      "Training progress:  74%|███████▍  | 223/300 [01:11<00:26,  2.91it/s]2025-03-16 20:33:39,518 - sciml.model.deeponet.deeponet - INFO - Epoch 224/300\n",
      "2025-03-16 20:33:39,519 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075326\n",
      "2025-03-16 20:33:39,520 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.077268\n",
      "Training progress:  75%|███████▍  | 224/300 [01:11<00:26,  2.89it/s]2025-03-16 20:33:39,867 - sciml.model.deeponet.deeponet - INFO - Epoch 225/300\n",
      "2025-03-16 20:33:39,868 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.076180\n",
      "2025-03-16 20:33:39,868 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.081393\n",
      "Training progress:  75%|███████▌  | 225/300 [01:11<00:26,  2.88it/s]2025-03-16 20:33:40,226 - sciml.model.deeponet.deeponet - INFO - Epoch 226/300\n",
      "2025-03-16 20:33:40,227 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.076676\n",
      "2025-03-16 20:33:40,228 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.079248\n",
      "Training progress:  75%|███████▌  | 226/300 [01:12<00:25,  2.85it/s]2025-03-16 20:33:40,577 - sciml.model.deeponet.deeponet - INFO - Epoch 227/300\n",
      "2025-03-16 20:33:40,578 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075582\n",
      "2025-03-16 20:33:40,578 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.077104\n",
      "Training progress:  76%|███████▌  | 227/300 [01:12<00:25,  2.85it/s]2025-03-16 20:33:40,925 - sciml.model.deeponet.deeponet - INFO - Epoch 228/300\n",
      "2025-03-16 20:33:40,926 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.077457\n",
      "2025-03-16 20:33:40,926 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.079340\n",
      "Training progress:  76%|███████▌  | 228/300 [01:12<00:25,  2.86it/s]2025-03-16 20:33:41,276 - sciml.model.deeponet.deeponet - INFO - Epoch 229/300\n",
      "2025-03-16 20:33:41,277 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.076388\n",
      "2025-03-16 20:33:41,277 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.078513\n",
      "Training progress:  76%|███████▋  | 229/300 [01:13<00:24,  2.86it/s]2025-03-16 20:33:41,625 - sciml.model.deeponet.deeponet - INFO - Epoch 230/300\n",
      "2025-03-16 20:33:41,626 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075966\n",
      "2025-03-16 20:33:41,626 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.076202\n",
      "Training progress:  77%|███████▋  | 230/300 [01:13<00:24,  2.86it/s]2025-03-16 20:33:41,981 - sciml.model.deeponet.deeponet - INFO - Epoch 231/300\n",
      "2025-03-16 20:33:41,982 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.076704\n",
      "2025-03-16 20:33:41,982 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.079190\n",
      "Training progress:  77%|███████▋  | 231/300 [01:13<00:24,  2.84it/s]2025-03-16 20:33:42,335 - sciml.model.deeponet.deeponet - INFO - Epoch 232/300\n",
      "2025-03-16 20:33:42,336 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.074996\n",
      "2025-03-16 20:33:42,337 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.080300\n",
      "Training progress:  77%|███████▋  | 232/300 [01:14<00:23,  2.84it/s]2025-03-16 20:33:42,726 - sciml.model.deeponet.deeponet - INFO - Epoch 233/300\n",
      "2025-03-16 20:33:42,727 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075540\n",
      "2025-03-16 20:33:42,728 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.077408\n",
      "Training progress:  78%|███████▊  | 233/300 [01:14<00:24,  2.75it/s]2025-03-16 20:33:43,117 - sciml.model.deeponet.deeponet - INFO - Epoch 234/300\n",
      "2025-03-16 20:33:43,117 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075627\n",
      "2025-03-16 20:33:43,118 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.077027\n",
      "Training progress:  78%|███████▊  | 234/300 [01:14<00:24,  2.69it/s]2025-03-16 20:33:43,463 - sciml.model.deeponet.deeponet - INFO - Epoch 235/300\n",
      "2025-03-16 20:33:43,464 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075421\n",
      "2025-03-16 20:33:43,464 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.078570\n",
      "Training progress:  78%|███████▊  | 235/300 [01:15<00:23,  2.75it/s]2025-03-16 20:33:43,815 - sciml.model.deeponet.deeponet - INFO - Epoch 236/300\n",
      "2025-03-16 20:33:43,816 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.076236\n",
      "2025-03-16 20:33:43,816 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.077175\n",
      "Training progress:  79%|███████▊  | 236/300 [01:15<00:23,  2.77it/s]2025-03-16 20:33:44,168 - sciml.model.deeponet.deeponet - INFO - Epoch 237/300\n",
      "2025-03-16 20:33:44,168 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075484\n",
      "2025-03-16 20:33:44,169 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.077051\n",
      "Training progress:  79%|███████▉  | 237/300 [01:16<00:22,  2.79it/s]2025-03-16 20:33:44,516 - sciml.model.deeponet.deeponet - INFO - Epoch 238/300\n",
      "2025-03-16 20:33:44,516 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075534\n",
      "2025-03-16 20:33:44,517 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.079497\n",
      "Training progress:  79%|███████▉  | 238/300 [01:16<00:22,  2.82it/s]2025-03-16 20:33:44,867 - sciml.model.deeponet.deeponet - INFO - Epoch 239/300\n",
      "2025-03-16 20:33:44,868 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075103\n",
      "2025-03-16 20:33:44,868 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.078432\n",
      "Training progress:  80%|███████▉  | 239/300 [01:16<00:21,  2.83it/s]2025-03-16 20:33:45,249 - sciml.model.deeponet.deeponet - INFO - Epoch 240/300\n",
      "2025-03-16 20:33:45,250 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.074708\n",
      "2025-03-16 20:33:45,251 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.076564\n",
      "Training progress:  80%|████████  | 240/300 [01:17<00:21,  2.76it/s]2025-03-16 20:33:45,597 - sciml.model.deeponet.deeponet - INFO - Epoch 241/300\n",
      "2025-03-16 20:33:45,598 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075176\n",
      "2025-03-16 20:33:45,598 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.077393\n",
      "Training progress:  80%|████████  | 241/300 [01:17<00:21,  2.79it/s]2025-03-16 20:33:45,949 - sciml.model.deeponet.deeponet - INFO - Epoch 242/300\n",
      "2025-03-16 20:33:45,950 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075037\n",
      "2025-03-16 20:33:45,951 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.077479\n",
      "Training progress:  81%|████████  | 242/300 [01:17<00:20,  2.81it/s]2025-03-16 20:33:46,305 - sciml.model.deeponet.deeponet - INFO - Epoch 243/300\n",
      "2025-03-16 20:33:46,306 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075272\n",
      "2025-03-16 20:33:46,307 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.076402\n",
      "Training progress:  81%|████████  | 243/300 [01:18<00:20,  2.81it/s]2025-03-16 20:33:46,680 - sciml.model.deeponet.deeponet - INFO - Epoch 244/300\n",
      "2025-03-16 20:33:46,681 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075592\n",
      "2025-03-16 20:33:46,682 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.077485\n",
      "Training progress:  81%|████████▏ | 244/300 [01:18<00:20,  2.76it/s]2025-03-16 20:33:47,033 - sciml.model.deeponet.deeponet - INFO - Epoch 245/300\n",
      "2025-03-16 20:33:47,034 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075182\n",
      "2025-03-16 20:33:47,034 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.078006\n",
      "Training progress:  82%|████████▏ | 245/300 [01:18<00:19,  2.78it/s]2025-03-16 20:33:47,382 - sciml.model.deeponet.deeponet - INFO - Epoch 246/300\n",
      "2025-03-16 20:33:47,384 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075179\n",
      "2025-03-16 20:33:47,384 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.076910\n",
      "Training progress:  82%|████████▏ | 246/300 [01:19<00:19,  2.81it/s]2025-03-16 20:33:47,734 - sciml.model.deeponet.deeponet - INFO - Epoch 247/300\n",
      "2025-03-16 20:33:47,735 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.074777\n",
      "2025-03-16 20:33:47,735 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.077115\n",
      "Training progress:  82%|████████▏ | 247/300 [01:19<00:18,  2.82it/s]2025-03-16 20:33:48,081 - sciml.model.deeponet.deeponet - INFO - Epoch 248/300\n",
      "2025-03-16 20:33:48,082 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.074368\n",
      "2025-03-16 20:33:48,082 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.077293\n",
      "Training progress:  83%|████████▎ | 248/300 [01:19<00:18,  2.84it/s]2025-03-16 20:33:48,438 - sciml.model.deeponet.deeponet - INFO - Epoch 249/300\n",
      "2025-03-16 20:33:48,439 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.074326\n",
      "2025-03-16 20:33:48,439 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.076428\n",
      "Training progress:  83%|████████▎ | 249/300 [01:20<00:18,  2.83it/s]2025-03-16 20:33:48,783 - sciml.model.deeponet.deeponet - INFO - Epoch 250/300\n",
      "2025-03-16 20:33:48,784 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.074275\n",
      "2025-03-16 20:33:48,785 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.076146\n",
      "Training progress:  83%|████████▎ | 250/300 [01:20<00:17,  2.85it/s]2025-03-16 20:33:49,150 - sciml.model.deeponet.deeponet - INFO - Epoch 251/300\n",
      "2025-03-16 20:33:49,151 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.074435\n",
      "2025-03-16 20:33:49,152 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.076757\n",
      "Training progress:  84%|████████▎ | 251/300 [01:21<00:17,  2.81it/s]2025-03-16 20:33:49,519 - sciml.model.deeponet.deeponet - INFO - Epoch 252/300\n",
      "2025-03-16 20:33:49,520 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.074784\n",
      "2025-03-16 20:33:49,521 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.076741\n",
      "Training progress:  84%|████████▍ | 252/300 [01:21<00:17,  2.78it/s]2025-03-16 20:33:49,870 - sciml.model.deeponet.deeponet - INFO - Epoch 253/300\n",
      "2025-03-16 20:33:49,871 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075145\n",
      "2025-03-16 20:33:49,871 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.077343\n",
      "Training progress:  84%|████████▍ | 253/300 [01:21<00:16,  2.80it/s]2025-03-16 20:33:50,221 - sciml.model.deeponet.deeponet - INFO - Epoch 254/300\n",
      "2025-03-16 20:33:50,222 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075353\n",
      "2025-03-16 20:33:50,223 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.078533\n",
      "Training progress:  85%|████████▍ | 254/300 [01:22<00:16,  2.81it/s]2025-03-16 20:33:50,580 - sciml.model.deeponet.deeponet - INFO - Epoch 255/300\n",
      "2025-03-16 20:33:50,581 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075887\n",
      "2025-03-16 20:33:50,582 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.077294\n",
      "Training progress:  85%|████████▌ | 255/300 [01:22<00:16,  2.80it/s]2025-03-16 20:33:50,975 - sciml.model.deeponet.deeponet - INFO - Epoch 256/300\n",
      "2025-03-16 20:33:50,976 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075577\n",
      "2025-03-16 20:33:50,977 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.077060\n",
      "Training progress:  85%|████████▌ | 256/300 [01:22<00:16,  2.72it/s]2025-03-16 20:33:51,322 - sciml.model.deeponet.deeponet - INFO - Epoch 257/300\n",
      "2025-03-16 20:33:51,323 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075226\n",
      "2025-03-16 20:33:51,324 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.076165\n",
      "Training progress:  86%|████████▌ | 257/300 [01:23<00:15,  2.76it/s]2025-03-16 20:33:51,677 - sciml.model.deeponet.deeponet - INFO - Epoch 258/300\n",
      "2025-03-16 20:33:51,678 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.074434\n",
      "2025-03-16 20:33:51,678 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.075256\n",
      "Training progress:  86%|████████▌ | 258/300 [01:23<00:15,  2.78it/s]2025-03-16 20:33:52,032 - sciml.model.deeponet.deeponet - INFO - Epoch 259/300\n",
      "2025-03-16 20:33:52,032 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.074003\n",
      "2025-03-16 20:33:52,033 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.075287\n",
      "Training progress:  86%|████████▋ | 259/300 [01:23<00:14,  2.79it/s]2025-03-16 20:33:52,399 - sciml.model.deeponet.deeponet - INFO - Epoch 260/300\n",
      "2025-03-16 20:33:52,400 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.073969\n",
      "2025-03-16 20:33:52,401 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.075823\n",
      "Training progress:  87%|████████▋ | 260/300 [01:24<00:14,  2.77it/s]2025-03-16 20:33:52,762 - sciml.model.deeponet.deeponet - INFO - Epoch 261/300\n",
      "2025-03-16 20:33:52,763 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.074320\n",
      "2025-03-16 20:33:52,772 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.076501\n",
      "Training progress:  87%|████████▋ | 261/300 [01:24<00:14,  2.75it/s]2025-03-16 20:33:53,122 - sciml.model.deeponet.deeponet - INFO - Epoch 262/300\n",
      "2025-03-16 20:33:53,123 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075009\n",
      "2025-03-16 20:33:53,124 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.077174\n",
      "Training progress:  87%|████████▋ | 262/300 [01:24<00:13,  2.78it/s]2025-03-16 20:33:53,472 - sciml.model.deeponet.deeponet - INFO - Epoch 263/300\n",
      "2025-03-16 20:33:53,472 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075502\n",
      "2025-03-16 20:33:53,473 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.078042\n",
      "Training progress:  88%|████████▊ | 263/300 [01:25<00:13,  2.80it/s]2025-03-16 20:33:53,832 - sciml.model.deeponet.deeponet - INFO - Epoch 264/300\n",
      "2025-03-16 20:33:53,833 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075730\n",
      "2025-03-16 20:33:53,834 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.075293\n",
      "Training progress:  88%|████████▊ | 264/300 [01:25<00:12,  2.79it/s]2025-03-16 20:33:54,187 - sciml.model.deeponet.deeponet - INFO - Epoch 265/300\n",
      "2025-03-16 20:33:54,187 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075068\n",
      "2025-03-16 20:33:54,188 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.075554\n",
      "Training progress:  88%|████████▊ | 265/300 [01:26<00:12,  2.80it/s]2025-03-16 20:33:54,541 - sciml.model.deeponet.deeponet - INFO - Epoch 266/300\n",
      "2025-03-16 20:33:54,542 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.074206\n",
      "2025-03-16 20:33:54,542 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.074501\n",
      "Training progress:  89%|████████▊ | 266/300 [01:26<00:12,  2.81it/s]2025-03-16 20:33:54,907 - sciml.model.deeponet.deeponet - INFO - Epoch 267/300\n",
      "2025-03-16 20:33:54,908 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.074005\n",
      "2025-03-16 20:33:54,908 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.074708\n",
      "Training progress:  89%|████████▉ | 267/300 [01:26<00:11,  2.78it/s]2025-03-16 20:33:55,276 - sciml.model.deeponet.deeponet - INFO - Epoch 268/300\n",
      "2025-03-16 20:33:55,277 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.074268\n",
      "2025-03-16 20:33:55,278 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.077540\n",
      "Training progress:  89%|████████▉ | 268/300 [01:27<00:11,  2.76it/s]2025-03-16 20:33:55,636 - sciml.model.deeponet.deeponet - INFO - Epoch 269/300\n",
      "2025-03-16 20:33:55,637 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.074848\n",
      "2025-03-16 20:33:55,637 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.076159\n",
      "Training progress:  90%|████████▉ | 269/300 [01:27<00:11,  2.77it/s]2025-03-16 20:33:55,990 - sciml.model.deeponet.deeponet - INFO - Epoch 270/300\n",
      "2025-03-16 20:33:55,991 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.074609\n",
      "2025-03-16 20:33:55,991 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.075371\n",
      "Training progress:  90%|█████████ | 270/300 [01:27<00:10,  2.79it/s]2025-03-16 20:33:56,337 - sciml.model.deeponet.deeponet - INFO - Epoch 271/300\n",
      "2025-03-16 20:33:56,338 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.074674\n",
      "2025-03-16 20:33:56,338 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.075198\n",
      "Training progress:  90%|█████████ | 271/300 [01:28<00:10,  2.81it/s]2025-03-16 20:33:56,691 - sciml.model.deeponet.deeponet - INFO - Epoch 272/300\n",
      "2025-03-16 20:33:56,691 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.074067\n",
      "2025-03-16 20:33:56,692 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.074353\n",
      "Training progress:  91%|█████████ | 272/300 [01:28<00:09,  2.82it/s]2025-03-16 20:33:57,044 - sciml.model.deeponet.deeponet - INFO - Epoch 273/300\n",
      "2025-03-16 20:33:57,045 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.073770\n",
      "2025-03-16 20:33:57,046 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.074362\n",
      "Training progress:  91%|█████████ | 273/300 [01:28<00:09,  2.82it/s]2025-03-16 20:33:57,398 - sciml.model.deeponet.deeponet - INFO - Epoch 274/300\n",
      "2025-03-16 20:33:57,398 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.073722\n",
      "2025-03-16 20:33:57,399 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.075225\n",
      "Training progress:  91%|█████████▏| 274/300 [01:29<00:09,  2.82it/s]2025-03-16 20:33:57,755 - sciml.model.deeponet.deeponet - INFO - Epoch 275/300\n",
      "2025-03-16 20:33:57,756 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.073693\n",
      "2025-03-16 20:33:57,756 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.075937\n",
      "Training progress:  92%|█████████▏| 275/300 [01:29<00:08,  2.82it/s]2025-03-16 20:33:58,102 - sciml.model.deeponet.deeponet - INFO - Epoch 276/300\n",
      "2025-03-16 20:33:58,103 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.073874\n",
      "2025-03-16 20:33:58,103 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.074735\n",
      "Training progress:  92%|█████████▏| 276/300 [01:29<00:08,  2.84it/s]2025-03-16 20:33:58,449 - sciml.model.deeponet.deeponet - INFO - Epoch 277/300\n",
      "2025-03-16 20:33:58,450 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.073841\n",
      "2025-03-16 20:33:58,450 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.074613\n",
      "Training progress:  92%|█████████▏| 277/300 [01:30<00:08,  2.85it/s]2025-03-16 20:33:58,795 - sciml.model.deeponet.deeponet - INFO - Epoch 278/300\n",
      "2025-03-16 20:33:58,796 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.073899\n",
      "2025-03-16 20:33:58,797 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.074858\n",
      "Training progress:  93%|█████████▎| 278/300 [01:30<00:07,  2.86it/s]2025-03-16 20:33:59,160 - sciml.model.deeponet.deeponet - INFO - Epoch 279/300\n",
      "2025-03-16 20:33:59,161 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.074069\n",
      "2025-03-16 20:33:59,161 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.074342\n",
      "Training progress:  93%|█████████▎| 279/300 [01:31<00:07,  2.82it/s]2025-03-16 20:33:59,510 - sciml.model.deeponet.deeponet - INFO - Epoch 280/300\n",
      "2025-03-16 20:33:59,511 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.074360\n",
      "2025-03-16 20:33:59,512 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.075739\n",
      "Training progress:  93%|█████████▎| 280/300 [01:31<00:07,  2.83it/s]2025-03-16 20:33:59,866 - sciml.model.deeponet.deeponet - INFO - Epoch 281/300\n",
      "2025-03-16 20:33:59,867 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.074333\n",
      "2025-03-16 20:33:59,867 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.075850\n",
      "Training progress:  94%|█████████▎| 281/300 [01:31<00:06,  2.83it/s]2025-03-16 20:34:00,222 - sciml.model.deeponet.deeponet - INFO - Epoch 282/300\n",
      "2025-03-16 20:34:00,223 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.074123\n",
      "2025-03-16 20:34:00,224 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.074661\n",
      "Training progress:  94%|█████████▍| 282/300 [01:32<00:06,  2.82it/s]2025-03-16 20:34:00,567 - sciml.model.deeponet.deeponet - INFO - Epoch 283/300\n",
      "2025-03-16 20:34:00,568 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.074030\n",
      "2025-03-16 20:34:00,568 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.075495\n",
      "Training progress:  94%|█████████▍| 283/300 [01:32<00:05,  2.84it/s]2025-03-16 20:34:00,928 - sciml.model.deeponet.deeponet - INFO - Epoch 284/300\n",
      "2025-03-16 20:34:00,928 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.073856\n",
      "2025-03-16 20:34:00,929 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.073876\n",
      "Training progress:  95%|█████████▍| 284/300 [01:32<00:05,  2.82it/s]2025-03-16 20:34:01,282 - sciml.model.deeponet.deeponet - INFO - Epoch 285/300\n",
      "2025-03-16 20:34:01,283 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.073579\n",
      "2025-03-16 20:34:01,284 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.073757\n",
      "Training progress:  95%|█████████▌| 285/300 [01:33<00:05,  2.82it/s]2025-03-16 20:34:01,635 - sciml.model.deeponet.deeponet - INFO - Epoch 286/300\n",
      "2025-03-16 20:34:01,636 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.073752\n",
      "2025-03-16 20:34:01,636 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.075902\n",
      "Training progress:  95%|█████████▌| 286/300 [01:33<00:04,  2.83it/s]2025-03-16 20:34:01,982 - sciml.model.deeponet.deeponet - INFO - Epoch 287/300\n",
      "2025-03-16 20:34:01,982 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.074244\n",
      "2025-03-16 20:34:01,983 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.074694\n",
      "Training progress:  96%|█████████▌| 287/300 [01:33<00:04,  2.84it/s]2025-03-16 20:34:02,332 - sciml.model.deeponet.deeponet - INFO - Epoch 288/300\n",
      "2025-03-16 20:34:02,333 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.073710\n",
      "2025-03-16 20:34:02,333 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.074112\n",
      "Training progress:  96%|█████████▌| 288/300 [01:34<00:04,  2.85it/s]2025-03-16 20:34:02,684 - sciml.model.deeponet.deeponet - INFO - Epoch 289/300\n",
      "2025-03-16 20:34:02,684 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.074248\n",
      "2025-03-16 20:34:02,685 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.075975\n",
      "Training progress:  96%|█████████▋| 289/300 [01:34<00:03,  2.85it/s]2025-03-16 20:34:00,104 - sciml.model.deeponet.deeponet - INFO - Epoch 290/300\n",
      "2025-03-16 20:34:00,105 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.074940\n",
      "2025-03-16 20:34:00,106 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.075590\n",
      "2025-03-16 20:34:00,540 - sciml.model.deeponet.deeponet - INFO - Epoch 291/300\n",
      "2025-03-16 20:34:00,541 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.074374\n",
      "2025-03-16 20:34:00,542 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.073794\n",
      "2025-03-16 20:34:00,925 - sciml.model.deeponet.deeponet - INFO - Epoch 292/300\n",
      "2025-03-16 20:34:00,926 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075337\n",
      "2025-03-16 20:34:00,927 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.076872\n",
      "2025-03-16 20:34:01,272 - sciml.model.deeponet.deeponet - INFO - Epoch 293/300\n",
      "2025-03-16 20:34:01,273 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075302\n",
      "2025-03-16 20:34:01,273 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.074711\n",
      "2025-03-16 20:34:01,622 - sciml.model.deeponet.deeponet - INFO - Epoch 294/300\n",
      "2025-03-16 20:34:01,623 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.074068\n",
      "2025-03-16 20:34:01,624 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.073101\n",
      "2025-03-16 20:34:01,968 - sciml.model.deeponet.deeponet - INFO - Epoch 295/300\n",
      "2025-03-16 20:34:01,969 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.075313\n",
      "2025-03-16 20:34:01,969 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.075460\n",
      "2025-03-16 20:34:02,318 - sciml.model.deeponet.deeponet - INFO - Epoch 296/300\n",
      "2025-03-16 20:34:02,319 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.074079\n",
      "2025-03-16 20:34:02,320 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.075715\n",
      "2025-03-16 20:34:02,674 - sciml.model.deeponet.deeponet - INFO - Epoch 297/300\n",
      "2025-03-16 20:34:02,675 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.074014\n",
      "2025-03-16 20:34:02,676 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.072996\n",
      "2025-03-16 20:34:03,023 - sciml.model.deeponet.deeponet - INFO - Epoch 298/300\n",
      "2025-03-16 20:34:03,024 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.074485\n",
      "2025-03-16 20:34:03,024 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.073521\n",
      "Training progress:  99%|█████████▉| 298/300 [01:34<00:00,  9.78it/s]2025-03-16 20:34:03,381 - sciml.model.deeponet.deeponet - INFO - Epoch 299/300\n",
      "2025-03-16 20:34:03,381 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.073524\n",
      "2025-03-16 20:34:03,382 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.074717\n",
      "Training progress: 100%|█████████▉| 299/300 [01:35<00:00,  7.64it/s]2025-03-16 20:34:03,730 - sciml.model.deeponet.deeponet - INFO - Epoch 300/300\n",
      "2025-03-16 20:34:03,731 - sciml.model.deeponet.deeponet - INFO - Training Loss: 0.074029\n",
      "2025-03-16 20:34:03,731 - sciml.model.deeponet.deeponet - INFO - Test Loss: 0.073285\n",
      "Training progress: 100%|██████████| 300/300 [01:35<00:00,  3.14it/s]\n"
     ]
    }
   ],
   "source": [
    "loss_history_train,loss_history_test = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3233814239501953, 0.2927292287349701, 0.29456931352615356, 0.28803813457489014, 0.27708715200424194, 0.26923590898513794, 0.268725723028183, 0.26676154136657715, 0.2588200271129608, 0.25129812955856323, 0.24707886576652527, 0.24396221339702606, 0.23969529569149017, 0.23418766260147095, 0.22902607917785645, 0.2249894142150879, 0.2203235924243927, 0.21396200358867645, 0.20777201652526855, 0.202562615275383, 0.19673869013786316, 0.1899072229862213, 0.18369638919830322, 0.17717744410037994, 0.17006410658359528, 0.1639646738767624, 0.1576715111732483, 0.15308459103107452, 0.14859947562217712, 0.14540201425552368, 0.14228293299674988, 0.14072149991989136, 0.13833993673324585, 0.13665413856506348, 0.13481764495372772, 0.13246241211891174, 0.13072136044502258, 0.12857046723365784, 0.1263439953327179, 0.12460346519947052, 0.12260641902685165, 0.12074040621519089, 0.1193290650844574, 0.11776645481586456, 0.11611580103635788, 0.11455374211072922, 0.1131235808134079, 0.11174291372299194, 0.11028145253658295, 0.10895934700965881, 0.10772722214460373, 0.1064959466457367, 0.10537951439619064, 0.1044570803642273, 0.1037391945719719, 0.10347175598144531, 0.10294933617115021, 0.10237093269824982, 0.1001977026462555, 0.099333256483078, 0.09965085983276367, 0.09869830310344696, 0.09727464616298676, 0.09632346034049988, 0.09633179754018784, 0.09642160683870316, 0.09494012594223022, 0.09392639994621277, 0.09379218518733978, 0.09379521012306213, 0.09362011402845383, 0.09237736463546753, 0.09159290790557861, 0.09151951223611832, 0.09153854846954346, 0.09144730865955353, 0.09048188477754593, 0.08968167006969452, 0.08948013931512833, 0.08964870125055313, 0.09002219140529633, 0.0894538164138794, 0.08863890171051025, 0.08783450722694397, 0.0876162052154541, 0.08784149587154388, 0.08791640400886536, 0.08785460144281387, 0.0870765820145607, 0.08643544465303421, 0.08597713708877563, 0.0857391431927681, 0.08578882366418839, 0.08597788214683533, 0.08686722069978714, 0.08689961582422256, 0.08666369318962097, 0.08503201603889465, 0.0842190682888031, 0.0841786116361618, 0.08437229692935944, 0.08477316796779633, 0.08444826304912567, 0.08427359908819199, 0.08359089493751526, 0.08293986320495605, 0.08290815353393555, 0.08298691362142563, 0.08334936201572418, 0.0832785964012146, 0.08311012387275696, 0.08271467685699463, 0.08250278234481812, 0.08227714151144028, 0.08184237033128738, 0.0815870463848114, 0.08131210505962372, 0.08125709742307663, 0.08107419312000275, 0.08102992177009583, 0.08123351633548737, 0.08189395815134048, 0.08461245894432068, 0.08580869436264038, 0.08859144151210785, 0.08103647828102112, 0.08274644613265991, 0.08914054930210114, 0.08050087094306946, 0.08446541428565979, 0.0898343175649643, 0.08081555366516113, 0.09304944425821304, 0.08770540356636047, 0.08641510456800461, 0.08990414440631866, 0.08117173612117767, 0.08460924029350281, 0.08183964341878891, 0.08540564775466919, 0.08094055950641632, 0.08272646367549896, 0.08093449473381042, 0.08268431574106216, 0.08068645000457764, 0.08117178082466125, 0.08040490746498108, 0.08106479793787003, 0.08023017644882202, 0.08044078201055527, 0.0797562375664711, 0.08001835644245148, 0.07969403266906738, 0.079430490732193, 0.07954856753349304, 0.07906563580036163, 0.07928747683763504, 0.07878138870000839, 0.07913284748792648, 0.07846208661794662, 0.0787929892539978, 0.07832390069961548, 0.07865580916404724, 0.07836355268955231, 0.07821045815944672, 0.07828063517808914, 0.07798196375370026, 0.0781434178352356, 0.07784803211688995, 0.07791197299957275, 0.0778106153011322, 0.07763813436031342, 0.07772086560726166, 0.07751496136188507, 0.07749007642269135, 0.07748958468437195, 0.07730332016944885, 0.07730264216661453, 0.0772501528263092, 0.07711665332317352, 0.07710689306259155, 0.0770229920744896, 0.07693536579608917, 0.07691475749015808, 0.07684468477964401, 0.07675951719284058, 0.07672429084777832, 0.07664754986763, 0.076579749584198, 0.07653412222862244, 0.07648742944002151, 0.07643221318721771, 0.0763409286737442, 0.07629385590553284, 0.07624751329421997, 0.07620440423488617, 0.07616546005010605, 0.07613327354192734, 0.07612226158380508, 0.07622265815734863, 0.07629843056201935, 0.0763537585735321, 0.07617433369159698, 0.07598438858985901, 0.07595807313919067, 0.07590298354625702, 0.07586786150932312, 0.07586652040481567, 0.0760091170668602, 0.076224684715271, 0.07613825798034668, 0.07582882046699524, 0.07548652589321136, 0.0755191370844841, 0.07586048543453217, 0.07562372088432312, 0.07553707808256149, 0.07586607336997986, 0.07629133760929108, 0.07665026187896729, 0.0768880844116211, 0.07722356915473938, 0.07701049745082855, 0.07532647252082825, 0.07617965340614319, 0.07667633146047592, 0.07558182626962662, 0.07745739817619324, 0.07638847827911377, 0.0759655013680458, 0.07670357078313828, 0.07499569654464722, 0.07554003596305847, 0.07562731951475143, 0.07542110234498978, 0.07623608410358429, 0.07548442482948303, 0.07553412020206451, 0.07510265707969666, 0.07470782101154327, 0.07517597079277039, 0.0750366747379303, 0.07527238130569458, 0.07559168338775635, 0.07518178224563599, 0.07517871260643005, 0.07477746158838272, 0.07436767220497131, 0.07432648539543152, 0.0742749273777008, 0.07443492114543915, 0.07478399574756622, 0.07514543831348419, 0.07535316050052643, 0.07588671892881393, 0.07557672262191772, 0.07522566616535187, 0.07443442195653915, 0.07400290668010712, 0.07396931946277618, 0.07431952655315399, 0.07500888407230377, 0.07550151646137238, 0.07573016732931137, 0.07506754994392395, 0.07420626282691956, 0.0740048885345459, 0.07426820695400238, 0.07484809309244156, 0.07460924983024597, 0.07467368990182877, 0.07406666874885559, 0.07376977801322937, 0.0737224742770195, 0.07369308173656464, 0.07387401163578033, 0.07384103536605835, 0.07389934360980988, 0.07406942546367645, 0.07436004281044006, 0.07433319091796875, 0.07412277162075043, 0.07402975112199783, 0.07385583966970444, 0.07357912510633469, 0.07375191152095795, 0.07424364984035492, 0.07371046394109726, 0.07424809783697128, 0.07494024932384491, 0.07437410950660706, 0.07533654570579529, 0.07530198246240616, 0.0740681141614914, 0.075312539935112, 0.07407943904399872, 0.07401391118764877, 0.07448476552963257, 0.07352350652217865, 0.0740293487906456]\n"
     ]
    }
   ],
   "source": [
    "print(loss_history_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_history_train,color='blue')\n",
    "plt.plot(loss_history_test,color='red')\n",
    "plt.legend(['train','test'])\n",
    "#log \n",
    "plt.yscale('log')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
