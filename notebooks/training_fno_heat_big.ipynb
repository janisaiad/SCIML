{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9752a62a",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-17 01:47:49.974516: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-17 01:47:49.976198: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-17 01:47:50.024203: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-17 01:47:50.025610: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-17 01:47:50.729993: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-03-17 01:47:52.460363: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-17 01:47:52.511732: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "from sciml.model.fno import FNO\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "tf.config.list_physical_devices('GPU')\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38f025b0",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "nb_xi = 2 # can be deduced from mu because it's len(mu.shape) - 1\n",
    "p_1 = 30 # dimension of scheme for xi for all i\n",
    "p_2 = 30 # dimension of scheme for xi for all i\n",
    "p_3 = 30 # dimension of scheme for xi for all i\n",
    "epochs = 50\n",
    "index = 450\n",
    "n_modes = p_1\n",
    "n_layers = 4 # need to be low because there is a low difference between the with time\n",
    "alpha = 0.5\n",
    "best_loss = 0.00005\n",
    "activation = 'relu'\n",
    "kernel_initializer = 'he_normal'\n",
    "device = \"GPU\"\n",
    "n_epochs = epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddf87c97",
   "metadata": {
    "lines_to_end_of_cell_marker": 2
   },
   "outputs": [],
   "source": [
    "# inputs are of the form [batch, p_1, p_1, nd_xi +1] for nb_xi=2 (+1 because of the mu=f(x))\n",
    "\n",
    "first_network = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(p_1, p_1,)),  # [batch, p_1, p_1, 3]\n",
    "    tf.keras.layers.Flatten(),  # [batch, p_1*p_1*3]\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(p_1 * p_1, activation='relu'),\n",
    "    tf.keras.layers.Reshape((p_1, p_1,))  # [batch, p_1, p_1, p_2]\n",
    "])\n",
    "\n",
    "last_network = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(p_1, p_1,)),  # [batch, p_1, p_1, 3]\n",
    "    tf.keras.layers.Flatten(),  # [batch, p_1*p_1*3]\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(p_1 * p_1 * (1), activation='linear'),\n",
    "    tf.keras.layers.Reshape((p_1, p_1,))  # [batch, p_1, p_1, 3]\n",
    "])\n",
    "\n",
    "\n",
    "# first network graph:\n",
    "# [batch, p_1, p_1, 3] -> [batch, p_1*p_1*3] -> [batch, 512] -> [batch, 256] -> [batch, p_1*p_1*p_2] -> [batch, p_1, p_1, p_2]\n",
    "# last network graph:  \n",
    "# [batch, p_1, p_1, 3] -> [batch, p_1*p_1*3] -> [batch, 256] -> [batch, 512] -> [batch, p_1*p_1*3] -> [batch, p_1, p_1, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4389c7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"data/test_data/big_dataset_fno/heat2d/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88ebba4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-17 01:47:52,696 - sciml.model.fno.fno - INFO - Model initialized with 50 epochs, 32 batch size, 0.001 learning rate\n"
     ]
    }
   ],
   "source": [
    "model = FNO(regular_params={\"first_network\": first_network, \"last_network\": last_network},fourier_params={\"n_layers\": n_layers, \"dim_coords\":2, \"n_modes\": n_modes, \"activation\": activation, \"kernel_initializer\": kernel_initializer}, hyper_params={\"p_1\": p_1, \"p_2\": p_2,'p_3':p_3,\"device\": device,\"n_epochs\":n_epochs,\"index\":index,\"alpha\":alpha,\"folder_path\":folder_path,\"best_loss\":best_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a22e9e81",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "os.makedirs('results/fnograph', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "743fd78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = datetime.now().strftime(\"%Y%m%d_%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b67eab84",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntf.keras.utils.plot_model(model, \\n                         to_file=f'results/fno/model_graph_{date}.png',\\n                         show_shapes=True, \\n                         show_layer_names=True)\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "tf.keras.utils.plot_model(model, \n",
    "                         to_file=f'results/fno/model_graph_{date}.png',\n",
    "                         show_shapes=True, \n",
    "                         show_layer_names=True)\n",
    "'''\n",
    "# we create a txt file to save the model summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ed18d2",
   "metadata": {},
   "source": [
    "print(\"Model visualization and summary saved to results/fno/\")\n",
    "+\n",
    "mus, sol = model.get_data_partial(folder_path,alpha=alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca68b09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(mus.shape)\n",
    "# print(sol.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9d72bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import logging\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "# Ajouter en haut du notebook pour désactiver tout le logging\n",
    "# logging.getLogger().setLevel(logging.ERROR)  # Ne montrera que les erreurs graves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b994dc86",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-17 01:48:02,028 - sciml.model.fno.fno - INFO - === Partial Training Started ===\n",
      "2025-03-17 01:48:02,056 - sciml.model.fno.fno - INFO - Model Configuration:\n",
      "2025-03-17 01:48:02,058 - sciml.model.fno.fno - INFO - Hyperparameters: {\n",
      "  \"p_1\": 30,\n",
      "  \"p_2\": 30,\n",
      "  \"p_3\": 30,\n",
      "  \"device\": \"GPU\",\n",
      "  \"n_epochs\": 50,\n",
      "  \"index\": 450,\n",
      "  \"alpha\": 0.5,\n",
      "  \"folder_path\": \"data/test_data/big_dataset_fno/heat2d/\",\n",
      "  \"best_loss\": 5e-05\n",
      "}\n",
      "2025-03-17 01:48:02,060 - sciml.model.fno.fno - INFO - Fourier Parameters: {\n",
      "  \"n_layers\": 4,\n",
      "  \"dim_coords\": 2,\n",
      "  \"n_modes\": 30,\n",
      "  \"activation\": \"relu\",\n",
      "  \"kernel_initializer\": \"he_normal\"\n",
      "}\n",
      "2025-03-17 01:48:02,062 - sciml.model.fno.fno - INFO - Data Shape - Inputs: (500, 30, 30), Solutions: (500, 30, 30)\n",
      "2025-03-17 01:48:02,063 - sciml.model.fno.fno - INFO - Alpha (partial training fraction): 0.5\n",
      "2025-03-17 01:48:02,064 - sciml.model.fno.fno - INFO - Device: GPU\n",
      "2025-03-17 01:48:02.162535: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype float and shape [500,30,30]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "Training progress:   0%|          | 0/50 [00:00<?, ?it/s]2025-03-17 01:48:02.388351: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype float and shape [400,30,30]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2025-03-17 01:48:01.769700: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype float and shape [100,30,30]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2025-03-17 01:48:01,894 - sciml.model.fno.fno - INFO - Epoch 1/50\n",
      "2025-03-17 01:48:01,895 - sciml.model.fno.fno - INFO - Training Loss: 0.086100\n",
      "2025-03-17 01:48:01,896 - sciml.model.fno.fno - INFO - Test Loss: 0.069976\n",
      "2025-03-17 01:48:03,273 - sciml.model.fno.fno - INFO - Epoch 2/50\n",
      "2025-03-17 01:48:03,274 - sciml.model.fno.fno - INFO - Training Loss: 0.075682\n",
      "2025-03-17 01:48:03,275 - sciml.model.fno.fno - INFO - Test Loss: 0.057758\n",
      "Training progress:   4%|▍         | 2/50 [00:00<00:21,  2.24it/s]2025-03-17 01:48:04,619 - sciml.model.fno.fno - INFO - Epoch 3/50\n",
      "2025-03-17 01:48:04,620 - sciml.model.fno.fno - INFO - Training Loss: 0.058379\n",
      "2025-03-17 01:48:04,621 - sciml.model.fno.fno - INFO - Test Loss: 0.038752\n",
      "Training progress:   6%|▌         | 3/50 [00:02<00:38,  1.22it/s]2025-03-17 01:48:05,932 - sciml.model.fno.fno - INFO - Epoch 4/50\n",
      "2025-03-17 01:48:05,932 - sciml.model.fno.fno - INFO - Training Loss: 0.034500\n",
      "2025-03-17 01:48:05,933 - sciml.model.fno.fno - INFO - Test Loss: 0.019563\n",
      "Training progress:   8%|▊         | 4/50 [00:03<00:46,  1.00s/it]2025-03-17 01:48:07,246 - sciml.model.fno.fno - INFO - Epoch 5/50\n",
      "2025-03-17 01:48:07,247 - sciml.model.fno.fno - INFO - Training Loss: 0.016525\n",
      "2025-03-17 01:48:07,247 - sciml.model.fno.fno - INFO - Test Loss: 0.017276\n",
      "Training progress:  10%|█         | 5/50 [00:04<00:50,  1.11s/it]2025-03-17 01:48:08,561 - sciml.model.fno.fno - INFO - Epoch 6/50\n",
      "2025-03-17 01:48:08,563 - sciml.model.fno.fno - INFO - Training Loss: 0.011819\n",
      "2025-03-17 01:48:08,563 - sciml.model.fno.fno - INFO - Test Loss: 0.012708\n",
      "Training progress:  12%|█▏        | 6/50 [00:06<00:51,  1.18s/it]2025-03-17 01:48:09,851 - sciml.model.fno.fno - INFO - Epoch 7/50\n",
      "2025-03-17 01:48:09,852 - sciml.model.fno.fno - INFO - Training Loss: 0.007316\n",
      "2025-03-17 01:48:09,853 - sciml.model.fno.fno - INFO - Test Loss: 0.006286\n",
      "Training progress:  14%|█▍        | 7/50 [00:07<00:52,  1.21s/it]2025-03-17 01:48:11,168 - sciml.model.fno.fno - INFO - Epoch 8/50\n",
      "2025-03-17 01:48:11,168 - sciml.model.fno.fno - INFO - Training Loss: 0.003010\n",
      "2025-03-17 01:48:11,169 - sciml.model.fno.fno - INFO - Test Loss: 0.002837\n",
      "Training progress:  16%|█▌        | 8/50 [00:08<00:52,  1.25s/it]2025-03-17 01:48:12,620 - sciml.model.fno.fno - INFO - Epoch 9/50\n",
      "2025-03-17 01:48:12,621 - sciml.model.fno.fno - INFO - Training Loss: 0.001695\n",
      "2025-03-17 01:48:12,621 - sciml.model.fno.fno - INFO - Test Loss: 0.001602\n",
      "Training progress:  18%|█▊        | 9/50 [00:10<00:53,  1.31s/it]2025-03-17 01:48:13,993 - sciml.model.fno.fno - INFO - Epoch 10/50\n",
      "2025-03-17 01:48:13,994 - sciml.model.fno.fno - INFO - Training Loss: 0.001059\n",
      "2025-03-17 01:48:13,994 - sciml.model.fno.fno - INFO - Test Loss: 0.001051\n",
      "Training progress:  20%|██        | 10/50 [00:11<00:53,  1.33s/it]2025-03-17 01:48:15,302 - sciml.model.fno.fno - INFO - Epoch 11/50\n",
      "2025-03-17 01:48:15,303 - sciml.model.fno.fno - INFO - Training Loss: 0.000759\n",
      "2025-03-17 01:48:15,304 - sciml.model.fno.fno - INFO - Test Loss: 0.000688\n",
      "Training progress:  22%|██▏       | 11/50 [00:12<00:51,  1.32s/it]2025-03-17 01:48:16,594 - sciml.model.fno.fno - INFO - Epoch 12/50\n",
      "2025-03-17 01:48:16,595 - sciml.model.fno.fno - INFO - Training Loss: 0.000614\n",
      "2025-03-17 01:48:16,595 - sciml.model.fno.fno - INFO - Test Loss: 0.000603\n",
      "Training progress:  24%|██▍       | 12/50 [00:14<00:49,  1.31s/it]2025-03-17 01:48:17,832 - sciml.model.fno.fno - INFO - Epoch 13/50\n",
      "2025-03-17 01:48:17,833 - sciml.model.fno.fno - INFO - Training Loss: 0.000520\n",
      "2025-03-17 01:48:17,834 - sciml.model.fno.fno - INFO - Test Loss: 0.000511\n",
      "Training progress:  26%|██▌       | 13/50 [00:15<00:47,  1.29s/it]2025-03-17 01:48:19,179 - sciml.model.fno.fno - INFO - Epoch 14/50\n",
      "2025-03-17 01:48:19,180 - sciml.model.fno.fno - INFO - Training Loss: 0.000490\n",
      "2025-03-17 01:48:19,181 - sciml.model.fno.fno - INFO - Test Loss: 0.000490\n",
      "Training progress:  28%|██▊       | 14/50 [00:16<00:47,  1.31s/it]2025-03-17 01:48:20,741 - sciml.model.fno.fno - INFO - Epoch 15/50\n",
      "2025-03-17 01:48:20,742 - sciml.model.fno.fno - INFO - Training Loss: 0.000427\n",
      "2025-03-17 01:48:20,743 - sciml.model.fno.fno - INFO - Test Loss: 0.000453\n",
      "Training progress:  30%|███       | 15/50 [00:18<00:48,  1.38s/it]2025-03-17 01:48:22,362 - sciml.model.fno.fno - INFO - Epoch 16/50\n",
      "2025-03-17 01:48:22,363 - sciml.model.fno.fno - INFO - Training Loss: 0.000407\n",
      "2025-03-17 01:48:22,363 - sciml.model.fno.fno - INFO - Test Loss: 0.000421\n",
      "Training progress:  32%|███▏      | 16/50 [00:19<00:49,  1.46s/it]2025-03-17 01:48:23,849 - sciml.model.fno.fno - INFO - Epoch 17/50\n",
      "2025-03-17 01:48:23,850 - sciml.model.fno.fno - INFO - Training Loss: 0.000381\n",
      "2025-03-17 01:48:23,850 - sciml.model.fno.fno - INFO - Test Loss: 0.000407\n",
      "Training progress:  34%|███▍      | 17/50 [00:21<00:48,  1.46s/it]2025-03-17 01:48:25,311 - sciml.model.fno.fno - INFO - Epoch 18/50\n",
      "2025-03-17 01:48:25,312 - sciml.model.fno.fno - INFO - Training Loss: 0.000352\n",
      "2025-03-17 01:48:25,312 - sciml.model.fno.fno - INFO - Test Loss: 0.000392\n",
      "Training progress:  36%|███▌      | 18/50 [00:22<00:46,  1.46s/it]2025-03-17 01:48:26,781 - sciml.model.fno.fno - INFO - Epoch 19/50\n",
      "2025-03-17 01:48:26,782 - sciml.model.fno.fno - INFO - Training Loss: 0.000335\n",
      "2025-03-17 01:48:26,783 - sciml.model.fno.fno - INFO - Test Loss: 0.000377\n",
      "Training progress:  38%|███▊      | 19/50 [00:24<00:45,  1.47s/it]2025-03-17 01:48:28,203 - sciml.model.fno.fno - INFO - Epoch 20/50\n",
      "2025-03-17 01:48:28,203 - sciml.model.fno.fno - INFO - Training Loss: 0.000320\n",
      "2025-03-17 01:48:28,204 - sciml.model.fno.fno - INFO - Test Loss: 0.000366\n",
      "Training progress:  40%|████      | 20/50 [00:25<00:43,  1.45s/it]2025-03-17 01:48:29,562 - sciml.model.fno.fno - INFO - Epoch 21/50\n",
      "2025-03-17 01:48:29,562 - sciml.model.fno.fno - INFO - Training Loss: 0.000298\n",
      "2025-03-17 01:48:29,563 - sciml.model.fno.fno - INFO - Test Loss: 0.000354\n",
      "Training progress:  42%|████▏     | 21/50 [00:27<00:41,  1.42s/it]2025-03-17 01:48:30,839 - sciml.model.fno.fno - INFO - Epoch 22/50\n",
      "2025-03-17 01:48:30,840 - sciml.model.fno.fno - INFO - Training Loss: 0.000280\n",
      "2025-03-17 01:48:30,840 - sciml.model.fno.fno - INFO - Test Loss: 0.000344\n",
      "Training progress:  44%|████▍     | 22/50 [00:28<00:38,  1.38s/it]2025-03-17 01:48:32,089 - sciml.model.fno.fno - INFO - Epoch 23/50\n",
      "2025-03-17 01:48:32,090 - sciml.model.fno.fno - INFO - Training Loss: 0.000269\n",
      "2025-03-17 01:48:32,091 - sciml.model.fno.fno - INFO - Test Loss: 0.000337\n",
      "Training progress:  46%|████▌     | 23/50 [00:29<00:36,  1.34s/it]"
     ]
    }
   ],
   "source": [
    "loss_history_train,loss_history_test = model.fit_partial(save_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8a18f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error saving model summary: This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with open(f'results/fnograph/model_summary_{date}.txt', 'w') as f:\n",
    "        model.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
    "except Exception as e:\n",
    "    print(f\"Error saving model summary: {e}\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a96ae575",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loss_history_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mloss_history_train\u001b[49m))\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(loss_history_test))\n",
      "\u001b[31mNameError\u001b[39m: name 'loss_history_train' is not defined"
     ]
    }
   ],
   "source": [
    "print(len(loss_history_train))\n",
    "print(len(loss_history_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b26d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "plt.plot(loss_history_train,color='blue')\n",
    "plt.plot(loss_history_test,color='red')\n",
    "plt.legend(['Train','Test'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.yscale('log')\n",
    "plt.grid()\n",
    "date = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "plt.savefig(f'results/loss_history_fno{date}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53494d31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
